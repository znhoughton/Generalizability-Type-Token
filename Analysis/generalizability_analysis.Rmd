---
title: "Generalizability Analysis Script"
author: "Zachary Houghton"
date: "2023-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(sjPlot)
```

## Conditions Table

Table1:

|  |  |  |  |  |  |  |  |  |
|----|----|----|----|----|----|----|----|----|
| **Condition1** | #of tokens | #of types | **Condition2** | #of tokens | #of types | **Condition3** | #of tokens | #of types |
| dan | 12 | 12 | dan | 12 | 3 | dan | 12 | 12 |
| nem | 12 | 3 | nem | 3 | 3 | nem | 3 | 3 |
| sil | 6 | 6 | sil | 6 | 6 | sil | 6 | 6 |
| shoon | 6 | 6 | shoon | 6 | 6 | shoon | 6 | 6 |
| **Condition4** |  |  | **Condition5** |  |  | **nem language** | #of tokens | #of types |
| dan | 12 | 3 | dan | 3 | 3 | dan | 3 | 3 |
| nem | 12 | 12 | nem | 12 | 3 | nem | 12 | 12 |
| sil | 6 | 6 | sil | 6 | 6 | sil | 6 | 6 |
| shoon | 6 | 6 | shoon | 6 | 6 | shoon | 6 | 6 |

Table2

|  |  |  |  |  |  |  |  |  |
|----|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|
| **Condition** | **dan token** | **nem token** | **sil token** | **shoon token** | **dan type** | **nem type** | **sil type** | **shoon type** |
| 1 | 12 | 12 | 6 | 6 | 12 | 3 | 6 | 6 |
| 2 | 12 | 3 | 6 | 6 | 3 | 3 | 6 | 6 |
| 3 | 12 | 3 | 6 | 6 | 12 | 3 | 6 | 6 |
| 4 | 12 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |
| 5 | 3 | 12 | 6 | 6 | 3 | 3 | 6 | 6 |
| 6 | 3 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |

|   | Frequent Token | Frequent Type | Infrequent Token | Infrequent Type | Frequent Competitor Token | Frequent Competitor Type | Infrequent Competitor Token | Infrequent Competitor Type |
|----|----|----|----|----|----|----|----|----|
| **Condition 1** | 12 | 12 | 12 | 3 | 6 | 6 | 6 | 6 |
| **Condition 2** | 12 | 3 | 3 | 3 | 6 | 6 | 6 | 6 |
| **Condition 3** | 12 | 12 | 3 | 3 | 6 | 6 | 6 | 6 |

|   | Frequent Token | Frequent Type | Infrequent Token | Infrequent Type |
|----|----|----|----|----|
| **Condition 1** | 12 | 12 | 12 | 3 |
| **Condition 2** | 12 | 3 | 3 | 3 |
| **Condition 3** | 12 | 12 | 3 | 3 |

## Data Preparation

First let's load our data and clean it up

<!--# confirm the number of items in the table (*5) matches the items given to participants -->

```{r message = F}
data = read.csv('../Data/data_comprehension.csv', quote = "\"")# %>% #I'm not sure why, but read_csv() breaks because due to the quotes, even when setting the quote character properly
  #filter(is.na(PROLIFIC_PID) == F)

start_date <- as.POSIXct("2024-10-29") #, format="%Y-%m-%d %H:%M:%OS"
end_date <- as.POSIXct("2024-10-31") #, format="%Y-%m-%d %H:%M:%OS"

data = data %>% #I fucked up and accidentally coded a few participants in the wrong condition, so this line of code is to correct that mistake. We can inspected training_received to determine which condition a participant is in.
  mutate(date = as.POSIXct(date)) %>% #, format="%Y-%m-%d %H:%M:%OS")
  mutate(condition = ifelse(
    date >= start_date & date <= end_date, '1', condition
  ))


data_analysis = data %>%
  dplyr::select(participant, date, condition, pretraining, textbox.text, textbox_5.text, textbox_6.text, prod_label, prod_condition, prod_image2, prod_resp.text, key_resp_16.keys, comp_label1_location, comp_label2_location, label1, label2, comp_condition_stem, comp_condition_suffix, stem, stem_condition, mouse.clicked_name, comprehension_label, suffix) %>%
  rename(age = textbox.text,
         native_lang = textbox_5.text,
         other_langs = textbox_6.text,
         fc_resp = key_resp_16.keys,
         fc_label1_location = comp_label1_location,
         fc_label2_location = comp_label2_location,
         fc_label1 = label1,
         fc_label2 = label2,
         prod_suffix = prod_image2,
         fc_condition_stem = comp_condition_stem,
         fc_condition_suffix = comp_condition_suffix,
         prod_resp = prod_resp.text,
         prod_stem = prod_label,
         resp_stem = stem) %>%
  mutate(comprehension_response = case_when(
    mouse.clicked_name == 'prod_image1_5' ~ 'big_sg',
    mouse.clicked_name == 'prod_image2_3' ~ 'dim_sg',
    mouse.clicked_name == 'alt_image1_3' ~ 'dim_pl',
    mouse.clicked_name == 'alt_image2_3' ~ 'big_pl'
  )) %>%
  group_by(participant) %>%
  fill(c(condition, pretraining, age, native_lang, other_langs)) 

#data_analysis = data_analysis %>%
  #filter(!participant %in% c(332893, 837048, 356830, 117154, 894692)) #not SONA participants
data_analysis$date = gsub('_.*', '', data_analysis$date)
data_analysis$date = as.Date(data_analysis$date)

data_analysis = data_analysis %>%
  filter(date > '2024-10-01')

data_analysis$pretraining = as.factor(data_analysis$pretraining / 100)
data_analysis$condition = as.factor(data_analysis$condition)
data_analysis = data_analysis %>%
  mutate(fc_condition_suffix = ifelse(fc_condition_suffix == 'big', 'big_pl', fc_condition_suffix))

data_analysis_2afc = data_analysis %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, fc_resp, fc_label1_location, fc_label2_location, fc_label1, fc_label2, fc_condition_stem, fc_condition_suffix, resp_stem) %>%
  drop_na(fc_resp)



data_analysis_prod = data_analysis %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, prod_stem, prod_suffix, prod_condition, prod_resp) %>%
  drop_na(prod_resp)

data_analysis_prod$prod_suffix = gsub('.*/[0-9]*_(.+)\\.PNG', '\\1', data_analysis_prod$prod_suffix)

data_analysis_prod$prod_suffix[data_analysis_prod$prod_suffix=='2'] = 'big_pl'


data_analysis_comprehension = data_analysis %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, comprehension_label, comprehension_response)


training_received = data_analysis %>%
  select(suffix, condition, participant, date, stem_condition) %>%
  group_by(participant, condition, stem_condition, suffix, date) %>%
  summarize(table(suffix))

training_received2 = data_analysis %>%
  filter(comprehension_label == '' & !suffix == '') %>%
  select(suffix, condition) %>%
  group_by(participant, condition, suffix) %>%
  summarize(table(suffix)) %>%
  arrange(condition, participant, suffix)
```

```{r}
data_analysis %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

There are quite a lot of typos, so now we'll manually go through the production data and correct the typos:

training_con1 = training_received %\>%

filter(condition==1)

training_con4 = training_received %\>%

filter(condition==4)

xtabs(\~stem_condition + suffix, data = training_con1)

```{r}
#data_analysis_prod_typos = data_analysis_prod %>%
#  filter(prod_suffix == 'dim_pl')
#write_csv(data_analysis_prod_typos, '../Data/prod_data_typos.csv') #so that we can go through and manually correct typos
training_con1 = training_received %>%
  filter(condition==1)

training_con4 = training_received %>%
  filter(condition==4)

#xtabs(~stem_condition + suffix, data = training_con1)

```

The new

```{r}
#bad_participants = c(58877, 58950, 58253, 59044, 59192, 58101, 58988, 58898, 59227, 59328, 56878
#)
bad_participants = c(59819, 59913, 59915, 59795, 57882, 59703, 58913, 59530, 59955, 59406, 59423, 59901,59555, 59436, 59967, 58681, 59983, 57551, 59981, 59785, 59414, 59947, 59535, 59577, 59973, 59533, 59969, 59556, 60097, 59971, 59453, 59890, 59858, 60146, 60011, 59761, 58184, 59950, 59871, 60163, 60181, 59479, 59476, 59828, 60201, 59953, 59741, 59710, 59574, 59862, 59927, 60222, 60122, 59473
)
#bad participants are participants who answered with only the stem (no suffix) more than half the dim_pl trials

#data_analysis_prod = read_csv('../Data/data_analysis_prod_typos_fixed.csv') %>% #manually corrected typos
# filter(!participant %in% bad_participants)

#data_analysis_prod = data_analysis_prod %>%
#  filter(!participants %in% bad_participants)

data_analysis_prod$date = as.Date(data_analysis_prod$date)

data_analysis_prod = data_analysis_prod %>%
  mutate(prod_resp_suffix = str_extract_all(prod_resp, 'dan|sil|shoon|nem')) %>%
  unnest(prod_resp_suffix, keep_empty = T) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))
 

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(comprehension_suffix = str_extract_all(comprehension_label, 'dan|sil|shoon|nem')) %>%
  unnest(comprehension_suffix, keep_empty = T) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem')) %>%
  filter(!participant %in% bad_participants)

 
data_analysis_2afc = data_analysis_2afc %>%
  mutate(resp = ifelse(fc_resp == fc_label1_location, fc_label1, fc_label2)) %>%
  filter(!participant %in% bad_participants)

data_analysis_2afc = data_analysis_2afc %>%
  mutate(resp_suffix = str_extract_all(resp, 'dan|sil|shoon|nem')) %>%
  unnest(resp_suffix, keep_empty = T)

data_analysis_2afc = data_analysis_2afc %>%
  mutate(accuracy = case_when(fc_condition_suffix == 'big_pl' ~ ifelse(resp_suffix %in% c('dan', 'sil'), 1, 0))) %>%
  mutate(accuracy = case_when(fc_condition_suffix == 'dim_sg' ~ ifelse(resp_suffix %in% c('nem', 'shoon'), 1, 0))) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))

# accuracy_scores = data_analysis_2afc %>% f
#   group_by(participant) %>%
#   filter(!is.na(accuracy)) %>%
#   summarize(mean(accuracy))

data_analysis_2afc = data_analysis_2afc %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(resp_suffix == 'dan', 'freq',
                              ifelse(resp_suffix == 'sil', 'freq_competitor',
                              ifelse(resp_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(resp_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(resp_suffix == 'dan', 'infreq',
         ifelse(resp_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


data_analysis_prod = data_analysis_prod %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(prod_resp_suffix == 'dan', 'freq',
                              ifelse(prod_resp_suffix == 'sil', 'freq_competitor',
                              ifelse(prod_resp_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(prod_resp_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(prod_resp_suffix == 'dan', 'infreq',
         ifelse(prod_resp_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(comprehension_suffix == 'dan', 'freq',
                              ifelse(comprehension_suffix == 'sil', 'freq_competitor',
                              ifelse(comprehension_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(comprehension_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(comprehension_suffix == 'dan', 'infreq',
         ifelse(comprehension_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


names = c('resp_stem', 'picture_meaning', 'stem_condition', 'resp', 'resp_suffix_form')
names_2afc = c('stem_condition', 'picture_meaning', 'resp_stem', 'resp', 'resp_suffix_form')

colnames(data_analysis_prod)[8:12] = names
colnames(data_analysis_2afc)[13:17] = names_2afc


data_analysis_prod = data_analysis_prod %>%
  mutate(accuracy = case_when(picture_meaning == 'big_pl' ~ ifelse(resp_suffix_form %in% c('dan', 'sil'), 1, 0))) %>%
  mutate(accuracy = case_when(picture_meaning == 'dim_sg' ~ ifelse(resp_suffix_form %in% c('nem', 'shoon'), 1, 0)))

data_analysis_2afc = data_analysis_2afc %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, stem_condition, picture_meaning, resp_stem, resp, resp_suffix_form, freq_choice, accuracy, language) %>%
  mutate(task = '2afc')



data_analysis_prod = data_analysis_prod %>%
  mutate(task = 'prod')

#data_analysis_prod$date = as.Date(data_analysis_prod$date)
data_analysis_prod$condition = factor(data_analysis_prod$condition)
data_analysis_prod$pretraining = factor(data_analysis_prod$pretraining)

# data_analysis_2afc$date = as.character(data_analysis_2afc$date)
# data_analysis_2afc$condition = as.numeric(as.character(data_analysis_2afc$condition))
# data_analysis_2afc$pretraining = as.numeric(as.character(data_analysis_2afc$pretraining))

data_analysis = data_analysis_2afc %>%
  full_join(data_analysis_prod) 


accuracy_scores = data_analysis %>%
  filter(!is.na(accuracy) & task == '2afc') %>%
  group_by(participant) %>%
  summarize(mean_accuracy = mean(accuracy), sd_accuracy = sd(accuracy))

data_analysis = data_analysis %>%
  filter(!any(native_lang %in% c('Spanish\n', 'Vietnames', 'Vietnames\n', 'hebrew\n')))

length(unique(data_analysis$participant))

parts_above_75_acc = accuracy_scores %>%
  filter(mean_accuracy >= 0.75)

data_analysis2 = data_analysis %>%
  filter(participant %in% parts_above_75_acc$participant)
```

```{r}
data_analysis = data_analysis %>%
  mutate(meaning_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(picture_meaning == 'big_pl', 'freq',
                              ifelse(picture_meaning == 'dim_sg', 'infreq', 'novel')),
         ifelse(picture_meaning == 'big_pl', 'infreq', #if condition is 4,5, or 6
         ifelse(picture_meaning == 'dim_sg', 'freq', 'novel'))))

data_analysis = data_analysis %>%
  mutate(language = case_when(
    condition %in% c(1,2,3) ~ 'dan',
    condition %in% c(4,5,6) ~ 'nem'
  ))

data_analysis = data_analysis %>%
  mutate(condition = ifelse(condition == 4, 1, 
                            ifelse(condition == 5, 2, 
                                   ifelse(condition == 6, 3, condition)))) %>%
  filter(!is.na(resp_suffix_form)) %>%
  left_join(accuracy_scores, by = 'participant')


```

```{r}
data_analysis_comprehension = data_analysis_comprehension %>%
  filter(!is.na(comprehension_response)) %>%
  select(-freq_choice)
  
data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(comprehension_suffix = case_when(
    is.na(comprehension_suffix) ~ 'none',
    !is.na(comprehension_suffix) ~ comprehension_suffix
  ))

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(condition = ifelse(condition == 4, 1, 
                            ifelse(condition == 5, 2, 
                                   ifelse(condition == 6, 3, condition))))


data_analysis2 = data_analysis %>%
  filter(mean_accuracy >= 0.75)
```

```{r}
data %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

```{r}
data_analysis %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

# Analysis

First we'll eliminate participants with below \_\_\_% accuracy

```{r}
# accuracy_threshold = 0.7
# data_analysis_m1 = data_analysis %>%
#   filter(!mean_accuracy < accuracy_threshold)
```

Our dependent measure will be `freq_choice`.

Our independent measures will be pretraining, condition, stem_condition (whether the stem was familiar or novel), and task

<!--# add predictions? -->

<!--# analyses: freq_choice ~ pretraining*condition*stem_condition*task + (1|stem) + (1 + stem_condition*task|participant) + (pretraining*condition*task|stem) -->

<!--# freq vs infreq for novel meanings -->

<!--# freq vs freq competitor for novel meanings -->

<!--# also add analyses for subset data, subsetting by stem_condition and picture_meaning -->

```{r}
#options (contrasts = c('contr.treatment','contr.treatment'))
options(contrasts = c("contr.sum","contr.sum"))

data_m1 = data_analysis %>%
  filter(picture_meaning == 'dim_pl') %>%
  #filter(freq_choice %in% c('freq', 'infreq')) %>% #we are discarding sil and shoon responses by doing this
  mutate(freq_choice = case_when(freq_choice == 'freq' ~ 1,
                                 freq_choice == 'infreq' ~ 0))%>%
  mutate(condition = as.factor(condition)) %>%
  mutate(participant = as.factor(participant)) %>%
  mutate(pretraining = as.factor(pretraining)) 

data_m1_prod = data_m1 %>%
  filter(task=='prod')

str(data_analysis)

xtabs_df = data_m1 %>%
  select(resp_suffix_form, condition, task, language)

xtabs(~resp_suffix_form + language + condition + task, data = xtabs_df)
#data_m1$condition = factor(data_m1$condition, levels = c(3, 1, 2)) 

data_familiar = data_m1 %>%
  filter(stem_condition == 'familiar')

data_novel = data_m1 %>%
  filter(stem_condition == 'novel')


#length(unique(data_m1$participant))
#length(unique(data_familiar$participant))


# priors_m1 = c(
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'muinfreq'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'muinfreq'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'muinfreq')
# )

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'b'),
  prior(student_t(3, 0, 0.5), class = 'sd'),
  prior(lkj_corr_cholesky(2), class = 'cor'))
  
# 
# 
# m1 = brm(freq_choice ~ pretraining*condition*stem_condition*task + (1 + stem_condition*task|participant) + (pretraining*condition*task|resp_stem),
#          data = data_m1,
#          family = bernoulli(link = 'logit'),
#          iter = 16000, 
#          warmup = 8000,
#          chains = 4,
#          cores = 4,
#          prior = priors_m1,
#          control = list(adapt_delta = 0.98),
#          file = '../Data/model1')

# 
# m1_smaller = brm(freq_choice ~ (pretraining + condition + stem_condition + task)^3 + (1 + stem_condition*task|participant) + (pretraining*condition*task|resp_stem),
#          data = data_m1,
#          family = bernoulli(link = 'logit'),
#          iter = 10000, 
#          warmup = 5000,
#          chains = 4,
#          cores = 4,
#          prior = priors_m1,
#          #control = list(adapt_delta = 0.98),
#          file = '../Data/model1_small')


m1_smaller = brm(freq_choice ~ condition + stem_condition + task + task:condition + condition:stem_condition + stem_condition:task #rerun this model
                 + (1 + stem_condition*task|participant) + (condition|resp_stem),
         data = data_m1,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model1_small')

fixef(m1_smaller)
# 
# test = glmer(freq_choice ~ condition + stem_condition + task + task:condition + condition:stem_condition + stem_condition:task #rerun this model
#                  + (1 + stem_condition*task|participant) + (condition|resp_stem),
#          data = data_m1,
#          family = "binomial")




m1_only_familiar_stems = brm(freq_choice ~ condition*task + (1 + task|participant) + (condition*task|resp_stem),
         data = data_familiar,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model_familiar')



m1_only_novel_stems = brm(freq_choice ~ condition*task + (1 + task|participant) + (condition*task|resp_stem),
         data = data_novel,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model_novel')

fixef(m1_only_familiar_stems)
fixef(m1_only_novel_stems)

conditional_effects(m1_smaller)
conditional_effects(m1_only_familiar_stems)
conditional_effects(m1_only_novel_stems)


```

```{r}
plot_model(m1_smaller, type = 'int')
plot_model(m1_only_familiar_stems, type = 'int')
plot_model(m1_only_novel_stems, type = 'int')
```

```{r}
data_prod = data_m1 %>%
  filter(task == 'prod')

data_2afc = data_m1 %>%
  filter(task == '2afc')

m1_prod_small = brm(freq_choice ~ condition + stem_condition + condition:stem_condition
                 + (1 + stem_condition|participant) + (condition|resp_stem),
         data = data_prod,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_small')

fixef(m1_prod_small)

m1_2afc_small = brm(freq_choice ~ condition + stem_condition + condition:stem_condition
                 + (1 + stem_condition|participant) + (condition|resp_stem),
         data = data_2afc,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_small')

fixef(m1_2afc_small)

conditional_effects(m1_prod_small)
conditional_effects(m1_2afc_small)


##### even smaller models

data_familiar_prod = data_familiar %>%
  filter(task == 'prod')
data_familiar_2afc = data_familiar %>%
  filter(task == '2afc')

data_novel_prod = data_novel %>%
  filter(task == 'prod')
data_novel_2afc = data_novel %>%
  filter(task == '2afc')


def_priors = data.frame(get_prior(freq_choice ~ condition
                 + (1 |participant) + (condition|resp_stem),
         data = data_familiar_prod,
         family = bernoulli(link = 'logit')))

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'b'),
  prior(student_t(3, 0, 0.5), class = 'sd'))#,
  #prior(lkj_corr_cholesky(2), class = 'cor'))

m1_prod_familiar = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_familiar_prod,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 9000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99, max_treedepth=12),
         file = '../Data/m1_prod_familiar')


m1_2afc_familiar = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_familiar_2afc,
         family = bernoulli(link = 'logit'),
         iter = 22000, 
         warmup = 11000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc_familiar')


m1_prod_novel = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_novel_prod,
         family = bernoulli(link = 'logit'),
         iter = 30000, 
         warmup = 15000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_prod_novel')



m1_2afc_novel = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_novel_2afc,
         family = bernoulli(link = 'logit'),
         iter = 30000, 
         warmup = 15000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc_novel')




fixef(m1_prod_familiar)
fixef(m1_2afc_familiar)
fixef(m1_prod_novel)
fixef(m1_2afc_novel)


conditional_effects(m1_prod_familiar)
conditional_effects(m1_2afc_familiar)
conditional_effects(m1_prod_novel)
conditional_effects(m1_2afc_novel)

ranef(m1_prod_familiar)
ranef(m1_2afc_familiar)
ranef(m1_prod_novel)
ranef(m1_2afc_novel)

```

Comprehension analysis:

### Plots

```{r}
library(ggh4x)
data_analysis_2afc_prod_plot = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning%in% c('big_pl', 'dim_sg')) %>%
  group_by(picture_meaning, condition, stem_condition, language) %>%
  count(resp_suffix_form) %>%
  group_by(picture_meaning, condition, stem_condition, language) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot, aes(x=picture_meaning, y = proportion, fill = resp_suffix_form)) +
  geom_col(position='dodge') +
  facet_nested(condition~stem_condition+language) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot2 = data_analysis2 %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning%in% c('big_pl', 'dim_sg')) %>%
  group_by(picture_meaning, condition, task) %>%
  count(freq_choice) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot2 = data_analysis2 %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning=='dim_pl') %>%
  group_by(picture_meaning, condition, task) %>%
  count(freq_choice) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot2 = data_analysis2 %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning=='dim_pl' | stem_condition == 'novel') %>%
  group_by(condition, task) %>%
  count(freq_choice) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge', color='black') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot3 = data_analysis2 %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning=='dim_pl' & stem_condition == 'novel') %>%
  group_by(condition, task, language) %>%
  count(resp_suffix_form, .drop = F) %>%
  mutate(proportion = n / sum(n)) %>%
  ungroup() %>%
  # Add missing combinations
  complete(condition, task, language, resp_suffix_form, fill = list(n = 0))

ggplot(data_analysis_2afc_prod_plot3, aes(fill=resp_suffix_form, y = proportion, x = language)) +
  geom_col(position='dodge', color='black') +
  facet_nested(condition~task) +
  theme_bw()
```

```{r}
data_analysis_comprehension_plot1 = data_analysis_comprehension %>%
  group_by(condition, language, comprehension_suffix) %>%
  count(comprehension_response) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_comprehension_plot1, aes(x=comprehension_suffix, y = proportion, fill = comprehension_response)) +
  geom_col(position='dodge') +
  facet_nested(condition~language) +
  theme_bw()
```

```{r}
data_analysis_subjects_prod_plot = data_analysis %>%
  filter(task %in% c('prod')) %>%
  mutate(meaning_condition = case_when(picture_meaning == 'dim_pl' ~ 'new meaning',
                   picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original meaning (minus big_sg)')) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition) %>%
  filter(resp_suffix_form %in% c('nem', 'dan')) %>%
  count(resp_suffix_form, .drop = F) %>%
  ungroup() %>%
  complete(participant, meaning_condition, resp_suffix_form, fill = list(n = 0)) %>%
  group_by(participant) %>%
  mutate(condition = ifelse(is.na(condition), 
                            unique(condition[!is.na(condition)]),
                            condition)) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition, resp_suffix_form) %>%
  summarize(total_value = sum(n, na.rm = T)) %>%
  summarize(proportion = total_value[resp_suffix_form=='dan'] / (total_value[resp_suffix_form=='dan'] + total_value[resp_suffix_form=='nem']))

data_analysis_subjects_prod_plot = data_analysis_subjects_prod_plot %>%
  pivot_wider(names_from = meaning_condition, values_from = proportion)

p1 = ggplot(data_analysis_subjects_prod_plot, aes(x=`new meaning`, y = `original meaning (minus big_sg)`)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) +
  facet_wrap(~condition) +
  theme_bw() +
  ggtitle('dan vs nem')
```

```{r}
data_analysis_subjects_prod_plot2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  mutate(meaning_condition = case_when(picture_meaning == 'dim_pl' ~ 'new meaning',
                   picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original meaning (minus big_sg)')) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition) %>%
  filter(resp_suffix_form %in% c('sil', 'shoon')) %>%
  count(resp_suffix_form, .drop = F) %>%
  ungroup() %>%
  complete(participant, meaning_condition, resp_suffix_form, fill = list(n = 0)) %>%
  group_by(participant) %>%
  mutate(condition = ifelse(is.na(condition), 
                            unique(condition[!is.na(condition)]),
                            condition)) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition, resp_suffix_form) %>%
  summarize(total_value = sum(n, na.rm = T)) %>%
  summarize(proportion = total_value[resp_suffix_form=='sil'] / (total_value[resp_suffix_form=='sil'] + total_value[resp_suffix_form=='shoon']))

data_analysis_subjects_prod_plot2 = data_analysis_subjects_prod_plot2 %>%
  pivot_wider(names_from = meaning_condition, values_from = proportion)

p2 = ggplot(data_analysis_subjects_prod_plot2, aes(x=`new meaning`, y = `original meaning (minus big_sg)`)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) + 
  facet_wrap(~condition) +
  theme_bw() +
  ggtitle('sil vs shoon')
```

```{r}
library(ggpubr)
ggarrange(p1, p2, nrow = 2)
```

```{r}
data_analysis_subjects_prod_plot3 = data_analysis %>%
  filter(task %in% c('prod')) %>% 
  ungroup() %>%
  group_by(participant, language, condition, picture_meaning) %>%
  count(resp_suffix_form, .drop = F) %>%
  ungroup() %>%
  complete(participant, language, condition, picture_meaning, resp_suffix_form, fill = list(n = 0)) %>%
  group_by(participant) %>%
  mutate(condition = ifelse(is.na(condition), 
                            unique(condition[!is.na(condition)]),
                            condition)) %>%
  ungroup() %>%
  group_by(participant, language, condition, picture_meaning, resp_suffix_form) %>%
  summarize(total_value = sum(n, na.rm = T)) %>%
  summarize(proportion = case_when(
    language=='dan' & picture_meaning == 'big_pl' ~ total_value[resp_suffix_form=='sil'] / (total_value[resp_suffix_form=='sil'] + total_value[resp_suffix_form=='dan']),
    language=='dan' & picture_meaning == 'dim_pl' ~ total_value[resp_suffix_form=='sil'] / (total_value[resp_suffix_form=='sil'] + total_value[resp_suffix_form=='dan']),
    language=='nem' & picture_meaning == 'dim_sg' ~ total_value[resp_suffix_form=='shoon'] / (total_value[resp_suffix_form=='shoon'] + total_value[resp_suffix_form=='nem']),
    language == 'nem' & picture_meaning == 'dim_pl' ~ total_value[resp_suffix_form=='shoon'] / (total_value[resp_suffix_form=='shoon'] + total_value[resp_suffix_form=='nem']))) %>%
  distinct()


data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  na.omit()

length(unique(data_analysis_subjects_prod_plot3$participant))

data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  group_by(participant, language, condition, picture_meaning) %>%
  mutate('key' = case_when(
    language == 'dan' & picture_meaning == 'big_pl' ~ 'x-axis',
    language == 'nem' & picture_meaning == 'dim_sg' ~ 'x-axis',
    language == 'dan' & picture_meaning == 'dim_pl' ~ 'y-axis',
    language == 'nem' & picture_meaning == 'dim_pl' ~ 'y-axis'
  ))

data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  ungroup() %>%
  group_by(participant) %>%
  filter(n() == 2) %>%
  ungroup



data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  group_by(participant, key) %>%  # Group by participant and axis type
  summarize(proportion = sum(proportion), .groups = 'drop') %>%  # Sum proportions within each group
  pivot_wider(
    names_from = key,   # Create separate columns for x-axis and y-axis
    values_from = proportion,    # Use proportion values for the new columns
    values_fill = list(proportion = 0)  # Fill missing values with 0
  )

p3 = ggplot(data_analysis_subjects_prod_plot3, aes(x=`x-axis`, y = `y-axis`)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) + 
  #facet_wrap(~condition) +
  theme_bw() #+
  #ggtitle('sil vs shoon')

p3
```
