---
title: "Generalizability Analysis Script"
author: "Zachary Houghton"
date: "2023-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(sjPlot)
library(dplyr)
options(contrasts = c("contr.sum","contr.sum"))
```

## Conditions Table

Table1:

|  |  |  |  |  |  |  |  |  |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| **Condition1** | #of tokens | #of types | **Condition2** | #of tokens | #of types | **Condition3** | #of tokens | #of types |
| dan | 12 | 12 | dan | 12 | 3 | dan | 12 | 12 |
| nem | 12 | 3 | nem | 3 | 3 | nem | 3 | 3 |
| sil | 6 | 6 | sil | 6 | 6 | sil | 6 | 6 |
| shoon | 6 | 6 | shoon | 6 | 6 | shoon | 6 | 6 |
| **Condition4** |  |  | **Condition5** |  |  | **nem language** | #of tokens | #of types |
| dan | 12 | 3 | dan | 3 | 3 | dan | 3 | 3 |
| nem | 12 | 12 | nem | 12 | 3 | nem | 12 | 12 |
| sil | 6 | 6 | sil | 6 | 6 | sil | 6 | 6 |
| shoon | 6 | 6 | shoon | 6 | 6 | shoon | 6 | 6 |

Table2

|  |  |  |  |  |  |  |  |  |
|--------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| **Condition** | **dan token** | **nem token** | **sil token** | **shoon token** | **dan type** | **nem type** | **sil type** | **shoon type** |
| 1 | 12 | 12 | 6 | 6 | 12 | 3 | 6 | 6 |
| 2 | 12 | 3 | 6 | 6 | 3 | 3 | 6 | 6 |
| 3 | 12 | 3 | 6 | 6 | 12 | 3 | 6 | 6 |
| 4 | 12 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |
| 5 | 3 | 12 | 6 | 6 | 3 | 3 | 6 | 6 |
| 6 | 3 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |

|   | Frequent Token | Frequent Type | Infrequent Token | Infrequent Type | Frequent Competitor Token | Frequent Competitor Type | Infrequent Competitor Token | Infrequent Competitor Type |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| **Condition 1** | 12 | 12 | 12 | 3 | 6 | 6 | 6 | 6 |
| **Condition 2** | 12 | 3 | 3 | 3 | 6 | 6 | 6 | 6 |
| **Condition 3** | 12 | 12 | 3 | 3 | 6 | 6 | 6 | 6 |

|   | Frequent Token | Frequent Type | Infrequent Token | Infrequent Type |
|---------------|---------------|---------------|---------------|---------------|
| **Condition 1** | 12 | 12 | 12 | 3 |
| **Condition 2** | 12 | 3 | 3 | 3 |
| **Condition 3** | 12 | 12 | 3 | 3 |

## Data Preparation

First let's load our data and clean it up

<!--# confirm the number of items in the table (*5) matches the items given to participants -->

```{r message = F}
data = read.csv('../Data/data.csv', quote = "\"")# %>% #I'm not sure why, but read_csv() breaks because due to the quotes, even when setting the quote character properly
  #filter(is.na(PROLIFIC_PID) == F)
# 
# file_names = paste0("../Data/part", 1:6, ".csv")
# parts1through6 = do.call(rbind, lapply(file_names, read.csv, stringsAsFactors = FALSE)) %>%
#   mutate(across(everything(), as.character))
# 
# data = data %>%
#   mutate(across(everything(), as.character)) 
# 
# full_data = data %>%
#   left_join(parts1through6)
# 
# 
# start_date <- as.POSIXct("2024-10-29") #, format="%Y-%m-%d %H:%M:%OS"
# end_date <- as.POSIXct("2024-10-31") #, format="%Y-%m-%d %H:%M:%OS"


data_analysis = data %>%
  dplyr::select(participant, date, condition, textbox.text, textbox_5.text, textbox_6.text, prod_label, prod_condition, prod_image2, prod_resp.text, key_resp_16.keys, comp_label1_location, comp_label2_location, label1, label2, comp_condition_stem, comp_condition_suffix, stem, stem_condition, mouse.clicked_name, comprehension_label, suffix) %>%
  rename(age = textbox.text,
         native_lang = textbox_5.text,
         other_langs = textbox_6.text,
         fc_resp = key_resp_16.keys,
         fc_label1_location = comp_label1_location,
         fc_label2_location = comp_label2_location,
         fc_label1 = label1,
         fc_label2 = label2,
         prod_suffix = prod_image2,
         fc_condition_stem = comp_condition_stem,
         fc_condition_suffix = comp_condition_suffix,
         prod_resp = prod_resp.text,
         prod_stem = prod_label,
         resp_stem = stem) %>%
  mutate(comprehension_response = case_when(
    mouse.clicked_name == 'prod_image1_5' ~ 'big_sg',
    mouse.clicked_name == 'prod_image2_3' ~ 'dim_sg',
    mouse.clicked_name == 'alt_image1_3' ~ 'dim_pl',
    mouse.clicked_name == 'alt_image2_3' ~ 'big_pl'
  )) %>%
  group_by(participant) %>%
  fill(c(condition, age, native_lang, other_langs)) 

#data_analysis = data_analysis %>%
  #filter(!participant %in% c(332893, 837048, 356830, 117154, 894692)) #not SONA participants
data_analysis$date = gsub('_.*', '', data_analysis$date)
data_analysis$date = as.Date(data_analysis$date)

data_analysis = data_analysis %>%
  filter(date > '2024-10-01')

#data_analysis$pretraining = as.factor(data_analysis$pretraining / 100)
data_analysis$condition = as.factor(data_analysis$condition)
data_analysis = data_analysis %>%
  mutate(fc_condition_suffix = ifelse(fc_condition_suffix == 'big', 'big_pl', fc_condition_suffix))

data_analysis_2afc = data_analysis %>%
  select(participant, date, condition, age, native_lang, other_langs, fc_resp, fc_label1_location, fc_label2_location, fc_label1, fc_label2, fc_condition_stem, fc_condition_suffix, resp_stem) %>%
  drop_na(fc_resp)



data_analysis_prod = data_analysis %>%
  select(participant, date, condition, age, native_lang, other_langs, prod_stem, prod_suffix, prod_condition, prod_resp) %>%
  drop_na(prod_resp)

data_analysis_prod$prod_suffix = gsub('.*/[0-9]*_(.+)\\.PNG', '\\1', data_analysis_prod$prod_suffix)

data_analysis_prod$prod_suffix[data_analysis_prod$prod_suffix=='2'] = 'big_pl'


data_analysis_comprehension = data_analysis %>%
  select(participant, date, condition, age, native_lang, other_langs, stem_condition, comprehension_label, comprehension_response)


training_received = data_analysis %>%
  select(suffix, condition, participant, date, stem_condition) %>%
  group_by(participant, condition, stem_condition, suffix, date) %>%
  summarize(table(suffix))

training_received2 = data_analysis %>%
  filter(comprehension_label == '' & !suffix == '') %>%
  select(suffix, condition) %>%
  group_by(participant, condition, suffix) %>%
  summarize(table(suffix)) %>%
  arrange(condition, participant, suffix)
```

```{r}
data_analysis %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

There are quite a lot of typos, so now we'll manually go through the production data and correct the typos:

```{r}
# training_con1 = training_received %>%
#   filter(condition==1)
# 
# training_con4 = training_received %>%
#   filter(condition==4)
# 
# xtabs(~stem_condition + suffix, data = training_con1)
```

```{r}
data_analysis_prod_typos = data_analysis_prod %>%
  filter(prod_suffix == 'dim_pl')
#write_csv(data_analysis_prod_typos, '../Data/prod_data_typos.csv') #so that we can go through and manually correct typos
training_con1 = training_received %>%
  filter(condition==1)

training_con4 = training_received %>%
  filter(condition==4)

#xtabs(~stem_condition + suffix, data = training_con1)

```

The new

```{r}
bad_participants = c(21648, 942255, 649741, 813027, 153394, 644767, 839046, 291576, 549825, 317268, 510986, 329047, 932850, 164814, 957856, 22470, 897907, 961820, 770478, 314909, 309918, 127245, 503226, 896045, 300947, 66695, 166035, 273572, 732396, 737249, 26157, 630864, 692114, 997216, 211393, 943399, 353750, 237361, 57092, 846859, 77553, 886837)

#bad participants are participants who answered with only the stem (no suffix) more than half the dim_pl trials

data_analysis_prod2 = data_analysis_prod %>%
  filter(prod_suffix != 'dim_pl')

data_analysis_prod2$date = as.character(data_analysis_prod2$date)


# data_analysis_prod = read_csv('../Data/prod_data_typos_fixed.csv') %>% #manually corrected typos
#   filter(!participant %in% bad_participants) 

data_analysis_prod = data_analysis_prod %>%
  filter(!participant %in% bad_participants)

data_analysis_prod$condition = factor(data_analysis_prod$condition)
data_analysis_prod$date = as.character(data_analysis_prod$date)
#data_analysis_prod = data_analysis_prod %>%
  #full_join(data_analysis_prod2)

#data_analysis_prod = data_analysis_prod %>%
#  filter(!participants %in% bad_participants)

data_analysis_prod$date = as.Date(data_analysis_prod$date)

data_analysis_prod = data_analysis_prod %>%
  mutate(prod_resp_suffix = str_extract_all(prod_resp, 'dan|sil|shoon|nem')) %>%
  unnest(prod_resp_suffix, keep_empty = T) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))
 

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(comprehension_suffix = str_extract_all(comprehension_label, 'dan|sil|shoon|nem')) %>%
  unnest(comprehension_suffix, keep_empty = T) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem')) %>%
  filter(!participant %in% bad_participants)

 
data_analysis_2afc = data_analysis_2afc %>%
  mutate(resp = ifelse(fc_resp == fc_label1_location, fc_label1, fc_label2)) %>%
  filter(!participant %in% bad_participants)

data_analysis_2afc = data_analysis_2afc %>%
  mutate(resp_suffix = str_extract_all(resp, 'dan|sil|shoon|nem')) %>%
  unnest(resp_suffix, keep_empty = T)

data_analysis_2afc = data_analysis_2afc %>%
  mutate(accuracy = case_when(fc_condition_suffix == 'big_pl' ~ ifelse(resp_suffix %in% c('dan', 'sil'), 1, 0),
                              fc_condition_suffix == 'dim_sg' ~ ifelse(resp_suffix %in% c('nem', 'shoon'), 1, 0))) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))

# accuracy_scores = data_analysis_2afc %>% f
#   group_by(participant) %>%
#   filter(!is.na(accuracy)) %>%
#   summarize(mean(accuracy))

data_analysis_2afc = data_analysis_2afc %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(resp_suffix == 'dan', 'freq',
                              ifelse(resp_suffix == 'sil', 'freq_competitor',
                              ifelse(resp_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(resp_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(resp_suffix == 'dan', 'infreq',
         ifelse(resp_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


data_analysis_prod = data_analysis_prod %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(prod_resp_suffix == 'dan', 'freq',
                              ifelse(prod_resp_suffix == 'sil', 'freq_competitor',
                              ifelse(prod_resp_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(prod_resp_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(prod_resp_suffix == 'dan', 'infreq',
         ifelse(prod_resp_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(comprehension_suffix == 'dan', 'freq',
                              ifelse(comprehension_suffix == 'sil', 'freq_competitor',
                              ifelse(comprehension_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(comprehension_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(comprehension_suffix == 'dan', 'infreq',
         ifelse(comprehension_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


names = c('resp_stem', 'picture_meaning', 'stem_condition', 'resp', 'resp_suffix_form')
names_2afc = c('stem_condition', 'picture_meaning', 'resp_stem', 'resp', 'resp_suffix_form')

colnames(data_analysis_prod)[7:11] = names
colnames(data_analysis_2afc)[12:16] = names_2afc


data_analysis_prod = data_analysis_prod %>%
  mutate(accuracy = case_when(picture_meaning == 'big_pl' ~ ifelse(resp_suffix_form %in% c('dan', 'sil'), 1, 0),
         picture_meaning == 'dim_sg' ~ ifelse(resp_suffix_form %in% c('nem', 'shoon'), 1, 0)))

data_analysis_2afc = data_analysis_2afc %>%
  select(participant, date, condition, age, native_lang, other_langs, stem_condition, picture_meaning, resp_stem, resp, resp_suffix_form, freq_choice, accuracy, language) %>%
  mutate(task = '2afc')



data_analysis_prod = data_analysis_prod %>%
  mutate(task = 'prod')

#data_analysis_prod$date = as.Date(data_analysis_prod$date)
data_analysis_prod$condition = factor(data_analysis_prod$condition)


# data_analysis_2afc$date = as.character(data_analysis_2afc$date)
# data_analysis_2afc$condition = as.numeric(as.character(data_analysis_2afc$condition))
# data_analysis_2afc$pretraining = as.numeric(as.character(data_analysis_2afc$pretraining))

data_analysis = data_analysis_2afc %>%
  full_join(data_analysis_prod) 


accuracy_scores = data_analysis %>%
  filter(task == '2afc') %>%
  group_by(participant) %>%
  summarize(mean_accuracy = mean(accuracy, na.rm = T), sd_accuracy = sd(accuracy, na.rm = T))

data_analysis = data_analysis %>%
  filter(!any(native_lang %in% c('Spanish\n', 'Vietnames', 'Vietnames\n', 'hebrew\n')))

length(unique(data_analysis$participant))

parts_above_75_acc = accuracy_scores %>%
  filter(mean_accuracy >= 0.75)

data_analysis2 = data_analysis %>%
  filter(participant %in% parts_above_75_acc$participant)
```

```{r}
data_analysis = data_analysis %>%
  mutate(meaning_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(picture_meaning == 'big_pl', 'freq',
                              ifelse(picture_meaning == 'dim_sg', 'infreq', 'novel')),
         ifelse(picture_meaning == 'big_pl', 'infreq', #if condition is 4,5, or 6
         ifelse(picture_meaning == 'dim_sg', 'freq', 'novel'))))

data_analysis = data_analysis %>%
  mutate(language = case_when(
    condition %in% c(1,2,3) ~ 'dan',
    condition %in% c(4,5,6) ~ 'nem'
  ))

data_analysis = data_analysis %>%
  mutate(original_condition = condition) %>%
  mutate(condition = ifelse(condition == 4, 1, 
                            ifelse(condition == 5, 2, 
                                   ifelse(condition == 6, 3, condition)))) %>%
  filter(!is.na(resp_suffix_form)) %>%
  left_join(accuracy_scores, by = 'participant')


```

```{r}
data_analysis_comprehension = data_analysis_comprehension %>%
  filter(!is.na(comprehension_response)) %>%
  select(-freq_choice)
  
data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(comprehension_suffix = case_when(
    is.na(comprehension_suffix) ~ 'none',
    !is.na(comprehension_suffix) ~ comprehension_suffix
  ))

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(condition = ifelse(condition == 4, 1, 
                            ifelse(condition == 5, 2, 
                                   ifelse(condition == 6, 3, condition))))


data_analysis2 = data_analysis %>%
  filter(mean_accuracy >= 0.75)
```

```{r}
data %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

```{r}
data_analysis %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

# Analysis

First we'll eliminate participants with below \_\_\_% accuracy

```{r}
# accuracy_threshold = 0.7
# data_analysis_m1 = data_analysis %>%
#   filter(!mean_accuracy < accuracy_threshold)
```

Our dependent measure will be `freq_choice`.

Our independent measures will be pretraining, condition, stem_condition (whether the stem was familiar or novel), and task

<!--# add predictions? -->

<!--# analyses: freq_choice ~ pretraining*condition*stem_condition*task + (1|stem) + (1 + stem_condition*task|participant) + (pretraining*condition*task|stem) -->

<!--# freq vs infreq for novel meanings -->

<!--# freq vs freq competitor for novel meanings -->

<!--# also add analyses for subset data, subsetting by stem_condition and picture_meaning -->

```{r}
#options (contrasts = c('contr.treatment','contr.treatment'))
options(contrasts = c("contr.sum","contr.sum"))

data_m1 = data_analysis %>%
  filter(picture_meaning == 'dim_pl') %>%
  #filter(freq_choice %in% c('freq', 'infreq')) %>% #we are discarding sil and shoon responses by doing this
  mutate(freq_choice = case_when(freq_choice == 'freq' ~ 1,
                                 freq_choice == 'infreq' ~ 0))%>%
  mutate(condition = as.factor(condition)) %>%
  mutate(participant = as.factor(participant)) 

data_m1_prod = data_m1 %>%
  filter(task=='prod')

#str(data_analysis)

#xtabs_df = data_m1 %>%
  #select(resp_suffix_form, condition, task, language)

#xtabs(~resp_suffix_form + language + condition + task, data = xtabs_df)
#data_m1$condition = factor(data_m1$condition, levels = c(3, 1, 2)) 

data_familiar = data_m1 %>%
  filter(stem_condition == 'familiar')

data_novel = data_m1 %>%
  filter(stem_condition == 'novel')


#length(unique(data_m1$participant))
#length(unique(data_familiar$participant))


# priors_m1 = c(
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'muinfreq'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'muinfreq'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'muinfreq')
# )

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'b'),
  prior(student_t(3, 0, 0.5), class = 'sd'),
  prior(lkj_corr_cholesky(2), class = 'cor'))
  
# 
# 
# m1 = brm(freq_choice ~ pretraining*condition*stem_condition*task + (1 + stem_condition*task|participant) + (pretraining*condition*task|resp_stem),
#          data = data_m1,
#          family = bernoulli(link = 'logit'),
#          iter = 16000, 
#          warmup = 8000,
#          chains = 4,
#          cores = 4,
#          prior = priors_m1,
#          control = list(adapt_delta = 0.98),
#          file = '../Data/model1')

# 
# m1_smaller = brm(freq_choice ~ (pretraining + condition + stem_condition + task)^3 + (1 + stem_condition*task|participant) + (pretraining*condition*task|resp_stem),
#          data = data_m1,
#          family = bernoulli(link = 'logit'),
#          iter = 10000, 
#          warmup = 5000,
#          chains = 4,
#          cores = 4,
#          prior = priors_m1,
#          #control = list(adapt_delta = 0.98),
#          file = '../Data/model1_small')


m1_smaller = brm(freq_choice ~ condition + stem_condition + task + task:condition + condition:stem_condition + stem_condition:task #rerun this model
                 + (1 + stem_condition*task|participant) + (condition|resp_stem),
         data = data_m1,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model1_small')

fixef(m1_smaller)
# 
# test = glmer(freq_choice ~ condition + stem_condition + task + task:condition + condition:stem_condition + stem_condition:task #rerun this model
#                  + (1 + stem_condition*task|participant) + (condition|resp_stem),
#          data = data_m1,
#          family = "binomial")




m1_only_familiar_stems = brm(freq_choice ~ condition*task + (1 + task|participant) + (condition*task|resp_stem),
         data = data_familiar,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model_familiar')



m1_only_novel_stems = brm(freq_choice ~ condition*task + (1 + task|participant) + (condition*task|resp_stem),
         data = data_novel,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model_novel')

fixef(m1_only_familiar_stems)
fixef(m1_only_novel_stems)


hypothesis(m1_smaller, c('-(condition1+condition2)=0'))

```

```{r}
plot_model(m1_smaller, type = 'int')
plot_model(m1_only_familiar_stems, type = 'int')
plot_model(m1_only_novel_stems, type = 'int')
```

```{r}
data_prod = data_m1 %>%
  filter(task == 'prod')

data_2afc = data_m1 %>%
  filter(task == '2afc')

m1_prod_small = brm(freq_choice ~ condition + stem_condition + condition:stem_condition
                 + (1 + stem_condition|participant) + (condition|resp_stem),
         data = data_prod,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_small')

#data_prod_cond1

fixef(m1_prod_small)

m1_2afc_small = brm(freq_choice ~ condition + stem_condition + condition:stem_condition
                 + (1 + stem_condition|participant) + (condition|resp_stem),
         data = data_2afc,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_small')

fixef(m1_2afc_small)

# conditional_effects(m1_prod_small)
# conditional_effects(m1_2afc_small)



data_prod_cond1 = data_prod %>% filter(condition == 1)
data_prod_cond2 = data_prod %>% filter(condition == 2)
data_prod_cond3 = data_prod %>% filter(condition == 3)


data_familiar_cond1 = data_familiar %>% filter(condition == 1)
data_familiar_cond2 = data_familiar %>% filter(condition == 2)
data_familiar_cond3 = data_familiar %>% filter(condition == 3)

# 
# m1_prod_cond1 = brm(freq_choice ~ 1
#                  + (1 |participant), #+ (condition|resp_stem),
#          data = data_prod_cond1,
#          family = bernoulli(link = 'logit'))
# 
# m1_prod_cond2 = brm(freq_choice ~ 1
#                  + (1 |participant), #+ (condition|resp_stem),
#          data = data_prod_cond2,
#          family = bernoulli(link = 'logit'))
# 
# m1_prod_cond3 = brm(freq_choice ~ 1
#                  + (1 |participant), #+ (condition|resp_stem),
#          data = data_prod_cond3,
#          family = bernoulli(link = 'logit'))
# 
# 
# 
# 
# m1_familiar_cond1 = brm(freq_choice ~ 1
#                  + (1 |participant), #+ (condition|resp_stem),
#          data = data_familiar_cond1,
#          family = bernoulli(link = 'logit'))
# 
# m1_familiar_cond2 = brm(freq_choice ~ 1
#                  + (1 |participant), #+ (condition|resp_stem),
#          data = data_familiar_cond2,
#          family = bernoulli(link = 'logit'))
# 
# m1_familiar_cond3 = brm(freq_choice ~ 1
#                  + (1 |participant), #+ (condition|resp_stem),
#          data = data_familiar_cond3,
#          family = bernoulli(link = 'logit'))





data_familiar_prod = data_familiar %>%
  filter(task == 'prod')
data_familiar_2afc = data_familiar %>%
  filter(task == '2afc')

data_novel_prod = data_novel %>%
  filter(task == 'prod')
data_novel_2afc = data_novel %>%
  filter(task == '2afc')


def_priors = data.frame(get_prior(freq_choice ~ condition
                 + (1 |participant) + (condition|resp_stem),
         data = data_familiar_prod,
         family = bernoulli(link = 'logit')))

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'b'),
  prior(student_t(3, 0, 0.5), class = 'sd'))#,
  #prior(lkj_corr_cholesky(2), class = 'cor'))

m1_prod = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_familiar_prod,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 9000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99, max_treedepth=12),
         file = '../Data/m1_prod')


m1_2afc = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_familiar_2afc,
         family = bernoulli(link = 'logit'),
         iter = 22000, 
         warmup = 11000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc')



fixef(m1_prod)
fixef(m1_2afc)

##### even smaller models


m1_prod_familiar = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_familiar_prod,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 9000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99, max_treedepth=12),
         file = '../Data/m1_prod_familiar')


m1_2afc_familiar = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_familiar_2afc,
         family = bernoulli(link = 'logit'),
         iter = 22000, 
         warmup = 11000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc_familiar')


m1_prod_novel = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_novel_prod,
         family = bernoulli(link = 'logit'),
         iter = 30000, 
         warmup = 15000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_prod_novel')



m1_2afc_novel = brm(freq_choice ~ condition
                 + (1 |participant), #+ (condition|resp_stem),
         data = data_novel_2afc,
         family = bernoulli(link = 'logit'),
         iter = 30000, 
         warmup = 15000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc_novel')




fixef(m1_prod_familiar)
fixef(m1_2afc_familiar)
fixef(m1_prod_novel)
fixef(m1_2afc_novel)


# conditional_effects(m1_prod_familiar)
# conditional_effects(m1_2afc_familiar)
# conditional_effects(m1_prod_novel)
# conditional_effects(m1_2afc_novel)
# 
# ranef(m1_prod_familiar)
# ranef(m1_2afc_familiar)
# ranef(m1_prod_novel)
# ranef(m1_2afc_novel)

```

Key models:

```{r}

m1_prod_main = brm(freq_choice ~ condition + (1|participant) + (1|resp_stem),
         data = data_prod,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_main')

#data_prod_cond1



m1_2afc_main = brm(freq_choice ~ condition
                 + (1 | participant) + (1 | resp_stem),
         data = data_2afc,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_main')

prod_cond1 = data_prod %>%
  filter(condition == 1)

prod_cond2 = data_prod %>%
  filter(condition == 2)

prod_cond3 = data_prod %>%
  filter(condition == 3)

forced_choice_cond1 = data_2afc %>%
  filter(condition == 1)

forced_choice_cond2 = data_2afc %>%
  filter(condition == 2)

forced_choice_cond3 = data_2afc %>%
  filter(condition == 3)

m1_prod_cond1 = brm(freq_choice ~ 1 + (1|participant) + (1|resp_stem),
         data = prod_cond1,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_cond1')

m1_prod_cond2 = brm(freq_choice ~ 1 + (1|participant) + (1|resp_stem),
         data = prod_cond2,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_cond2')


m1_prod_cond3 = brm(freq_choice ~ 1 + (1|participant) + (1|resp_stem),
         data = prod_cond3,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_cond3')

m1_2afc_cond1 = brm(freq_choice ~ 1 + (1|participant) + (1|resp_stem),
         data = forced_choice_cond1,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_cond1')

m1_2afc_cond2 = brm(freq_choice ~ 1 + (1|participant) + (1|resp_stem),
         data = forced_choice_cond2,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_cond2')


m1_2afc_cond3 = brm(freq_choice ~ 1 + (1|participant) + (1|resp_stem),
         data = forced_choice_cond3,
         family = bernoulli(link = 'logit'),
         iter = 6000, 
         warmup = 3000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         #control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_cond3')

fixef(m1_prod_main)
fixef(m1_2afc_main)

fixef(m1_prod_cond1)
fixef(m1_prod_cond2)
fixef(m1_prod_cond3)

fixef(m1_2afc_cond1)
fixef(m1_2afc_cond2)
fixef(m1_2afc_cond3)

#conditional_effects(m1_prod_main)
#conditional_effects(m1_2afc_main)


percent_greater_zero_prod = data.frame(fixef(m1_prod_main, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_2afc = data.frame(fixef(m1_2afc_main, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_prod
percent_greater_zero_2afc
```

## Models for Paper

### Prep Data

```{r}
options(contrasts = c("contr.treatment","contr.treatment"))
## Production
#2x2 model for condition1
#original vs novel; frequent vs infrequent
data_prod = data_analysis %>%
  filter(task == 'prod') %>%
  filter(resp_suffix_form %in% c('dan', 'nem'))



data_2afc = data_analysis %>%
  filter(task == '2afc') %>%
  filter(resp_suffix_form %in% c('dan', 'nem'))


data_prod_no_sil_shoon = data_prod %>%
  mutate(meaning = case_when(
    picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original',
    picture_meaning == 'dim_pl' ~ 'novel'),
    frequency = case_when(
      freq_choice == 'freq' ~ 1,
      freq_choice == 'infreq' ~ 0,
      .default = NA
    )
  ) %>%
  filter((accuracy == 1) %>% replace_na(TRUE))


data_2afc = data_2afc %>%
  filter(resp_suffix_form %in% c('dan', 'nem')) %>%
  mutate(meaning = case_when(
    picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original',
    picture_meaning == 'dim_pl' ~ 'novel'),
    frequency = case_when(
      freq_choice == 'freq' ~ 1,
      freq_choice == 'infreq' ~ 0,
      .default = NA
    )
  ) %>%
  filter((accuracy == 1) %>% replace_na(TRUE))

data_2afc$condition = factor(data_2afc$condition, levels = c(3, 1, 2))


data_prod_no_sil_shoon$participant = factor(data_prod_no_sil_shoon$participant)
data_prod_no_sil_shoon$condition = factor(data_prod_no_sil_shoon$condition, levels = c(3, 1, 2))

#write_csv(data_prod_no_sil_shoon, '../Data/data_prod_no_sil_shoon.csv')

data_prod_original = data_prod_no_sil_shoon %>%
  filter(meaning == 'original')

data_prod_original_cond2_baseline = data_prod_original %>%
  mutate(condition = factor(condition, levels = c('2', '1', '3')))

data_prod_novel = data_prod_no_sil_shoon %>%
  filter(meaning == 'novel')

data_prod_novel_cond2_baseline = data_prod_novel %>%
  mutate(condition = factor(condition, levels = c('2', '1', '3')))

data_2afc_original = data_2afc %>%
  filter(meaning == 'original')

data_2afc_original_cond2_baseline = data_2afc_original %>%
  mutate(condition = factor(condition, levels = c('2', '1', '3')))

data_2afc_novel = data_2afc %>%
  filter(meaning == 'novel')

data_2afc_novel_cond2_baseline = data_2afc_novel %>%
  mutate(condition = factor(condition, levels = c('2', '1', '3')))

#data_analysis_comprehension$condition = factor(data_analysis_comprehension$condition)
data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(freq_suffix = case_when(
    language == 'dan' & comprehension_suffix == 'dan' ~ 'freq',
    language == 'nem' & comprehension_suffix == 'nem' ~ 'freq',
    .default = 'infreq'
  )) %>%
  mutate(original_meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'big_pl' ~ 1,
    comprehension_suffix == 'nem' & comprehension_response == 'dim_sg' ~ 1,
    .default = 0
  )) %>%
  mutate(novel_meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'dim_pl' ~ 1,
    comprehension_suffix == 'nem' & comprehension_response == 'dim_pl' ~ 1,
    .default = 0
  )) %>%
  filter(novel_meaning == 1 | original_meaning == 1)

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(frequent = case_when(
    language == 'dan' & comprehension_suffix == 'dan' ~ 1,
    language == 'nem' & comprehension_suffix == 'nem' ~ 1,
    .default = 0
  ),
  meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'big_pl' ~ 'original',
    comprehension_suffix == 'nem' & comprehension_response == 'dim_sg' ~ 'original',
    comprehension_response == 'dim_pl' ~ 'novel',
    .default = NA
  ))

data_comprehension_freq = data_analysis_comprehension %>%
  filter(frequent == 1)
data_comprehension_infreq = data_analysis_comprehension %>%
  filter(frequent == 0)


```

```{r}


```

### Models

```{r}


priors_m1 = c(
  prior(student_t(3, 0, 1), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 1), class = 'b'),
  prior(student_t(3, 0, 1), class = 'sd'))

model_prod_original = brm(frequency ~ condition + (1 | participant),
                                       data = data_prod_original,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_original')

model_prod_novel = brm(frequency ~ condition + (1 | participant),
                                       data = data_prod_novel,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_novel')


data_prod_both = data_prod_original %>%
  full_join(data_prod_novel)

data_prod_both$meaning = factor(data_prod_both$meaning)
contrasts(data_prod_both$meaning) = contr.sum(levels(data_prod_both$meaning))
data_prod_both$stem_condition = factor(data_prod_both$stem_condition, levels = c('novel', 'familiar'))
contrasts(data_prod_both$stem_condition) = contr.sum(levels(data_prod_both$stem_condition))

model_prod_both = brm(frequency ~ condition*meaning + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_both')


model_prod_both_stem = brm(frequency ~ condition*meaning*stem_condition + (1 + meaning*stem_condition | participant) + (1 | resp_stem),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_both_stem')



model_prod_original_cond2_baseline = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
                                       data = data_prod_original_cond2_baseline,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_original_cond2_baseline')

model_prod_novel_cond2_baseline = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
                                       data = data_prod_novel_cond2_baseline,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_novel_cond2_baseline')



fixef(model_prod_original)
fixef(model_prod_novel)


hypothesis(model_prod_original, "-c(condition1 + condition2) = 0")
hypothesis(model_prod_novel, "-c(condition1 + condition2) = 0")


percent_greater_zero_original = data.frame(fixef(model_prod_original, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_original_cond3 = data.frame(fixef(model_prod_original, summary = F)) %>%
  summarize(sum(condition1 + condition2 > 0) / n() * 100, sum(condition1 + condition2 > 0), n())


percent_greater_zero_novel = data.frame(fixef(model_prod_novel, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)
  
percent_greater_zero_novel_cond3 = data.frame(fixef(model_prod_novel, summary = F)) %>%
  summarize(sum(condition1 + condition2 > 0) / n() * 100, sum(condition1 + condition2 > 0), n())






plot_prod_stem = plot_model(model_prod_both_stem, type = 'int',
                            axis.title = c('Condition', 'Frequency'),
                            axis.labels = "condition",
                            legend.title = 'Meaning',
                            title = "",
                            dot.size = 2,
                            line.size = 1,
                            colors = c('#298c8c', '#800074'))[[4]] 
plot_prod_stem[[11]]$linetype = 'Meaning'
plot_prod_stem[[11]]$shape = 'Meaning'

plot_prod_stem[[1]]$group_col = factor(plot_prod_stem[[1]]$group_col, levels = c('novel', 'original'), labels = c('Novel', 'Original'))

plot_prod_stem[[1]]$group = factor(plot_prod_stem[[1]]$group, levels = c('novel', 'original'), labels = c('Novel', 'Original'))

plot_prod_stem[[1]]$facet = factor(plot_prod_stem[[1]]$facet, levels = c('novel', 'familiar'), labels = c('Novel', 'Familiar'))

#plot_prod_stem[[1]]$x

plot_prod_stem +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```

2afc

```{r}

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'b'),
  prior(student_t(3, 0, 0.5), class = 'sd'))


model_2afc_original = brm(frequency ~ condition + (1 | participant),
                                       data = data_2afc_original,
                                       family = bernoulli(link = 'logit'),
                                       iter = 20000, 
                                       warmup = 10000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_original')


model_2afc_novel = brm(frequency ~ condition + (1 | participant),
                                       data = data_2afc_novel,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_novel')

data_2afc_both = data_2afc_original %>%
  full_join(data_2afc_novel)

data_2afc_both$meaning = factor(data_2afc_both$meaning)
contrasts(data_2afc_both$meaning) = contr.sum(levels(data_2afc_both$meaning))
data_2afc_both$stem_condition = factor(data_2afc_both$stem_condition)
contrasts(data_2afc_both$stem_condition) = contr.sum(levels(data_2afc_both$stem_condition))

model_2afc_both = brm(frequency ~ condition*meaning + (1 + meaning | participant),
                                       data = data_2afc_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both')

data_2afc_both$condition_diff = factor(data_2afc_both$condition, levels = c(1,2,3))
model_2afc_both_stem_dif_conditions = brm(frequency ~ condition_diff*meaning*stem_condition + (1 + meaning | participant),
                                       data = data_2afc_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both_stem_dif_conditions')

model_2afc_both_stem = brm(frequency ~ condition*meaning*stem_condition + (1 + meaning | participant),
                                       data = data_2afc_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both_stem')


model_2afc_original_cond2_baseline = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
                                       data = data_2afc_original_cond2_baseline,
                                       family = bernoulli(link = 'logit'),
                                       iter = 20000, 
                                       warmup = 10000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_original_cond2_baseline')


model_2afc_novel_cond2_baseline = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
                                       data = data_2afc_novel_cond2_baseline,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_novel_cond2_baseline')

fixef(model_2afc_original)
fixef(model_2afc_novel)


hypothesis(model_2afc_original, "-c(condition1 + condition2) = 0")
hypothesis(model_2afc_novel, "-c(condition1 + condition2) = 0")


percent_greater_zero_original_2afc = data.frame(fixef(model_2afc_original, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_original_cond3_2afc = data.frame(fixef(model_2afc_original, summary = F)) %>%
  summarize(sum(condition1 + condition2 > 0) / n() * 100, sum(condition1 + condition2 > 0), n())


percent_greater_zero_novel_2afc = data.frame(fixef(model_2afc_novel, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)
  
percent_greater_zero_novel_cond3_2afc = data.frame(fixef(model_2afc_novel, summary = F)) %>%
  summarize(sum(condition1 + condition2 > 0) / n() * 100, sum(condition1 + condition2 > 0), n())
```

```{r}



plot_prod_stem = plot_model(model_2afc_both_stem_dif_conditions, type = 'int',
                            axis.title = c('Condition', 'Frequency'),
                            axis.labels = "condition",
                            legend.title = 'Meaning',
                            title = "",
                            dot.size = 2,
                            line.size = 1,
                            colors = c('#298c8c', '#800074'))[[4]] 
plot_prod_stem[[11]]$linetype = 'Meaning'
plot_prod_stem[[11]]$shape = 'Meaning'

plot_prod_stem[[1]]$group_col = factor(plot_prod_stem[[1]]$group_col, levels = c('novel', 'original'), labels = c('Novel', 'Original'))

plot_prod_stem[[1]]$group = factor(plot_prod_stem[[1]]$group, levels = c('novel', 'original'), labels = c('Novel', 'Original'))

plot_prod_stem[[1]]$facet = factor(plot_prod_stem[[1]]$facet, levels = c('novel', 'familiar'), labels = c('Novel', 'Familiar'))

#plot_prod_stem[[1]]$x

plot_prod_stem +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency')) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(c(0,1))
```

Comprehension

```{r}
priors_m1 = c(
  prior(student_t(3, 0, 1), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 1), class = 'b'),
  prior(student_t(3, 0, 1), class = 'sd'))
data_analysis_comprehension$frequent = factor(data_analysis_comprehension$frequent)

data_analysis_comprehension$condition = factor(data_analysis_comprehension$condition, levels = c(3, 1, 2))

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(meaning = case_when(
    meaning == 'novel' ~ 1,
    meaning == 'original' ~ 0
  ))
data_analysis_comprehension$meaning = factor(data_analysis_comprehension$meaning)
levels(data_analysis_comprehension$meaning)

model_comprehension = brm(meaning ~ condition*frequent + (1 + frequent | participant),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension')


fixef(model_comprehension)

hypothesis(model_comprehension, "-c(condition1 + condition2) = 0")


percent_greater_zero_comprehension = data.frame(fixef(model_comprehension, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_comprehension_cond3 = data.frame(fixef(model_comprehension, summary = F)) %>%
  summarize(sum(condition1 + condition2 > 0) / n() * 100, sum(condition1 + condition2 > 0), n())


freq_effects = hypothesis(model_comprehension, c("Intercept = Intercept + frequent1", "Intercept + condition1 = Intercept + condition1 + frequent1 + condition1:frequent1", "Intercept + condition2 = Intercept + condition2 + frequent1 + condition2:frequent1"))

freq_effects_df = data.frame(term = freq_effects$hypothesis$Hypothesis, estimate = freq_effects$hypothesis$Estimate, est.error = freq_effects$hypothesis$Est.Error, ci2.5 = freq_effects$hypothesis$CI.Lower, ci97.5 = freq_effects$hypothesis$CI.Upper)

data_analysis_comprehension$language = factor(data_analysis_comprehension$language)
contrasts(data_analysis_comprehension$language) = contr.sum(levels(data_analysis_comprehension$language))

data_analysis_comprehension_cond2_baseline = data_analysis_comprehension %>%
  mutate(condition = factor(condition, levels = c('2','1','3')))

model_comprehension_cond2_baseline = brm(meaning ~ condition*frequent + (1 + frequent | participant),
                                       data = data_analysis_comprehension_cond2_baseline,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_cond2_baseline')


model_comprehension_language = brm(meaning ~ condition*frequent*language + (1 + frequent | participant) + (frequent | language),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_language')


```

```{r}
options (contrasts = c('contr.treatment','contr.treatment'))


data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(frequency = ifelse(comprehension_suffix == language, 1, 0)) %>%
  mutate(condition_numeric = case_when(
    (condition == '1' & frequency == 1) | (condition == '3' & frequency == 1) ~ '12-12',
    (condition == '1' & frequency == 0) | (condition == '2' & frequency == 1) ~ '12-3',
    (condition == '2' & frequency == 0) | (condition == '3' & frequency == 0) ~ '3-3'
  ))

data_analysis_comprehension$condition_numeric = factor(data_analysis_comprehension$condition_numeric, levels = c('12-3', '12-12', '3-3'))


#12-12 high type high token
#12-3 high token low type
#3-3 low token low type 



model_comprehension_numeric = brm(meaning ~ condition_numeric + (1 | participant),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric_test')

data_analysis_comprehension$stem_condition = factor(data_analysis_comprehension$stem_condition)

contrasts(data_analysis_comprehension$stem_condition) = contr.sum(levels(data_analysis_comprehension$stem_condition))

model_comprehension_numeric_stem = brm(meaning ~ condition_numeric*stem_condition + (1 + stem_condition | participant),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric_stem_test2')

fixef(model_comprehension_numeric)
fixef(model_comprehension_numeric_stem)
```

### Plots

```{r}
library(ggh4x)

data_analysis_2afc_prod_plot = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('big_pl', 'dim_sg')) %>%
  group_by(condition, stem_condition) %>%
  count(freq_choice) %>%
  group_by(condition, stem_condition) 


# Create a new column to group freq/infreq together
data_analysis_2afc_prod_plot = data_analysis_2afc_prod_plot %>%
  mutate('Frequency' = ifelse(freq_choice %in% c('freq', 'freq_competitor'), 'Frequent', 'Infrequent')) %>%
  group_by(Frequency, condition, stem_condition) %>%
  mutate(proportion = n / sum(n))

data_analysis_2afc_prod_plot$freq_choice = factor(data_analysis_2afc_prod_plot$freq_choice, levels = c('freq_competitor', 'freq', 'infreq_competitor', 'infreq'))


data_analysis_2afc_prod_plot = data_analysis_2afc_prod_plot %>%
  filter(freq_choice %in% c('freq', 'infreq'))

data_analysis_2afc_prod_plot = data_analysis_2afc_prod_plot %>%
mutate(stem_condition = ifelse(stem_condition == 'familiar', 'Familiar', 'Novel'))

ggplot(data_analysis_2afc_prod_plot, aes(x = condition, y = proportion, fill = Frequency)) +
  geom_col(position = "dodge") + 
  facet_grid(~ stem_condition) + 
  theme_bw() +
  ggtitle('Production of old meanings') +
  xlab('Condition') +
  ylab('Proportion to competitor') +
  ylim(0, 1)

```

```{r}
data_analysis_2afc_prod_plot = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl')) %>%
  group_by(condition, stem_condition) %>%
  count(freq_choice) %>%
  group_by(condition, stem_condition) 


# Create a new column to group freq/infreq together
data_analysis_2afc_prod_plot = data_analysis_2afc_prod_plot %>%
  mutate('Frequency' = ifelse(freq_choice %in% c('freq', 'freq_competitor'), 'Frequent', 'Infrequent')) %>%
  group_by(Frequency, condition, stem_condition) %>%
  mutate(proportion = n / sum(n))

data_analysis_2afc_prod_plot$freq_choice = factor(data_analysis_2afc_prod_plot$freq_choice, levels = c('freq_competitor', 'freq', 'infreq_competitor', 'infreq'))


data_analysis_2afc_prod_plot = data_analysis_2afc_prod_plot %>%
  filter(freq_choice %in% c('freq', 'infreq'))

data_analysis_2afc_prod_plot = data_analysis_2afc_prod_plot %>%
mutate(stem_condition = ifelse(stem_condition == 'familiar', 'Familiar', 'Novel'))

ggplot(data_analysis_2afc_prod_plot, aes(x = condition, y = proportion, fill = Frequency)) +
  geom_col(position = "dodge") + 
  facet_grid(~ stem_condition) + 
  theme_bw() +
  ggtitle('Production of new meaning') +
  xlab('Condition') +
  ylab('Proportion to competitor') +
  ylim(0, 1)
```

```{r}
data_analysis_2afc_prod_plot = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('big_pl', 'dim_sg')) %>%
  group_by(picture_meaning, condition, stem_condition, language) %>%
  count(resp_suffix_form) %>%
  group_by(picture_meaning, condition, stem_condition, language) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot, aes(x=picture_meaning, y = proportion, fill = resp_suffix_form)) +
  geom_col(position='dodge') +
  facet_nested(condition~stem_condition+language) +
  theme_bw()
```

```{r}
library(dplyr)
library(tidyr)

data_analysis_2afc_prod_plot2 <- data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('big_pl', 'dim_sg')) %>%
  group_by(picture_meaning, condition, task, freq_choice) %>%  # Include freq_choice in grouping
  summarise(n = n(), .groups = "drop") %>%  # Use summarise instead of count()
  complete(picture_meaning, condition, task, freq_choice, fill = list(n = 0)) %>%  # Fill missing rows with n=0
  group_by(picture_meaning, condition, task) %>%
  mutate(proportion = n / sum(n))  # Compute proportions


ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
library(dplyr)
library(tidyr)

data_analysis_2afc_prod_plot2 <- data_analysis %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning == 'dim_pl') %>%
  group_by(picture_meaning, condition, task, freq_choice) %>%
  summarise(n = n(), .groups = "drop") %>%  # Use summarise instead of count()
  complete(picture_meaning, condition, task, freq_choice, fill = list(n = 0)) %>%  # Fill missing rows with n=0
  group_by(picture_meaning, condition, task) %>%
  mutate(proportion = n / sum(n))  # Compute proportions


ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning == 'dim_pl') %>%
  group_by(picture_meaning, condition, stem_condition, freq_choice) %>%
  summarise(n = n(), .groups = "drop") %>%  # Use summarise instead of count()
  complete(picture_meaning, condition, stem_condition, freq_choice, fill = list(n = 0)) %>%  # Fill missing rows with n=0
  group_by(picture_meaning, condition, stem_condition) %>%
  mutate(proportion = n / sum(n))  # Compute proportions

data_analysis_2afc_prod_plot2 = data_analysis_2afc_prod_plot2 %>%
  mutate(stem_condition = ifelse(stem_condition == 'familiar', 'Familiar', 'Novel')) %>%
  mutate('Frequency' = freq_choice)

ggplot(data_analysis_2afc_prod_plot2, aes(fill=Frequency, y = proportion, x = factor(condition))) +
  geom_col(position='dodge') +
  facet_wrap(~stem_condition) +
  ylab('Proportion') +
  xlab('Condition') +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot2b <- data_analysis %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning == 'dim_pl' & freq_choice %in% c('freq', 'infreq')) %>%
  group_by(picture_meaning, condition, task, freq_choice) %>%  # Include freq_choice in grouping
  summarise(n = n(), .groups = "drop") %>%  # Use summarise instead of count()
  complete(picture_meaning, condition, task, freq_choice, fill = list(n = 0)) %>%  # Fill missing rows with n=0
  group_by(picture_meaning, condition, task) %>%
  mutate(proportion = n / sum(n))  # Compute proportions


ggplot(data_analysis_2afc_prod_plot2b, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge') +
  #geom_errorbar(data = data_analysis_2afc_prod_plot2b, aes(x=factor(condition), y = proportion, ymin = proportion - ))
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot2 = data_analysis %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning=='dim_pl' | stem_condition == 'novel') %>%
  group_by(condition, task) %>%
  count(freq_choice) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge', color='black') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}

         
```

```{r}
data_analysis_2afc_prod_plot3 = data_analysis %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning=='dim_pl' | stem_condition == 'familiar') %>%
  group_by(condition, task) %>%
  count(freq_choice) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge', color='black') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot3 = data_analysis %>%
  group_by(condition, task, language) %>%
  count(resp_suffix_form, .drop = F) %>%
  mutate(proportion = n / sum(n)) %>%
  ungroup() %>%
  # Add missing combinations
  complete(condition, task, language, resp_suffix_form, fill = list(n = 0))

ggplot(data_analysis_2afc_prod_plot3, aes(fill=resp_suffix_form, y = proportion, x = language)) +
  geom_col(position='dodge', color='black') +
  facet_nested(condition~task) +
  theme_bw()
```

```{r}
data_analysis_2afc_prod_plot3b = data_analysis %>%
  filter(meaning_choice != 'novel') %>%
  filter(task %in% c('2afc', 'prod')) %>%
  filter(picture_meaning=='dim_pl' | stem_condition == 'familiar') %>%
  group_by(condition, task) %>%
  count(freq_choice) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_2afc_prod_plot2, aes(fill=freq_choice, y = proportion, x = factor(condition))) +
  geom_col(position='dodge', color='black') +
  facet_wrap(~task) +
  theme_bw()
```

```{r}
data_analysis_comprehension_plot1 = data_analysis_comprehension %>%
  group_by(condition, language, comprehension_suffix) %>%
  count(comprehension_response) %>%
  mutate(proportion = n / sum(n))

ggplot(data_analysis_comprehension_plot1, aes(x=comprehension_suffix, y = proportion, fill = comprehension_response)) +
  geom_col(position='dodge') +
  facet_nested(condition~language) +
  theme_bw()
```

```{r}
data_analysis_subjects_prod_plot = data_analysis %>%
  filter(task %in% c('prod')) %>%
  mutate(meaning_condition = case_when(picture_meaning == 'dim_pl' ~ 'new meaning',
                   picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original meaning (minus big_sg)')) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition) %>%
  filter(resp_suffix_form %in% c('nem', 'dan')) %>%
  count(resp_suffix_form, .drop = F) %>%
  ungroup() %>%
  complete(participant, meaning_condition, resp_suffix_form, fill = list(n = 0)) %>%
  group_by(participant) %>%
  mutate(condition = ifelse(is.na(condition), 
                            unique(condition[!is.na(condition)]),
                            condition)) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition, resp_suffix_form) %>%
  summarize(total_value = sum(n, na.rm = T)) %>%
  summarize(proportion = total_value[resp_suffix_form=='dan'] / (total_value[resp_suffix_form=='dan'] + total_value[resp_suffix_form=='nem']))

data_analysis_subjects_prod_plot = data_analysis_subjects_prod_plot %>%
  pivot_wider(names_from = meaning_condition, values_from = proportion)

p1 = ggplot(data_analysis_subjects_prod_plot, aes(x=`new meaning`, y = `original meaning (minus big_sg)`)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) +
  facet_wrap(~condition) +
  theme_bw() +
  ggtitle('dan vs nem')
```

```{r}
data_analysis_subjects_prod_plot2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  mutate(meaning_condition = case_when(picture_meaning == 'dim_pl' ~ 'new meaning',
                   picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original meaning (minus big_sg)')) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition) %>%
  filter(resp_suffix_form %in% c('sil', 'shoon')) %>%
  count(resp_suffix_form, .drop = F) %>%
  ungroup() %>%
  complete(participant, meaning_condition, resp_suffix_form, fill = list(n = 0)) %>%
  group_by(participant) %>%
  mutate(condition = ifelse(is.na(condition), 
                            unique(condition[!is.na(condition)]),
                            condition)) %>%
  ungroup() %>%
  group_by(participant, condition, meaning_condition, resp_suffix_form) %>%
  summarize(total_value = sum(n, na.rm = T)) %>%
  summarize(proportion = total_value[resp_suffix_form=='sil'] / (total_value[resp_suffix_form=='sil'] + total_value[resp_suffix_form=='shoon']))

data_analysis_subjects_prod_plot2 = data_analysis_subjects_prod_plot2 %>%
  pivot_wider(names_from = meaning_condition, values_from = proportion)

p2 = ggplot(data_analysis_subjects_prod_plot2, aes(x=`new meaning`, y = `original meaning (minus big_sg)`)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) + 
  facet_wrap(~condition) +
  theme_bw() +
  ggtitle('sil vs shoon')
```

```{r}
library(ggpubr)
ggarrange(p1, p2, nrow = 2)
```

```{r}
data_analysis_subjects_prod_plot3 = data_analysis %>%
  filter(task %in% c('prod')) %>% 
  ungroup() %>%
  group_by(participant, language, condition, picture_meaning) %>%
  count(resp_suffix_form, .drop = F) %>%
  ungroup() %>%
  complete(participant, language, condition, picture_meaning, resp_suffix_form, fill = list(n = 0)) %>%
  group_by(participant) %>%
  mutate(condition = ifelse(is.na(condition), 
                            unique(condition[!is.na(condition)]),
                            condition)) %>%
  ungroup() %>%
  group_by(participant, language, condition, picture_meaning, resp_suffix_form) %>%
  summarize(total_value = sum(n, na.rm = T)) %>%
  summarize(proportion = case_when(
    language=='dan' & picture_meaning == 'big_pl' ~ total_value[resp_suffix_form=='sil'] / (total_value[resp_suffix_form=='sil'] + total_value[resp_suffix_form=='dan']),
    language=='dan' & picture_meaning == 'dim_pl' ~ total_value[resp_suffix_form=='sil'] / (total_value[resp_suffix_form=='sil'] + total_value[resp_suffix_form=='dan']),
    language=='nem' & picture_meaning == 'dim_sg' ~ total_value[resp_suffix_form=='shoon'] / (total_value[resp_suffix_form=='shoon'] + total_value[resp_suffix_form=='nem']),
    language == 'nem' & picture_meaning == 'dim_pl' ~ total_value[resp_suffix_form=='shoon'] / (total_value[resp_suffix_form=='shoon'] + total_value[resp_suffix_form=='nem']))) %>%
  distinct()


data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  na.omit()

length(unique(data_analysis_subjects_prod_plot3$participant))

data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  group_by(participant, language, condition, picture_meaning) %>%
  mutate('key' = case_when(
    language == 'dan' & picture_meaning == 'big_pl' ~ 'x-axis',
    language == 'nem' & picture_meaning == 'dim_sg' ~ 'x-axis',
    language == 'dan' & picture_meaning == 'dim_pl' ~ 'y-axis',
    language == 'nem' & picture_meaning == 'dim_pl' ~ 'y-axis'
  ))

data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  ungroup() %>%
  group_by(participant) %>%
  filter(n() == 2) %>%
  ungroup



data_analysis_subjects_prod_plot3 = data_analysis_subjects_prod_plot3 %>%
  group_by(participant, key) %>%  # Group by participant and axis type
  summarize(proportion = sum(proportion), .groups = 'drop') %>%  # Sum proportions within each group
  pivot_wider(
    names_from = key,   # Create separate columns for x-axis and y-axis
    values_from = proportion,    # Use proportion values for the new columns
    values_fill = list(proportion = 0)  # Fill missing values with 0
  )

p3 = ggplot(data_analysis_subjects_prod_plot3, aes(x=`x-axis`, y = `y-axis`)) +
  geom_point() +
  geom_smooth(method='lm', formula= y~x) + 
  #facet_wrap(~condition) +
  theme_bw() #+
  #ggtitle('sil vs shoon')

p3
```

### Plot for paper

#### Models for Plots

##### Production

```{r eval = F}
options(contrasts = c("contr.sum","contr.sum"))
data_analysis$condition = factor(data_analysis$condition)


original_meaning_freq_prod_data_cond1 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_freq_prod_data_cond1 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) #freq, infreq, freq_competitor, infrequent_competitor


original_meaning_infreq_prod_data_cond1 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_prod_data_cond1 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))



original_meaning_freq_prod_data_cond1_subj_means = original_meaning_freq_prod_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_prod_model_cond1')

novel_meaning_freq_prod_data_cond1_subj_means = novel_meaning_freq_prod_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_prod_model_cond1')


original_meaning_infreq_prod_data_cond1_subj_means = original_meaning_infreq_prod_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_prod_model_cond1')

novel_meaning_infreq_prod_data_cond1_subj_means = novel_meaning_infreq_prod_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_prod_model_cond1')


####cond2

original_meaning_freq_prod_data_cond2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_prod_data_cond2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_prod_data_cond2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_prod_data_cond2 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))



original_meaning_freq_prod_data_cond2_subj_means = original_meaning_freq_prod_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_prod_model_cond2')

novel_meaning_freq_prod_data_cond2_subj_means = novel_meaning_freq_prod_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_prod_model_cond2')


original_meaning_infreq_prod_data_cond2_subj_means = original_meaning_infreq_prod_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_prod_model_cond2')

novel_meaning_infreq_prod_data_cond2_subj_means = novel_meaning_infreq_prod_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_prod_model_cond2')

#### cond3

original_meaning_freq_prod_data_cond3 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_prod_data_cond3 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_prod_data_cond3 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_prod_data_cond3 = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))




original_meaning_freq_prod_data_cond3_subj_means = original_meaning_freq_prod_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_prod_model_cond3')

novel_meaning_freq_prod_data_cond3_subj_means = novel_meaning_freq_prod_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_prod_model_cond3')


original_meaning_infreq_prod_data_cond3_subj_means = original_meaning_infreq_prod_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_prod_model_cond3')

novel_meaning_infreq_prod_data_cond3_subj_means = novel_meaning_infreq_prod_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_prod_model_cond3')



### models

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_freq_prod_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond1'
                                                                     )

novel_meaning_freq_prod_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond1'
                                                                     )

original_meaning_infreq_prod_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond1'
                                                                     )

novel_meaning_infreq_prod_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond1'
                                                                     )


#### cond2


original_meaning_freq_prod_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond2'
                                                                     )

novel_meaning_freq_prod_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       #prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond2'
                                                                     )

original_meaning_infreq_prod_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond2'
                                                                     )

novel_meaning_infreq_prod_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond2'
                                                                     )

#### cond3


original_meaning_freq_prod_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond3'
                                                                     )

novel_meaning_freq_prod_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond3'
                                                                     )

original_meaning_infreq_prod_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond3'
                                                                     )

novel_meaning_infreq_prod_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond3'
                                                                     )



model_names = c('original_meaning_freq_prod_model_cond1', 'novel_meaning_freq_prod_model_cond1', 'original_meaning_infreq_prod_model_cond1', 'novel_meaning_infreq_prod_model_cond1', 'original_meaning_freq_prod_model_cond2', 'novel_meaning_freq_prod_model_cond2', 'original_meaning_infreq_prod_model_cond2', 'novel_meaning_infreq_prod_model_cond2', 'original_meaning_freq_prod_model_cond3', 'novel_meaning_freq_prod_model_cond3', 'original_meaning_infreq_prod_model_cond3', 'novel_meaning_infreq_prod_model_cond3')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df = fixed_effects_df %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  dplyr::select(-ignore1, -ignore2)  # Remove the unnecessary columns


subj_effect_names = ls(pattern = "_subj_means$")
subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')

subject_effects = subject_effects %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2) 

subject_effects_prod = subject_effects %>%  # Remove the unnecessary columns 
  filter(Task == 'prod')

ggplot(fixed_effects_df, aes(x = Meaning, y = Prob, fill = Frequency)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_prod, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('Production') +
  xlab('Condition') +
  ylab('Probability of Producing a Form') +
  ylim(0, 1)



```

##### 2afc

```{r eval = F}

options(contrasts = c("contr.sum","contr.sum"))
data_analysis$condition = factor(data_analysis$condition)

original_meaning_freq_2afc_data_cond1 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_2afc_data_cond1 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_2afc_data_cond1 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_2afc_data_cond1 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))





original_meaning_freq_2afc_data_cond1_subj_means = original_meaning_freq_2afc_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_2afc_model_cond1')

novel_meaning_freq_2afc_data_cond1_subj_means = novel_meaning_freq_2afc_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_2afc_model_cond1')


original_meaning_infreq_2afc_data_cond1_subj_means = original_meaning_infreq_2afc_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_2afc_model_cond1')

novel_meaning_infreq_2afc_data_cond1_subj_means = novel_meaning_infreq_2afc_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_2afc_model_cond1')




####cond2

original_meaning_freq_2afc_data_cond2 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_2afc_data_cond2 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_2afc_data_cond2 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_2afc_data_cond2 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))



original_meaning_freq_2afc_data_cond2_subj_means = original_meaning_freq_2afc_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_2afc_model_cond2')

novel_meaning_freq_2afc_data_cond2_subj_means = novel_meaning_freq_2afc_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_2afc_model_cond2')


original_meaning_infreq_2afc_data_cond2_subj_means = original_meaning_infreq_2afc_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_2afc_model_cond2')

novel_meaning_infreq_2afc_data_cond2_subj_means = novel_meaning_infreq_2afc_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_2afc_model_cond2')




#### cond3

original_meaning_freq_2afc_data_cond3 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_2afc_data_cond3 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_2afc_data_cond3 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_2afc_data_cond3 = data_analysis %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))




original_meaning_freq_2afc_data_cond3_subj_means = original_meaning_freq_2afc_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_2afc_model_cond3')

novel_meaning_freq_2afc_data_cond3_subj_means = novel_meaning_freq_2afc_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_2afc_model_cond3')


original_meaning_infreq_2afc_data_cond3_subj_means = original_meaning_infreq_2afc_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_2afc_model_cond3')

novel_meaning_infreq_2afc_data_cond3_subj_means = novel_meaning_infreq_2afc_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_2afc_model_cond3')




### models

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_freq_2afc_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_2afc_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_2afc_model_cond1'
                                                                     )

novel_meaning_freq_2afc_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_2afc_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_2afc_model_cond1'
                                                                     )

original_meaning_infreq_2afc_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_2afc_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_2afc_model_cond1'
                                                                     )

novel_meaning_infreq_2afc_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_2afc_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_2afc_model_cond1'
                                                                     )


#### cond2


original_meaning_freq_2afc_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_2afc_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_2afc_model_cond2'
                                                                     )

novel_meaning_freq_2afc_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_2afc_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       #prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_2afc_model_cond2'
                                                                     )

original_meaning_infreq_2afc_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_2afc_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_2afc_model_cond2'
                                                                     )

novel_meaning_infreq_2afc_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_2afc_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_2afc_model_cond2'
                                                                     )

#### cond3


original_meaning_freq_2afc_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_2afc_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_2afc_model_cond3'
                                                                     )

novel_meaning_freq_2afc_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_2afc_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_2afc_model_cond3'
                                                                     )

original_meaning_infreq_2afc_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_2afc_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_2afc_model_cond3'
                                                                     )

novel_meaning_infreq_2afc_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_2afc_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_2afc_model_cond3'
                                                                     )



model_names = c('original_meaning_freq_2afc_model_cond1', 'novel_meaning_freq_2afc_model_cond1', 'original_meaning_infreq_2afc_model_cond1', 'novel_meaning_infreq_2afc_model_cond1', 'original_meaning_freq_2afc_model_cond2', 'novel_meaning_freq_2afc_model_cond2', 'original_meaning_infreq_2afc_model_cond2', 'novel_meaning_infreq_2afc_model_cond2', 'original_meaning_freq_2afc_model_cond3', 'novel_meaning_freq_2afc_model_cond3', 'original_meaning_infreq_2afc_model_cond3', 'novel_meaning_infreq_2afc_model_cond3')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df_2afc = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df_2afc = fixed_effects_df_2afc %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2)  # Remove the unnecessary columns



subj_effect_names = ls(pattern = "_subj_means$")
subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')

subject_effects = subject_effects %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2) 

subject_effects_2afc = subject_effects %>%
  filter(Task == '2afc')

ggplot(fixed_effects_df_2afc, aes(x = Meaning, y = Prob, fill = Frequency)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_2afc, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('2afc') +
  xlab('Condition') +
  ylab('Probability of Producing a Form') +
  ylim(0, 1)

```

##### Comprehension

```{r eval = F}
options(contrasts = c("contr.sum","contr.sum"))
data_analysis_comprehension$condition = factor(data_analysis_comprehension$condition)
data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(freq_suffix = case_when(
    language == 'dan' & comprehension_suffix == 'dan' ~ 'freq',
    language == 'nem' & comprehension_suffix == 'nem' ~ 'freq',
    .default = 'infreq'
  )) %>%
  mutate(original_meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'big_pl' ~ 1,
    comprehension_suffix == 'nem' & comprehension_response == 'dim_sg' ~ 1,
    .default = 0
  )) %>%
  mutate(novel_meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'dim_pl' ~ 1,
    comprehension_suffix == 'nem' & comprehension_response == 'dim_pl' ~ 1,
    .default = 0
  )) %>%
  filter(novel_meaning == 1 | original_meaning == 1)

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(resp_stem = str_remove(comprehension_label, comprehension_suffix))

original_meaning_freq_comprehension_data_cond1 = data_analysis_comprehension %>%
  filter(freq_suffix == 'freq' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0)) 

novel_meaning_freq_comprehension_data_cond1 = data_analysis_comprehension %>%
  filter(freq_suffix == 'freq' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))

original_meaning_infreq_comprehension_data_cond1 = data_analysis_comprehension %>%
  filter(freq_suffix == 'infreq' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_infreq_comprehension_data_cond1 = data_analysis_comprehension %>%
  filter(freq_suffix == 'infreq' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))


original_meaning_freq_comprehension_data_cond1_subj_means = original_meaning_freq_comprehension_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_comprehension_model_cond1')

novel_meaning_freq_comprehension_data_cond1_subj_means = novel_meaning_freq_comprehension_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_comprehension_model_cond1')


original_meaning_infreq_comprehension_data_cond1_subj_means = original_meaning_infreq_comprehension_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_comprehension_model_cond1')

novel_meaning_infreq_comprehension_data_cond1_subj_means = novel_meaning_infreq_comprehension_data_cond1 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_comprehension_model_cond1')

####cond2


original_meaning_freq_comprehension_data_cond2 = data_analysis_comprehension %>%
  filter(freq_suffix == 'freq' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_freq_comprehension_data_cond2 = data_analysis_comprehension %>%
  filter(freq_suffix == 'freq' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))

original_meaning_infreq_comprehension_data_cond2 = data_analysis_comprehension %>%
  filter(freq_suffix == 'infreq' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_infreq_comprehension_data_cond2 = data_analysis_comprehension %>%
  filter(freq_suffix == 'infreq' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))



original_meaning_freq_comprehension_data_cond2_subj_means = original_meaning_freq_comprehension_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_comprehension_model_cond2')

novel_meaning_freq_comprehension_data_cond2_subj_means = novel_meaning_freq_comprehension_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_comprehension_model_cond2')


original_meaning_infreq_comprehension_data_cond2_subj_means = original_meaning_infreq_comprehension_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_comprehension_model_cond2')

novel_meaning_infreq_comprehension_data_cond2_subj_means = novel_meaning_infreq_comprehension_data_cond2 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_comprehension_model_cond2')


#### cond3

original_meaning_freq_comprehension_data_cond3 = data_analysis_comprehension %>%
  filter(freq_suffix == 'freq' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_freq_comprehension_data_cond3 = data_analysis_comprehension %>%
  filter(freq_suffix == 'freq' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))

original_meaning_infreq_comprehension_data_cond3 = data_analysis_comprehension %>%
  filter(freq_suffix == 'infreq' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_infreq_comprehension_data_cond3 = data_analysis_comprehension %>%
  filter(freq_suffix == 'infreq' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))



original_meaning_freq_comprehension_data_cond3_subj_means = original_meaning_freq_comprehension_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_comprehension_model_cond3')

novel_meaning_freq_comprehension_data_cond3_subj_means = novel_meaning_freq_comprehension_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_comprehension_model_cond3')


original_meaning_infreq_comprehension_data_cond3_subj_means = original_meaning_infreq_comprehension_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_comprehension_model_cond3')

novel_meaning_infreq_comprehension_data_cond3_subj_means = novel_meaning_infreq_comprehension_data_cond3 %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_comprehension_model_cond3')


### models

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_freq_comprehension_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_comprehension_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_comprehension_model_cond1'
                                                                     )

novel_meaning_freq_comprehension_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_comprehension_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_comprehension_model_cond1'
                                                                     )

original_meaning_infreq_comprehension_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_comprehension_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_comprehension_model_cond1'
                                                                     )

novel_meaning_infreq_comprehension_model_cond1 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_comprehension_data_cond1,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_comprehension_model_cond1'
                                                                     )


#### cond2


original_meaning_freq_comprehension_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_comprehension_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_comprehension_model_cond2'
                                                                     )

novel_meaning_freq_comprehension_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_comprehension_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       #prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_comprehension_model_cond2'
                                                                     )

original_meaning_infreq_comprehension_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_comprehension_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_comprehension_model_cond2'
                                                                     )

novel_meaning_infreq_comprehension_model_cond2 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_comprehension_data_cond2,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_comprehension_model_cond2'
                                                                     )

#### cond3


original_meaning_freq_comprehension_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_comprehension_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_comprehension_model_cond3'
                                                                     )

novel_meaning_freq_comprehension_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_comprehension_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_comprehension_model_cond3'
                                                                     )

original_meaning_infreq_comprehension_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_comprehension_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_comprehension_model_cond3'
                                                                     )

novel_meaning_infreq_comprehension_model_cond3 = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_comprehension_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_comprehension_model_cond3'
                                                                     )



model_names = c('original_meaning_freq_comprehension_model_cond1', 'novel_meaning_freq_comprehension_model_cond1', 'original_meaning_infreq_comprehension_model_cond1', 'novel_meaning_infreq_comprehension_model_cond1', 'original_meaning_freq_comprehension_model_cond2', 'novel_meaning_freq_comprehension_model_cond2', 'original_meaning_infreq_comprehension_model_cond2', 'novel_meaning_infreq_comprehension_model_cond2', 'original_meaning_freq_comprehension_model_cond3', 'novel_meaning_freq_comprehension_model_cond3', 'original_meaning_infreq_comprehension_model_cond3', 'novel_meaning_infreq_comprehension_model_cond3')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df_comprehension = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df_comprehension = fixed_effects_df_comprehension %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2)  # Remove the unnecessary columns


subj_effect_names = ls(pattern = "_subj_means$")
subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')

subject_effects = subject_effects %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2) 

subject_effects_comprehension = subject_effects %>%
  filter(Task == 'comprehension')

ggplot(fixed_effects_df_comprehension, aes(x = Meaning, y = Prob, fill = Frequency)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_comprehension, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('Comprehension') +
  xlab('Condition') +
  ylab('Probability of Producing a Form') +
  ylim(0, 1)


```

##### Full plot

```{r eval = F}
# 
 fixed_effects_df_all = fixed_effects_df %>%
   full_join(fixed_effects_df_2afc) %>%
   full_join(fixed_effects_df_comprehension)

#write_csv(fixed_effects_df_all, '../Data/fixed_effects_df_all.csv')
#write_csv(subject_effects, '../Data/subject_effects.csv')

fixed_effects_df_all = read_csv('../Data/fixed_effects_df_all.csv')
subject_effects = read_csv('../Data/subject_effects.csv')

fixed_effects_df_all$Task = factor(fixed_effects_df_all$Task, levels = c('prod', '2afc', 'comprehension'))

subject_effects$Task = factor(subject_effects$Task, levels = c('prod', '2afc', 'comprehension'))

condition_labels = c("cond1" = "Condition 1", 
                      "cond2" = "Condition 2", 
                      "cond3" = "Condition 3")
task_labels = c("prod" = "Production",
                "2afc" = "Form Choice",
                "comprehension" = "Comprehension")

fixed_effects_df_all$Meaning = factor(fixed_effects_df_all$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

subject_effects$Meaning = factor(subject_effects$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

fixed_effects_df_all$Frequency = factor(fixed_effects_df_all$Frequency, 
                                  levels = c("freq", "infreq"), 
                                  labels = c("Frequent", "Infrequent"))

subject_effects$Frequency = factor(subject_effects$Frequency, 
                                  levels = c("freq", "infreq"), 
                                  labels = c("Frequent", "Infrequent"))


ggplot(fixed_effects_df_all, aes(x = Meaning, y = Prob, fill = Frequency)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects, 
             aes(x = Meaning, y = subj_values, fill = Frequency, color = Frequency),  # Map fill and color
             shape = 21,   # Hollow circle with fill and outline
             position = position_jitterdodge(jitter.width = 0.3, dodge.width = 0.9), 
             size = 2, stroke = 0.7, alpha = 0.1,  # Adjust size, border thickness, and transparency
             show.legend = FALSE) +  # Hides points from legend
  scale_fill_manual(values = c("Frequent" = "#66c2a5", "Infrequent" = "#8da0cb")) +  # Bar & point fill colors
  scale_color_manual(values = c("Frequent" = "#1b7837", "Infrequent" = "#2b8cbe")) +  # Darker border colors for points
  facet_grid(Task ~ Condition, labeller = labeller(Condition = condition_labels, Task = task_labels)) + 
  theme_bw() +
  ggtitle('Results by condition for each task') +
  xlab('Meaning') +
  ylab('Response Probability') +
  ylim(0, 1)
```

### sil shoon removed from prod

```{r eval = F}
options(contrasts = c("contr.sum","contr.sum"))
data_analysis$condition = factor(data_analysis$condition)

data_analysis_no_sil_shoon = data_analysis %>%
  filter(resp_suffix_form %in% c('dan', 'nem')) %>%
  mutate(meaning = case_when(
    picture_meaning %in% c('big_pl', 'dim_sg') ~ 'original',
    picture_meaning == 'dim_pl' ~ 'novel')
  )


original_meaning_freq_prod_data_cond1_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 1) %>%
  filter(meaning == 'original') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
original_meaning_infreq_prod_data_cond1_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 1) %>%
  filter(meaning == 'original') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

  
novel_meaning_freq_prod_data_cond1_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 1) %>%
  filter(meaning == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) #freq, infreq, freq_competitor, infrequent_competitor

novel_meaning_infreq_prod_data_cond1_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 1) %>%
  filter(meaning == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))



original_meaning_freq_prod_data_cond1_subj_means_no_sil_shoon = original_meaning_freq_prod_data_cond1_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_prod_model_cond1')

novel_meaning_freq_prod_data_cond1_subj_means_no_sil_shoon = novel_meaning_freq_prod_data_cond1_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_prod_model_cond1')


original_meaning_infreq_prod_data_cond1_subj_means_no_sil_shoon = original_meaning_infreq_prod_data_cond1_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_prod_model_cond1')

novel_meaning_infreq_prod_data_cond1_subj_means_no_sil_shoon = novel_meaning_infreq_prod_data_cond1_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_prod_model_cond1')


####cond2

original_meaning_freq_prod_data_cond2_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 2) %>%
  filter(meaning == 'original') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
original_meaning_infreq_prod_data_cond2_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 2) %>%
  filter(meaning == 'original') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

  
novel_meaning_freq_prod_data_cond2_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 2) %>%
  filter(meaning == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) #freq, infreq, freq_competitor, infrequent_competitor

novel_meaning_infreq_prod_data_cond2_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 2) %>%
  filter(meaning == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))




original_meaning_freq_prod_data_cond2_subj_means_no_sil_shoon = original_meaning_freq_prod_data_cond2_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_prod_model_cond2')

novel_meaning_freq_prod_data_cond2_subj_means_no_sil_shoon = novel_meaning_freq_prod_data_cond2_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_prod_model_cond2')


original_meaning_infreq_prod_data_cond2_subj_means_no_sil_shoon = original_meaning_infreq_prod_data_cond2_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_prod_model_cond2')

novel_meaning_infreq_prod_data_cond2_subj_means_no_sil_shoon = novel_meaning_infreq_prod_data_cond2_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_prod_model_cond2')

#### cond3

original_meaning_freq_prod_data_cond3_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 3) %>%
  filter(meaning == 'original') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
original_meaning_infreq_prod_data_cond3_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 3) %>%
  filter(meaning == 'original') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

  
novel_meaning_freq_prod_data_cond3_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 3) %>%
  filter(meaning == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) #freq, infreq, freq_competitor, infrequent_competitor

novel_meaning_infreq_prod_data_cond3_no_sil_shoon = data_analysis_no_sil_shoon %>%
  filter(task %in% c('prod') & condition == 3) %>%
  filter(meaning == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))



original_meaning_freq_prod_data_cond3_subj_means_no_sil_shoon = original_meaning_freq_prod_data_cond3_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_freq_prod_model_cond3')

novel_meaning_freq_prod_data_cond3_subj_means_no_sil_shoon = novel_meaning_freq_prod_data_cond3_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_freq_prod_model_cond3')


original_meaning_infreq_prod_data_cond3_subj_means_no_sil_shoon = original_meaning_infreq_prod_data_cond3_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_infreq_prod_model_cond3')

novel_meaning_infreq_prod_data_cond3_subj_means_no_sil_shoon = novel_meaning_infreq_prod_data_cond3_no_sil_shoon %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_infreq_prod_model_cond3')



### models

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_freq_prod_model_cond1_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond1_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond1_no_sil_shoon'
                                                                     )

novel_meaning_freq_prod_model_cond1_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond1_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond1_no_sil_shoon'
                                                                     )

original_meaning_infreq_prod_model_cond1_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond1_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond1_no_sil_shoon'
                                                                     )

novel_meaning_infreq_prod_model_cond1_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond1_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond1_no_sil_shoon'
                                                                     )


#### cond2


original_meaning_freq_prod_model_cond2_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond2_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond2_no_sil_shoon'
                                                                     )

novel_meaning_freq_prod_model_cond2_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond2_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       #prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond2_no_sil_shoon'
                                                                     )

original_meaning_infreq_prod_model_cond2_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond2_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond2_no_sil_shoon'
                                                                     )

novel_meaning_infreq_prod_model_cond2_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond2_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond2_no_sil_shoon'
                                                                     )

#### cond3


original_meaning_freq_prod_model_cond3_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond3_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond3_no_sil_shoon'
                                                                     )

novel_meaning_freq_prod_model_cond3_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond3,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond3_no_sil_shoon'
                                                                     )

original_meaning_infreq_prod_model_cond3_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond3_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond3_no_sil_shoon'
                                                                     )

novel_meaning_infreq_prod_model_cond3_no_sil_shoon = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond3_no_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 6000, 
                                       warmup = 3000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond3_no_sil_shoon'
                                                                     )



model_names = c('original_meaning_freq_prod_model_cond1_no_sil_shoon', 'novel_meaning_freq_prod_model_cond1_no_sil_shoon', 'original_meaning_infreq_prod_model_cond1_no_sil_shoon', 'novel_meaning_infreq_prod_model_cond1_no_sil_shoon', 'original_meaning_freq_prod_model_cond2_no_sil_shoon', 'novel_meaning_freq_prod_model_cond2_no_sil_shoon', 'original_meaning_infreq_prod_model_cond2_no_sil_shoon', 'novel_meaning_infreq_prod_model_cond2_no_sil_shoon', 'original_meaning_freq_prod_model_cond3_no_sil_shoon', 'novel_meaning_freq_prod_model_cond3_no_sil_shoon', 'original_meaning_infreq_prod_model_cond3_no_sil_shoon', 'novel_meaning_infreq_prod_model_cond3_no_sil_shoon')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df_no_sil_shoon = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df_no_sil_shoon = fixed_effects_df_no_sil_shoon %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2)  # Remove the unnecessary columns


subj_effect_names_no_sil_shoon = ls(pattern = "_subj_means_no_sil_shoon$")
subject_effects_no_sil_shoon = bind_rows(mget(subj_effect_names_no_sil_shoon), .id = 'source')

subject_effects_no_sil_shoon = subject_effects_no_sil_shoon %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2) 

subject_effects_prod_no_sil_shoon = subject_effects_no_sil_shoon %>%  # Remove the unnecessary columns 
  filter(Task == 'prod')


#write_csv(fixed_effects_df_no_sil_shoon, '../Data/fixed_effects_df_no_sil_shoon.csv')
#write_csv(subject_effects_no_sil_shoon, '../Data/subject_effects_no_sil_shoon.csv')

ggplot(fixed_effects_df_no_sil_shoon, aes(x = Meaning, y = Prob, fill = Frequency)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_prod_no_sil_shoon, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('Production') +
  xlab('Condition') +
  ylab('Probability of Producing a Form') +
  ylim(0, 1)


```

```{r eval = F}
fixed_effects_df_all_no_sil_no_shoon = fixed_effects_df_no_sil_shoon %>%
   full_join(fixed_effects_df_2afc) %>%
   full_join(fixed_effects_df_comprehension)

#write_csv(fixed_effects_df_all_no_sil_no_shoon, '../Data/fixed_effects_df_all_no_sil_no_shoon.csv')
#write_csv(subject_effects_prod_no_sil_shoon, '../Data/subject_effects_prod_no_sil_shoon.csv')

fixed_effects_df_all_no_sil_no_shoon = read_csv('../Data/fixed_effects_df_all_no_sil_no_shoon.csv')
subject_effects = read_csv('../Data/subject_effects_prod_no_sil_shoon.csv')

fixed_effects_df_all_no_sil_no_shoon$Task = factor(fixed_effects_df_all_no_sil_no_shoon$Task, levels = c('prod', '2afc', 'comprehension'))

subject_effects$Task = factor(subject_effects$Task, levels = c('prod', '2afc', 'comprehension'))

condition_labels = c("cond1" = "Condition 1", 
                      "cond2" = "Condition 2", 
                      "cond3" = "Condition 3")
task_labels = c("prod" = "Production",
                "2afc" = "Form Choice",
                "comprehension" = "Comprehension")

fixed_effects_df_all_no_sil_no_shoon$Meaning = factor(fixed_effects_df_all_no_sil_no_shoon$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

subject_effects$Meaning = factor(subject_effects$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

fixed_effects_df_all_no_sil_no_shoon$Frequency = factor(fixed_effects_df_all_no_sil_no_shoon$Frequency, 
                                  levels = c("freq", "infreq"), 
                                  labels = c("Frequent", "Infrequent"))

subject_effects$Frequency = factor(subject_effects$Frequency, 
                                  levels = c("freq", "infreq"), 
                                  labels = c("Frequent", "Infrequent"))


ggplot(fixed_effects_df_all_no_sil_no_shoon, aes(x = Meaning, y = Prob, fill = Frequency)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects, 
             aes(x = Meaning, y = subj_values, fill = Frequency, color = Frequency),  # Map fill and color
             shape = 21,   # Hollow circle with fill and outline
             position = position_jitterdodge(jitter.width = 0.3, dodge.width = 0.9), 
             size = 2, stroke = 0.7, alpha = 0.1,  # Adjust size, border thickness, and transparency
             show.legend = FALSE) +  # Hides points from legend
  scale_fill_manual(values = c("Frequent" = "#66c2a5", "Infrequent" = "#8da0cb")) +  # Bar & point fill colors
  scale_color_manual(values = c("Frequent" = "#1b7837", "Infrequent" = "#2b8cbe")) +  # Darker border colors for points
  facet_grid(Task ~ Condition, labeller = labeller(Condition = condition_labels, Task = task_labels)) + 
  theme_bw() +
  ggtitle('Results by condition for each task') +
  xlab('Meaning') +
  ylab('Response Probability') +
  ylim(0, 1)
```

# Observed Frequency Plot

```{r}
options(contrasts = c("contr.sum","contr.sum"))
data_analysis$condition = factor(data_analysis$condition)


original_meaning_freq_prod_data_cond1_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 1) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))

original_meaning_freq_prod_data_cond1_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 1) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_freq_prod_data_cond1_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) #freq, infreq, freq_competitor, infrequent_competitor

novel_meaning_freq_prod_data_cond1_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) #freq, infreq, freq_competitor, infrequent_competitor


original_meaning_infreq_prod_data_cond1_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 1) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

original_meaning_infreq_prod_data_cond1_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 1) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_prod_data_cond1_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))


novel_meaning_infreq_prod_data_cond1_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))

# 
# original_meaning_freq_prod_data_cond1_subj_means = original_meaning_freq_prod_data_cond1 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'original_meaning_freq_prod_model_cond1')
# 
# novel_meaning_freq_prod_data_cond1_subj_means = novel_meaning_freq_prod_data_cond1 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'novel_meaning_freq_prod_model_cond1')
# 
# 
# original_meaning_infreq_prod_data_cond1_subj_means = original_meaning_infreq_prod_data_cond1 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'original_meaning_infreq_prod_model_cond1')
# 
# novel_meaning_infreq_prod_data_cond1_subj_means = novel_meaning_infreq_prod_data_cond1 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'novel_meaning_infreq_prod_model_cond1')


####cond2

original_meaning_freq_prod_data_cond2_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 2) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))

original_meaning_freq_prod_data_cond2_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 2) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_prod_data_cond2_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

novel_meaning_freq_prod_data_cond2_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_prod_data_cond2_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 2) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

original_meaning_infreq_prod_data_cond2_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 2) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_prod_data_cond2_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))

novel_meaning_infreq_prod_data_cond2_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))


# original_meaning_freq_prod_data_cond2_subj_means = original_meaning_freq_prod_data_cond2 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'original_meaning_freq_prod_model_cond2')
# 
# novel_meaning_freq_prod_data_cond2_subj_means = novel_meaning_freq_prod_data_cond2 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'novel_meaning_freq_prod_model_cond2')
# 
# 
# original_meaning_infreq_prod_data_cond2_subj_means = original_meaning_infreq_prod_data_cond2 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'original_meaning_infreq_prod_model_cond2')
# 
# novel_meaning_infreq_prod_data_cond2_subj_means = novel_meaning_infreq_prod_data_cond2 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'novel_meaning_infreq_prod_model_cond2')

#### cond3

original_meaning_freq_prod_data_cond3_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))


original_meaning_freq_prod_data_cond3_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'dan' & picture_meaning == 'big_pl') | (language == 'nem' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
    
novel_meaning_freq_prod_data_cond3_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))
    
novel_meaning_freq_prod_data_cond3_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0))

original_meaning_infreq_prod_data_cond3_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

original_meaning_infreq_prod_data_cond3_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter((language == 'nem' & picture_meaning == 'big_pl') | (language == 'dan' & picture_meaning == 'dim_sg') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'infreq' ~ 1,
    .default = 0
  ))

novel_meaning_infreq_prod_data_cond3_familiar_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'familiar') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))

novel_meaning_infreq_prod_data_cond3_novel_stem = data_analysis %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  ungroup() %>%
  filter(stem_condition == 'novel') %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'infreq', 1, 0))



# original_meaning_freq_prod_data_cond3_subj_means = original_meaning_freq_prod_data_cond3 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'original_meaning_freq_prod_model_cond3')
# 
# novel_meaning_freq_prod_data_cond3_subj_means = novel_meaning_freq_prod_data_cond3 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'novel_meaning_freq_prod_model_cond3')
# 
# 
# original_meaning_infreq_prod_data_cond3_subj_means = original_meaning_infreq_prod_data_cond3 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'original_meaning_infreq_prod_model_cond3')
# 
# novel_meaning_infreq_prod_data_cond3_subj_means = novel_meaning_infreq_prod_data_cond3 %>%
#   group_by(participant) %>%
#   summarize(subj_values = mean(freq_choice_dv)) %>%
#   mutate(Model = 'novel_meaning_infreq_prod_model_cond3')
# 
# 

### models

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_freq_prod_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond1_familiar_stem')

original_meaning_freq_prod_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond1_novel_stem')

novel_meaning_freq_prod_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond1_familiar_stem'
                                                                     )

novel_meaning_freq_prod_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond1_novel_stem'
                                                                     )

original_meaning_infreq_prod_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond1_familiar_stem'
                                                                     )

original_meaning_infreq_prod_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond1_novel_stem'
                                                                     )

novel_meaning_infreq_prod_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond1_familiar_stem'
                                                                     )

novel_meaning_infreq_prod_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond1_novel_stem'
                                                                     )


#### cond2


original_meaning_freq_prod_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond2_familiar_stem'
                                                                     )


original_meaning_freq_prod_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond2_novel_stem'
                                                                     )

novel_meaning_freq_prod_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond2_familiar_stem'
                                                                     )


novel_meaning_freq_prod_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond2_novel_stem'
                                                                     )

original_meaning_infreq_prod_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond2_familiar_stem'
                                                                     )

original_meaning_infreq_prod_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond2_novel_stem'
                                                                     )
novel_meaning_infreq_prod_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 20000, 
                                       warmup = 10000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond2_familiar_stem'
                                                                     )

novel_meaning_infreq_prod_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond2_novel_stem'
                                                                     )

#### cond3


original_meaning_freq_prod_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond3_familiar_stem'
                                                                     )

original_meaning_freq_prod_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_freq_prod_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_freq_prod_model_cond3_novel_stem'
                                                                     )

novel_meaning_freq_prod_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond3_familiar_stem'
                                                                     )

novel_meaning_freq_prod_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_freq_prod_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_freq_prod_model_cond3_novel_stem'
                                                                     )

original_meaning_infreq_prod_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond3_familiar_stem'
                                                                     )

original_meaning_infreq_prod_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_infreq_prod_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_infreq_prod_model_cond3_novel_stem'
                                                                     )

novel_meaning_infreq_prod_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond3_familiar_stem'
                                                                     )

novel_meaning_infreq_prod_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_infreq_prod_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_infreq_prod_model_cond3_novel_stem'
                                                                     )



model_names = c(
'original_meaning_freq_prod_model_cond1_familiar_stem', 'novel_meaning_freq_prod_model_cond1_familiar_stem', 'original_meaning_infreq_prod_model_cond1_familiar_stem', 'novel_meaning_infreq_prod_model_cond1_familiar_stem', 'original_meaning_freq_prod_model_cond2_familiar_stem', 'novel_meaning_freq_prod_model_cond2_familiar_stem', 'original_meaning_infreq_prod_model_cond2_familiar_stem', 'novel_meaning_infreq_prod_model_cond2_familiar_stem', 'original_meaning_freq_prod_model_cond3_familiar_stem', 'novel_meaning_freq_prod_model_cond3_familiar_stem', 'original_meaning_infreq_prod_model_cond3_familiar_stem', 'novel_meaning_infreq_prod_model_cond3_familiar_stem', 'original_meaning_freq_prod_model_cond1_novel_stem', 
'novel_meaning_freq_prod_model_cond1_novel_stem', 'original_meaning_infreq_prod_model_cond1_novel_stem', 'novel_meaning_infreq_prod_model_cond1_novel_stem', 'original_meaning_freq_prod_model_cond2_novel_stem', 
'novel_meaning_freq_prod_model_cond2_novel_stem', 'original_meaning_infreq_prod_model_cond2_novel_stem', 'novel_meaning_infreq_prod_model_cond2_novel_stem', 'original_meaning_freq_prod_model_cond3_novel_stem', 
'novel_meaning_freq_prod_model_cond3_novel_stem', 'original_meaning_infreq_prod_model_cond3_novel_stem', 'novel_meaning_infreq_prod_model_cond3_novel_stem')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df = fixed_effects_df %>%
  separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition", "Stem", "ignore3"), sep = "_", remove = FALSE) %>%
  dplyr::select(-ignore1, -ignore2, -ignore3)  # Remove the unnecessary columns


# subj_effect_names = ls(pattern = "_subj_means$")
# subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')
# 
# subject_effects = subject_effects %>%
#   separate(Model, into = c("Meaning", "ignore1", "Frequency", "Task", "ignore2", "Condition"), sep = "_", remove = FALSE) %>%
#   select(-ignore1, -ignore2) 
# 
# subject_effects_prod = subject_effects %>%  # Remove the unnecessary columns 
#   filter(Task == 'prod')

#write_csv(fixed_effects_df, '../Data/fixed_effects_df.csv')

# ggplot(fixed_effects_df, aes(x = Meaning, y = Prob, fill = Frequency)) +
#   geom_col(position = position_dodge(width = 0.9)) + 
#   geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
#   geom_point(data = subject_effects_prod, 
#              aes(x = Meaning, y = subj_values),  
#              color = "black",  
#              position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
#              size = 2, alpha = 0.2, 
#              show.legend = FALSE) +  # Hides the points from the legend
#   facet_grid(~ Condition) + 
#   theme_bw() +
#   ggtitle('Production') +
#   xlab('Condition') +
#   ylab('Probability of Producing a Form') +
#   ylim(0, 1)


```

# Fixing Plot

## Prod

```{r}

options(contrasts = c("contr.treatment","contr.treatment"))
data_analysis$condition = factor(data_analysis$condition)


data_analysis_plot = data_analysis %>%
  filter(resp_suffix_form %in% c('dan', 'nem')) %>%
  filter((accuracy == 1) %>% replace_na(TRUE))


### C1

original_meaning_prod_data_cond1_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 1) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_prod_data_cond1_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 



original_meaning_prod_data_cond1_novel_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 1) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_prod_data_cond1_novel_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 






original_meaning_prod_data_cond1_familiar_stem_subj_means = original_meaning_prod_data_cond1_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_prod_data_cond1_familiar_stem')

novel_meaning_prod_data_cond1_familiar_stem_subj_means = novel_meaning_prod_data_cond1_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_prod_data_cond1_familiar_stem')

original_meaning_prod_data_cond1_novel_stem_subj_means = original_meaning_prod_data_cond1_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_prod_data_cond1_novel_stem')

novel_meaning_prod_data_cond1_novel_stem_subj_means = novel_meaning_prod_data_cond1_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_prod_data_cond1_novel_stem')


### C2

original_meaning_prod_data_cond2_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 2) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_prod_data_cond2_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 



original_meaning_prod_data_cond2_novel_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 2) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_prod_data_cond2_novel_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 






original_meaning_prod_data_cond2_familiar_stem_subj_means = original_meaning_prod_data_cond2_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_prod_data_cond2_familiar_stem')

novel_meaning_prod_data_cond2_familiar_stem_subj_means = novel_meaning_prod_data_cond2_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_prod_data_cond2_familiar_stem')

original_meaning_prod_data_cond2_novel_stem_subj_means = original_meaning_prod_data_cond2_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_prod_data_cond2_novel_stem')

novel_meaning_prod_data_cond2_novel_stem_subj_means = novel_meaning_prod_data_cond2_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_prod_data_cond2_novel_stem')



### C3

original_meaning_prod_data_cond3_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 3) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_prod_data_cond3_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 



original_meaning_prod_data_cond3_novel_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 3) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_prod_data_cond3_novel_stem = data_analysis_plot %>%
  filter(task %in% c('prod')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 






original_meaning_prod_data_cond3_familiar_stem_subj_means = original_meaning_prod_data_cond3_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_prod_data_cond3_familiar_stem')

novel_meaning_prod_data_cond3_familiar_stem_subj_means = novel_meaning_prod_data_cond3_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_prod_data_cond3_familiar_stem')

original_meaning_prod_data_cond3_novel_stem_subj_means = original_meaning_prod_data_cond3_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_prod_data_cond3_novel_stem')

novel_meaning_prod_data_cond3_novel_stem_subj_means = novel_meaning_prod_data_cond3_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_prod_data_cond3_novel_stem')



###############################
#Models
#################################



priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_prod_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_prod_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_prod_data_cond1_familiar_stem'
                                                                     )

novel_meaning_prod_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_prod_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_prod_data_cond1_familiar_stem'
                                                                     )

original_meaning_prod_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_prod_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_prod_data_cond1_novel_stem'
                                                                     )

novel_meaning_prod_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_prod_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_prod_data_cond1_novel_stem'
                                                                     )


###cond 2

original_meaning_prod_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_prod_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_prod_data_cond2_familiar_stem'
                                                                     )

novel_meaning_prod_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_prod_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_prod_data_cond2_familiar_stem'
                                                                     )

original_meaning_prod_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_prod_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_prod_data_cond2_novel_stem'
                                                                     )

novel_meaning_prod_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_prod_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_prod_data_cond2_novel_stem'
                                                                     )


###cond 3

original_meaning_prod_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_prod_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_prod_data_cond3_familiar_stem'
                                                                     )

novel_meaning_prod_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_prod_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_prod_data_cond3_familiar_stem'
                                                                     )

original_meaning_prod_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_prod_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_prod_data_cond3_novel_stem'
                                                                     )

novel_meaning_prod_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_prod_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_prod_data_cond3_novel_stem'
       
                                                              )





### Plot



model_names = c('original_meaning_prod_model_cond1_familiar_stem',
                'novel_meaning_prod_model_cond1_familiar_stem',
                'original_meaning_prod_model_cond1_novel_stem',
                'novel_meaning_prod_model_cond1_novel_stem',
                'original_meaning_prod_model_cond2_familiar_stem',
                'novel_meaning_prod_model_cond2_familiar_stem',
                'original_meaning_prod_model_cond2_novel_stem',
                'novel_meaning_prod_model_cond2_novel_stem',
                'original_meaning_prod_model_cond3_familiar_stem',
                'novel_meaning_prod_model_cond3_familiar_stem',
                'original_meaning_prod_model_cond3_novel_stem',
                'novel_meaning_prod_model_cond3_novel_stem')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df = fixed_effects_df %>%
  separate(Model, into = c("Meaning", "ignore1", "Task", "ignore2", "Condition", 'Stem', 'ignore3'), sep = "_", remove = FALSE) %>%
  dplyr::select(-ignore1, -ignore2, -ignore3)  # Remove the unnecessary columns


subj_effect_names = ls(pattern = "_subj_means$")
subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')

subject_effects = subject_effects %>%
  separate(Model, into = c("Meaning", "ignore1", "Task", "ignore2", "Condition", 'Stem', 'ignore3'), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2, -ignore3) 

subject_effects_prod = subject_effects %>%  # Remove the unnecessary columns 
  filter(Task == 'prod')

ggplot(fixed_effects_df, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_prod, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('Production') +
  xlab('Meaning') +
  ylab('Probability of Producing the Frequent Suffix') +
  ylim(0, 1)

```

## 2afc

```{r}
#options(contrasts = c("contr.sum","contr.sum"))

### C1

original_meaning_2afc_data_cond1_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 1) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_2afc_data_cond1_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 



original_meaning_2afc_data_cond1_novel_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 1) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_2afc_data_cond1_novel_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 1) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 






original_meaning_2afc_data_cond1_familiar_stem_subj_means = original_meaning_2afc_data_cond1_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_2afc_data_cond1_familiar_stem')

novel_meaning_2afc_data_cond1_familiar_stem_subj_means = novel_meaning_2afc_data_cond1_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_2afc_data_cond1_familiar_stem_subj_means')

original_meaning_2afc_data_cond1_novel_stem_subj_means = original_meaning_2afc_data_cond1_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_2afc_data_cond1_novel_stem')

novel_meaning_2afc_data_cond1_novel_stem_subj_means = novel_meaning_2afc_data_cond1_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_2afc_data_cond1_novel_stem')


### C2

original_meaning_2afc_data_cond2_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 2) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_2afc_data_cond2_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 



original_meaning_2afc_data_cond2_novel_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 2) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_2afc_data_cond2_novel_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 2) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 






original_meaning_2afc_data_cond2_familiar_stem_subj_means = original_meaning_2afc_data_cond2_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_2afc_data_cond2_familiar_stem')

novel_meaning_2afc_data_cond2_familiar_stem_subj_means = novel_meaning_2afc_data_cond2_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_2afc_data_cond2_familiar_stem')

original_meaning_2afc_data_cond2_novel_stem_subj_means = original_meaning_2afc_data_cond2_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_2afc_data_cond2_novel_stem')

novel_meaning_2afc_data_cond2_novel_stem_subj_means = novel_meaning_2afc_data_cond2_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_2afc_data_cond2_novel_stem')



### C3

original_meaning_2afc_data_cond3_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 3) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_2afc_data_cond3_familiar_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  filter(stem_condition == 'familiar') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 



original_meaning_2afc_data_cond3_novel_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter((picture_meaning == 'big_pl') | (picture_meaning == 'dim_sg')) %>%
  filter(condition == 3) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = case_when(
    freq_choice == 'freq' ~ 1,
    .default = 0
  ))
  
  
novel_meaning_2afc_data_cond3_novel_stem = data_analysis_plot %>%
  filter(task %in% c('2afc')) %>%
  filter(picture_meaning %in% c('dim_pl') & condition == 3) %>%
  filter(stem_condition == 'novel') %>%
  ungroup() %>%
  mutate(freq_choice_dv = ifelse(freq_choice == 'freq', 1, 0)) 






original_meaning_2afc_data_cond3_familiar_stem_subj_means = original_meaning_2afc_data_cond3_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_2afc_data_cond3_familiar_stem')

novel_meaning_2afc_data_cond3_familiar_stem_subj_means = novel_meaning_2afc_data_cond3_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_2afc_data_cond3_familiar_stem')

original_meaning_2afc_data_cond3_novel_stem_subj_means = original_meaning_2afc_data_cond3_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_2afc_data_cond3_novel_stem')

novel_meaning_2afc_data_cond3_novel_stem_subj_means = novel_meaning_2afc_data_cond3_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_2afc_data_cond3_novel_stem')



###############################
#Models
#################################



priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'sd'))
  
###cond 1

original_meaning_2afc_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_2afc_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_2afc_data_cond1_familiar_stem'
                                                                     )

novel_meaning_2afc_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_2afc_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_2afc_data_cond1_familiar_stem'
                                                                     )

original_meaning_2afc_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_2afc_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_2afc_data_cond1_novel_stem'
                                                                     )

novel_meaning_2afc_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_2afc_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_2afc_data_cond1_novel_stem'
                                                                     )


###cond 2

original_meaning_2afc_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_2afc_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_2afc_data_cond2_familiar_stem'
                                                                     )

novel_meaning_2afc_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_2afc_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_2afc_data_cond2_familiar_stem'
                                                                     )

original_meaning_2afc_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_2afc_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_2afc_data_cond2_novel_stem'
                                                                     )

novel_meaning_2afc_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_2afc_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_2afc_data_cond2_novel_stem'
                                                                     )


###cond 3

original_meaning_2afc_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_2afc_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_2afc_data_cond3_familiar_stem'
                                                                     )

novel_meaning_2afc_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_2afc_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_2afc_data_cond3_familiar_stem'
                                                                     )

original_meaning_2afc_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_2afc_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_2afc_data_cond3_novel_stem'
                                                                     )

novel_meaning_2afc_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_2afc_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 12000, 
                                       warmup = 6000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_2afc_data_cond3_novel_stem'
       
                                                              )





### Plot



model_names = c('original_meaning_2afc_model_cond1_familiar_stem',
                'novel_meaning_2afc_model_cond1_familiar_stem',
                'original_meaning_2afc_model_cond1_novel_stem',
                'novel_meaning_2afc_model_cond1_novel_stem',
                'original_meaning_2afc_model_cond2_familiar_stem',
                'novel_meaning_2afc_model_cond2_familiar_stem',
                'original_meaning_2afc_model_cond2_novel_stem',
                'novel_meaning_2afc_model_cond2_novel_stem',
                'original_meaning_2afc_model_cond3_familiar_stem',
                'novel_meaning_2afc_model_cond3_familiar_stem',
                'original_meaning_2afc_model_cond3_novel_stem',
                'novel_meaning_2afc_model_cond3_novel_stem')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df_2afc = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df_2afc = fixed_effects_df_2afc %>%
  separate(Model, into = c("Meaning", "ignore1", "Task", "ignore2", "Condition", 'Stem', 'ignore3'), sep = "_", remove = FALSE) %>%
  dplyr::select(-ignore1, -ignore2, -ignore3)  # Remove the unnecessary columns


subj_effect_names = ls(pattern = "_subj_means$")
subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')

subject_effects = subject_effects %>%
  separate(Model, into = c("Meaning", "ignore1", "Task", "ignore2", "Condition", 'Stem', 'ignore3'), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2, -ignore3) 

subject_effects_2afc = subject_effects %>%  # Remove the unnecessary columns 
  filter(Task == '2afc')

ggplot(fixed_effects_df_2afc, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_2afc, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('Forced-Choice Task') +
  xlab('Meaning') +
  ylab('Probability of Producing the Frequent Suffix') +
  ylim(0, 1)

```

## Comprehension

```{r}
options(contrasts = c("contr.sum","contr.sum"))
data_analysis_comprehension$condition = factor(data_analysis_comprehension$condition)
data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(freq_suffix = case_when(
    language == 'dan' & comprehension_suffix == 'dan' ~ 'freq',
    language == 'nem' & comprehension_suffix == 'nem' ~ 'freq',
    .default = 'infreq'
  )) %>%
  mutate(original_meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'big_pl' ~ 1,
    comprehension_suffix == 'nem' & comprehension_response == 'dim_sg' ~ 1,
    .default = 0
  )) %>%
  mutate(novel_meaning = case_when(
    comprehension_suffix == 'dan' & comprehension_response == 'dim_pl' ~ 1,
    comprehension_suffix == 'nem' & comprehension_response == 'dim_pl' ~ 1,
    .default = 0
  )) %>%
  filter(novel_meaning == 1 | original_meaning == 1)


data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(resp_stem = str_remove(comprehension_label, comprehension_suffix))

### Cond1

original_meaning_comprehension_data_cond1_familiar_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'familiar' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0)) 

novel_meaning_comprehension_data_cond1_familiar_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'familiar' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))

original_meaning_comprehension_data_cond1_novel_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'novel' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_comprehension_data_cond1_novel_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'novel' & condition == 1) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))


original_meaning_comprehension_data_cond1_familiar_stem_subj_means = original_meaning_comprehension_data_cond1_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_comprehension_data_cond1_familiar_stem')

novel_meaning_comprehension_data_cond1_familiar_stem_subj_means = novel_meaning_comprehension_data_cond1_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_comprehension_data_cond1_familiar_stem')


original_meaning_comprehension_data_cond1_novel_stem_subj_means = original_meaning_comprehension_data_cond1_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_comprehension_data_cond1_novel_stem')

novel_meaning_comprehension_data_cond1_novel_stem_subj_means = novel_meaning_comprehension_data_cond1_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_comprehension_data_cond1_novel_stem')





### Cond2

original_meaning_comprehension_data_cond2_familiar_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'familiar' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0)) 

novel_meaning_comprehension_data_cond2_familiar_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'familiar' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))

original_meaning_comprehension_data_cond2_novel_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'novel' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_comprehension_data_cond2_novel_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'novel' & condition == 2) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))


original_meaning_comprehension_data_cond2_familiar_stem_subj_means = original_meaning_comprehension_data_cond2_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_comprehension_data_cond2_familiar_stem')

novel_meaning_comprehension_data_cond2_familiar_stem_subj_means = novel_meaning_comprehension_data_cond2_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_comprehension_data_cond2_familiar_stem')


original_meaning_comprehension_data_cond2_novel_stem_subj_means = original_meaning_comprehension_data_cond2_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_comprehension_data_cond2_novel_stem')

novel_meaning_comprehension_data_cond2_novel_stem_subj_means = novel_meaning_comprehension_data_cond2_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_comprehension_data_cond2_novel_stem')





### Cond3

original_meaning_comprehension_data_cond3_familiar_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'familiar' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0)) 

novel_meaning_comprehension_data_cond3_familiar_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'familiar' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))

original_meaning_comprehension_data_cond3_novel_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'novel' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(original_meaning == 1, 1, 0))
    
novel_meaning_comprehension_data_cond3_novel_stem = data_analysis_comprehension %>%
  filter(stem_condition == 'novel' & condition == 3) %>%
  mutate(freq_choice_dv = ifelse(novel_meaning == 1, 1, 0))


original_meaning_comprehension_data_cond3_familiar_stem_subj_means = original_meaning_comprehension_data_cond3_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_comprehension_data_cond3_familiar_stem')

novel_meaning_comprehension_data_cond3_familiar_stem_subj_means = novel_meaning_comprehension_data_cond3_familiar_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_comprehension_data_cond3_familiar_stem')


original_meaning_comprehension_data_cond3_novel_stem_subj_means = original_meaning_comprehension_data_cond3_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'original_meaning_comprehension_data_cond3_novel_stem')

novel_meaning_comprehension_data_cond3_novel_stem_subj_means = novel_meaning_comprehension_data_cond3_novel_stem %>%
  group_by(participant) %>%
  summarize(subj_values = mean(freq_choice_dv)) %>%
  mutate(Model = 'novel_meaning_comprehension_data_cond3_novel_stem')







### models

priors_m1 = c(
  prior(student_t(3, 0, 1), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 1), class = 'sd'))
  
###cond 1

original_meaning_comprehension_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_comprehension_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_comprehension_model_cond1_familiar_stem'
                                                                     )

novel_meaning_comprehension_model_cond1_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_comprehension_data_cond1_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_comprehension_model_cond1_familiar_stem'
                                                                     )

original_meaning_comprehension_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_comprehension_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_comprehension_model_cond1_novel_stem'
                                                                     )

novel_meaning_comprehension_model_cond1_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_comprehension_data_cond1_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_comprehension_model_cond1_novel_stem'
                                                                     )


###cond 2

original_meaning_comprehension_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_comprehension_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.999),
                                       file = '../Data/original_meaning_comprehension_model_cond2_familiar_stem'
                                                                     )

novel_meaning_comprehension_model_cond2_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_comprehension_data_cond2_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_comprehension_model_cond2_familiar_stem'
                                                                     )

original_meaning_comprehension_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_comprehension_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_comprehension_model_cond2_novel_stem'
                                                                     )

novel_meaning_comprehension_model_cond2_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_comprehension_data_cond2_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 30000, 
                                       warmup = 15000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_comprehension_model_cond2_novel_stem'
                                                                     )



###cond 3

original_meaning_comprehension_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_comprehension_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_comprehension_model_cond3_familiar_stem'
                                                                     )

novel_meaning_comprehension_model_cond3_familiar_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_comprehension_data_cond3_familiar_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_comprehension_model_cond3_familiar_stem'
                                                                     )

original_meaning_comprehension_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = original_meaning_comprehension_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/original_meaning_comprehension_model_cond3_novel_stem'
                                                                     )

novel_meaning_comprehension_model_cond3_novel_stem = brm(freq_choice_dv ~ 1 + (1 | participant) + (1 | resp_stem),
                                       data = novel_meaning_comprehension_data_cond3_novel_stem,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/novel_meaning_comprehension_model_cond3_novel_stem'
                                                                     )






model_names = c('original_meaning_comprehension_model_cond1_familiar_stem',
                'novel_meaning_comprehension_model_cond1_familiar_stem',
                'original_meaning_comprehension_model_cond1_novel_stem',
                'novel_meaning_comprehension_model_cond1_novel_stem',
                'original_meaning_comprehension_model_cond2_familiar_stem',
                'novel_meaning_comprehension_model_cond2_familiar_stem',
                'original_meaning_comprehension_model_cond2_novel_stem',
                'novel_meaning_comprehension_model_cond2_novel_stem',
                'original_meaning_comprehension_model_cond3_familiar_stem',
                'novel_meaning_comprehension_model_cond3_familiar_stem',
                'original_meaning_comprehension_model_cond3_novel_stem',
                'novel_meaning_comprehension_model_cond3_novel_stem')

list_of_models = mget(model_names)

extract_fixed_effects = function(model, model_name) {
  as.data.frame(fixef(model)) %>%
    tibble::rownames_to_column("Term") %>%
    mutate(Prob = plogis(Estimate),
           Lower = plogis(Q2.5),         
           Upper = plogis(Q97.5), 
           Model = model_name)
}

fixed_effects_df_comprehension = map2_dfr(list_of_models, names(list_of_models), extract_fixed_effects)

fixed_effects_df_comprehension = fixed_effects_df_comprehension %>%
  separate(Model, into = c("Meaning", "ignore1", "Task", "ignore2", "Condition", 'Stem', 'ignore3'), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2, -ignore3)  # Remove the unnecessary columns


subj_effect_names = ls(pattern = "_subj_means$")
subject_effects = bind_rows(mget(subj_effect_names), .id = 'source')

subject_effects = subject_effects %>%
  separate(Model, into = c("Meaning", "ignore1", "Task", "ignore2", "Condition", 'Stem', 'ignore3'), sep = "_", remove = FALSE) %>%
  select(-ignore1, -ignore2, -ignore3) 

subject_effects_comprehension = subject_effects %>%
  filter(Task == 'comprehension')

ggplot(fixed_effects_df_comprehension, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects_comprehension, 
             aes(x = Meaning, y = subj_values),  
             color = "black",  
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, alpha = 0.2, 
             show.legend = FALSE) +  # Hides the points from the legend
  facet_grid(~ Condition) + 
  theme_bw() +
  ggtitle('Comprehension') +
  xlab('Condition') +
  ylab('Probability of Producing a Form') +
  ylim(0, 1)

```

## Full plot

```{r}
fixed_effects_df_all = fixed_effects_df %>%
   full_join(fixed_effects_df_2afc) %>%
   full_join(fixed_effects_df_comprehension)

write_csv(fixed_effects_df_all, '../Data/fixed_effects_df_all.csv')
write_csv(subject_effects, '../Data/subject_effects.csv')

fixed_effects_df_all = read_csv('../Data/fixed_effects_df_all.csv')
subject_effects = read_csv('../Data/subject_effects.csv')

fixed_effects_df_all$Task = factor(fixed_effects_df_all$Task, levels = c('prod', '2afc', 'comprehension'))

subject_effects$Task = factor(subject_effects$Task, levels = c('prod', '2afc', 'comprehension'))

condition_labels = c("cond1" = "Condition 1", 
                      "cond2" = "Condition 2", 
                      "cond3" = "Condition 3")
task_labels = c("prod" = "Production",
                "2afc" = "Form Choice",
                "comprehension" = "Comprehension")

fixed_effects_df_all$Meaning = factor(fixed_effects_df_all$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

subject_effects$Meaning = factor(subject_effects$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

fixed_effects_df_all$Stem = factor(fixed_effects_df_all$Stem, 
                                  levels = c("familiar", "novel"), 
                                  labels = c("Familiar", "Novel"))

subject_effects$Stem = factor(subject_effects$Stem, 
                                  levels = c("familiar", "novel"), 
                                  labels = c("Familiar", "Novel"))


ggplot(fixed_effects_df_all, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  geom_point(data = subject_effects, 
             aes(x = Meaning, y = subj_values, fill = Stem, color = Stem),  # Map fill and color
             shape = 21,   # Hollow circle with fill and outline
             position = position_jitterdodge(jitter.width = 0.3, dodge.width = 0.9), 
             size = 2, stroke = 0.7, alpha = 0.1,  # Adjust size, border thickness, and transparency
             show.legend = FALSE) +  # Hides points from legend
  scale_fill_manual(values = c("Familiar" = "#66c2a5", "Novel" = "#8da0cb")) +  # Bar & point fill colors
  scale_color_manual(values = c("Familiar" = "#1b7837", "Novel" = "#2b8cbe")) +  # Darker border colors for points
  facet_grid(Task ~ Condition, labeller = labeller(Condition = condition_labels, Task = task_labels)) + 
  theme_bw() +
  ggtitle('Results by condition for each task') +
  xlab('Meaning') +
  ylab('Response Probability') +
  ylim(0, 1)
```

# Nem/dan 1; sil/shoon zero

```{r}

data_sil_shoon = data_analysis %>%
  filter(task == 'prod') %>%
  mutate(participant = as.factor(participant)) 

data_sil_shoon = data_sil_shoon %>%
  mutate(dv = case_when(
    resp_suffix_form %in% c('nem', 'dan') ~ 1,
    resp_suffix_form %in% c('sil', 'shoon') ~ 0
  ))
```

```{r}
options(contrasts = c("contr.treatment","contr.treatment"))
data_sil_shoon$condition = factor(data_sil_shoon$condition, levels = c(3, 1, 2))

data_sil_shoon$meaning_choice = factor(data_sil_shoon$meaning_choice)
contrasts(data_sil_shoon$meaning_choice) = contr.sum(levels(data_sil_shoon$meaning_choice))

data_sil_shoon$stem_condition = factor(data_sil_shoon$stem_condition, levels = c('novel', 'familiar'))
contrasts(data_sil_shoon$stem_condition) = contr.sum(levels(data_sil_shoon$stem_condition))

model_prod_sil_shoon = brm(dv ~ condition + meaning_choice + stem_condition + condition:meaning_choice + condition:stem_condition + (1 + meaning_choice+stem_condition | participant) + (1 | resp_stem),
                                       data = data_sil_shoon,
                                       family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_sil_shoon')


```

```{r}
fixef(model_prod_sil_shoon)
conditional_effects(model_prod_sil_shoon)
```

## With Frequency

```{r}
data_sil_shoon_familiar = data_sil_shoon %>%
  filter(picture_meaning != 'dim_pl') %>%
  mutate(freq = case_when(
    language == 'nem' & picture_meaning == 'dim_sg' ~ 'freq',
    language == 'dan' & picture_meaning == 'big_pl' ~ 'freq',
    #language == 'nem' & picture_meaning == 'dim.pl' ~ 'freq',
    #language == 'dan' & picture_meaning == 'dim.pl' ~ 'freq',
    language == 'nem' & picture_meaning == 'big_pl' ~ 'infreq',
    language == 'dan' & picture_meaning == 'dim_sg' ~ 'infreq'
  ))
```

```{r}
options(contrasts = c("contr.treatment","contr.treatment"))
data_sil_shoon_familiar$condition = factor(data_sil_shoon_familiar$condition, levels = c(3, 1, 2))

#data_sil_shoon$meaning_choice = factor(data_sil_shoon$meaning_choice)
#contrasts(data_sil_shoon$meaning_choice) = contr.sum(levels(data_sil_shoon$meaning_choice))

data_sil_shoon_familiar$stem_condition = factor(data_sil_shoon_familiar$stem_condition, levels = c('novel', 'familiar'))
contrasts(data_sil_shoon_familiar$stem_condition) = contr.sum(levels(data_sil_shoon_familiar$stem_condition))

data_sil_shoon_familiar$freq = factor(data_sil_shoon_familiar$freq, levels = c('freq', 'infreq'))
contrasts(data_sil_shoon_familiar$freq) = contr.sum(levels(data_sil_shoon_familiar$freq))



model_prod_sil_shoon_freq = brm(dv ~ condition+ stem_condition +freq + condition:stem_condition + condition:freq + stem_condition:freq + (freq*stem_condition|participant) + (1 | resp_stem),
                                       data = data_sil_shoon_familiar,
                                       family = bernoulli(link = 'logit'),
                                       iter = 4000, 
                                       warmup = 2000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_sil_shoon_freq')
```

```{r}
fixef(model_prod_sil_shoon_freq)
conditional_effects(model_prod_sil_shoon_freq)
```
