---
title: "Generalizability Analysis Script"
author: "Zachary Houghton"
date: "2023-10-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(brms)
library(sjPlot)
```

## Conditions Table

Table1:

|  |  |  |  |  |  |  |  |  |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| **Condition1** | #of tokens | #of types | **Condition2** | #of tokens | #of types | **Condition3** | #of tokens | #of types |
| dan | 12 | 12 | dan | 12 | 3 | dan | 12 | 12 |
| nem | 12 | 3 | nem | 3 | 3 | nem | 3 | 3 |
| sil | 6 | 6 | sil | 6 | 6 | sil | 6 | 6 |
| shoon | 6 | 6 | shoon | 6 | 6 | shoon | 6 | 6 |
| **Condition4** |  |  | **Condition5** |  |  | **nem language** | #of tokens | #of types |
| dan | 12 | 3 | dan | 3 | 3 | dan | 3 | 3 |
| nem | 12 | 12 | nem | 12 | 3 | nem | 12 | 12 |
| sil | 6 | 6 | sil | 6 | 6 | sil | 6 | 6 |
| shoon | 6 | 6 | shoon | 6 | 6 | shoon | 6 | 6 |

Table2

|  |  |  |  |  |  |  |  |  |
|--------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| **Condition** | **dan token** | **nem token** | **sil token** | **shoon token** | **dan type** | **nem type** | **sil type** | **shoon type** |
| 1 | 12 | 12 | 6 | 6 | 12 | 3 | 6 | 6 |
| 2 | 12 | 3 | 6 | 6 | 3 | 3 | 6 | 6 |
| 3 | 12 | 3 | 6 | 6 | 12 | 3 | 6 | 6 |
| 4 | 12 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |
| 5 | 3 | 12 | 6 | 6 | 3 | 3 | 6 | 6 |
| 6 | 3 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |

|   | Frequent Token | Frequent Type | Infrequent Token | Infrequent Type | Frequent Competitor Token | Frequent Competitor Type | Infrequent Competitor Token | Infrequent Competitor Type |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| **Condition 1** | 12 | 12 | 12 | 3 | 6 | 6 | 6 | 6 |
| **Condition 2** | 12 | 3 | 3 | 3 | 6 | 6 | 6 | 6 |
| **Condition 3** | 12 | 12 | 3 | 3 | 6 | 6 | 6 | 6 |

|   | Frequent Token | Frequent Type | Infrequent Token | Infrequent Type |
|---------------|---------------|---------------|---------------|---------------|
| **Condition 1** | 12 | 12 | 12 | 3 |
| **Condition 2** | 12 | 3 | 3 | 3 |
| **Condition 3** | 12 | 12 | 3 | 3 |

## Data Preparation

First let's load our data and clean it up

<!--# confirm the number of items in the table (*5) matches the items given to participants -->

```{r message = F}
data = read.csv('../Data/data_comprehension.csv', quote = "\"")# %>% #I'm not sure why, but read_csv() breaks because due to the quotes, even when setting the quote character properly
  #filter(is.na(PROLIFIC_PID) == F)

start_date <- as.POSIXct("2024-10-29") #, format="%Y-%m-%d %H:%M:%OS"
end_date <- as.POSIXct("2024-10-31") #, format="%Y-%m-%d %H:%M:%OS"

data = data %>% #I fucked up and accidentally coded a few participants in the wrong condition, so this line of code is to correct that mistake. We can inspected training_received to determine which condition a participant is in.
  mutate(date = as.POSIXct(date)) %>% #, format="%Y-%m-%d %H:%M:%OS")
  mutate(condition = ifelse(
    date >= start_date & date <= end_date, '1', condition
  ))

training_received = data %>%
  select(stem, suffix, label, condition, participant, date) %>%
  group_by(participant, condition, suffix, date) %>%
  summarize(table(suffix))


data_analysis = data %>%
  dplyr::select(participant, date, condition, pretraining, textbox.text, textbox_5.text, textbox_6.text, prod_label, prod_condition, prod_image2, prod_resp.text, key_resp_16.keys, comp_label1_location, comp_label2_location, label1, label2, comp_condition_stem, comp_condition_suffix, stem, mouse.clicked_name, comprehension_label, suffix) %>%
  rename(age = textbox.text,
         native_lang = textbox_5.text,
         other_langs = textbox_6.text,
         fc_resp = key_resp_16.keys,
         fc_label1_location = comp_label1_location,
         fc_label2_location = comp_label2_location,
         fc_label1 = label1,
         fc_label2 = label2,
         prod_suffix = prod_image2,
         fc_condition_stem = comp_condition_stem,
         fc_condition_suffix = comp_condition_suffix,
         prod_resp = prod_resp.text,
         prod_stem = prod_label,
         resp_stem = stem) %>%
  mutate(comprehension_response = case_when(
    mouse.clicked_name == 'prod_image1_5' ~ 'big',
    mouse.clicked_name == 'prod_image2_3' ~ 'dim_sg',
    mouse.clicked_name == 'alt_image2_3' ~ 'dim_pl',
    mouse.clicked_name == 'alt_image2_3' ~ 'big_pl'
  )) %>%
  group_by(participant) %>%
  fill(c(condition, pretraining, age, native_lang, other_langs)) 

#data_analysis = data_analysis %>%
  #filter(!participant %in% c(332893, 837048, 356830, 117154, 894692)) #not SONA participants
data_analysis$date = gsub('_.*', '', data_analysis$date)
data_analysis$date = as.Date(data_analysis$date)

data_analysis = data_analysis %>%
  filter(date > '2024-10-01')

data_analysis$pretraining = as.factor(data_analysis$pretraining / 100)
data_analysis$condition = as.factor(data_analysis$condition)
data_analysis = data_analysis %>%
  mutate(fc_condition_suffix = ifelse(fc_condition_suffix == 'big', 'big_pl', fc_condition_suffix))

data_analysis_2afc = data_analysis %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, fc_resp, fc_label1_location, fc_label2_location, fc_label1, fc_label2, fc_condition_stem, fc_condition_suffix, resp_stem) %>%
  drop_na(fc_resp)



data_analysis_prod = data_analysis %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, prod_stem, prod_suffix, prod_condition, prod_resp) %>%
  drop_na(prod_resp)

data_analysis_prod$prod_suffix = gsub('.*/[0-9]*_(.+)\\.PNG', '\\1', data_analysis_prod$prod_suffix)

data_analysis_prod$prod_suffix[data_analysis_prod$prod_suffix=='2'] = 'big_pl'


data_analysis_comprehension = data_analysis %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, comprehension_label, comprehension_response)


training_received = data_analysis %>%
  select(suffix, condition, participant, date) %>%
  group_by(participant, condition, suffix, date) %>%
  summarize(table(suffix))
```

There are quite a lot of typos, so now we'll manually go through the production data and correct the typos:

```{r}
data_analysis_prod_typos = data_analysis_prod %>%
  filter(prod_suffix == 'dim_pl')
write_csv(data_analysis_prod_typos, '../Data/prod_data_typos.csv') #so that we can go through and manually correct typos
```

The new

```{r}
#bad_participants = c(58877, 58950, 58253, 59044, 59192, 58101, 58988, 58898, 59227, 59328, 56878
#)
#bad participants are participants who answered with only the stem (no suffix) more than 3 times out of the 6 production trials

#data_analysis_prod = read_csv('../Data/data_analysis_prod_typos_fixed.csv') %>% #manually corrected typos
 # filter(!participant %in% bad_participants)


data_analysis_prod = data_analysis_prod %>%
  mutate(prod_resp_suffix = str_extract_all(prod_resp, 'dan|sil|shoon|nem')) %>%
  unnest(prod_resp_suffix, keep_empty = T) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))
 

data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(comprehension_suffix = str_extract_all(comprehension_label, 'dan|sil|shoon|nem')) %>%
  unnest(comprehension_suffix, keep_empty = T) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))

 
data_analysis_2afc = data_analysis_2afc %>%
  mutate(resp = ifelse(fc_resp == fc_label1_location, fc_label1, fc_label2))

data_analysis_2afc = data_analysis_2afc %>%
  mutate(resp_suffix = str_extract_all(resp, 'dan|sil|shoon|nem')) %>%
  unnest(resp_suffix, keep_empty = T)

data_analysis_2afc = data_analysis_2afc %>%
  mutate(accuracy = case_when(fc_condition_suffix == 'big_pl' ~ ifelse(resp_suffix %in% c('dan', 'sil'), 1, 0))) %>%
  mutate(accuracy = case_when(fc_condition_suffix == 'dim_sg' ~ ifelse(resp_suffix %in% c('nem', 'shoon'), 1, 0))) %>%
  mutate(language = case_when(condition %in% c(1,2,3) ~ 'dan', condition %in% c(4,5,6) ~ 'nem'))

# accuracy_scores = data_analysis_2afc %>% f
#   group_by(participant) %>%
#   filter(!is.na(accuracy)) %>%
#   summarize(mean(accuracy))

data_analysis_2afc = data_analysis_2afc %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(resp_suffix == 'dan', 'freq',
                              ifelse(resp_suffix == 'sil', 'freq_competitor',
                              ifelse(resp_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(resp_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(resp_suffix == 'dan', 'infreq',
         ifelse(resp_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


data_analysis_prod = data_analysis_prod %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(prod_resp_suffix == 'dan', 'freq',
                              ifelse(prod_resp_suffix == 'sil', 'freq_competitor',
                              ifelse(prod_resp_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(prod_resp_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(prod_resp_suffix == 'dan', 'infreq',
         ifelse(prod_resp_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


data_analysis_comprehension = data_analysis_comprehension %>%
  mutate(freq_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(comprehension_suffix == 'dan', 'freq',
                              ifelse(comprehension_suffix == 'sil', 'freq_competitor',
                              ifelse(comprehension_suffix == 'nem', 'infreq', 'infreq_competitor'))),
         ifelse(comprehension_suffix == 'nem', 'freq', #if condition is 4,5, or 6
         ifelse(comprehension_suffix == 'dan', 'infreq',
         ifelse(comprehension_suffix == 'shoon', 'freq_competitor', 'infreq_competitor')))))


names = c('resp_stem', 'picture_meaning', 'stem_condition', 'resp', 'resp_suffix_form')
names_2afc = c('stem_condition', 'picture_meaning', 'resp_stem', 'resp', 'resp_suffix_form')

colnames(data_analysis_prod)[8:12] = names
colnames(data_analysis_2afc)[13:17] = names_2afc


data_analysis_prod = data_analysis_prod %>%
  mutate(accuracy = case_when(picture_meaning == 'big_pl' ~ ifelse(resp_suffix_form %in% c('dan', 'sil'), 1, 0))) %>%
  mutate(accuracy = case_when(picture_meaning == 'dim_sg' ~ ifelse(resp_suffix_form %in% c('nem', 'shoon'), 1, 0)))

data_analysis_2afc = data_analysis_2afc %>%
  select(participant, date, condition, pretraining, age, native_lang, other_langs, stem_condition, picture_meaning, resp_stem, resp, resp_suffix_form, freq_choice, accuracy, language) %>%
  mutate(task = '2afc')



data_analysis_prod = data_analysis_prod %>%
  mutate(task = 'prod')

#data_analysis_prod$date = as.Date(data_analysis_prod$date)
data_analysis_prod$condition = factor(data_analysis_prod$condition)
data_analysis_prod$pretraining = factor(data_analysis_prod$pretraining)

# data_analysis_2afc$date = as.character(data_analysis_2afc$date)
# data_analysis_2afc$condition = as.numeric(as.character(data_analysis_2afc$condition))
# data_analysis_2afc$pretraining = as.numeric(as.character(data_analysis_2afc$pretraining))

data_analysis = data_analysis_2afc %>%
  full_join(data_analysis_prod) 


accuracy_scores = data_analysis %>%
  filter(!is.na(accuracy) & task == '2afc') %>%
  group_by(participant) %>%
  summarize(mean_accuracy = mean(accuracy), sd_accuracy = sd(accuracy))

data_analysis = data_analysis %>%
  filter(!any(native_lang %in% c('Spanish\n', 'Vietnames', 'Vietnames\n', 'hebrew\n')))

length(unique(data_analysis$participant))
```

```{r}
data_analysis = data_analysis %>%
  mutate(meaning_choice = ifelse(condition %in% c(1,2,3), 
                              ifelse(picture_meaning == 'big_pl', 'freq',
                              ifelse(picture_meaning == 'dim_sg', 'infreq', 'novel')),
         ifelse(picture_meaning == 'big_pl', 'infreq', #if condition is 4,5, or 6
         ifelse(picture_meaning == 'dim_sg', 'freq', 'novel'))))

data_analysis = data_analysis %>%
  mutate(condition = ifelse(condition == 4, 1, 
                            ifelse(condition == 5, 2, 
                                   ifelse(condition == 6, 3, condition)))) %>%
  filter(!is.na(resp_suffix_form)) %>%
  left_join(accuracy_scores, by = 'participant')


```

```{r}

  

```

```{r}
data %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

```{r}
data_analysis %>%
  group_by(condition) %>%
  summarize(length(unique(participant)))
```

# Analysis

First we'll eliminate participants with below \_\_\_% accuracy

```{r}
# accuracy_threshold = 0.7
# data_analysis_m1 = data_analysis %>%
#   filter(!mean_accuracy < accuracy_threshold)
```

Our dependent measure will be `freq_choice`.

Our independent measures will be pretraining, condition, stem_condition (whether the stem was familiar or novel), and task

<!--# add predictions? -->

<!--# analyses: freq_choice ~ pretraining*condition*stem_condition*task + (1|stem) + (1 + stem_condition*task|participant) + (pretraining*condition*task|stem) -->

<!--# freq vs infreq for novel meanings -->

<!--# freq vs freq competitor for novel meanings -->

<!--# also add analyses for subset data, subsetting by stem_condition and picture_meaning -->

```{r}
#options (contrasts = c('contr.treatment','contr.treatment'))
options(contrasts = c("contr.sum","contr.sum"))

data_m1 = data_analysis %>%
  filter(picture_meaning == 'dim_sg') %>%
  #filter(freq_choice %in% c('freq', 'infreq')) %>% #we are discarding sil and shoon responses by doing this
  mutate(freq_choice = ifelse(freq_choice == 'freq', 1, 0)) %>%
  mutate(condition = as.factor(condition)) %>%
  mutate(participant = as.factor(participant)) %>%
  mutate(pretraining = as.factor(pretraining)) 

data_m1_prod = data_m1 %>%
  filter(task=='prod')

str(data_analysis)

xtabs_df = data_m1 %>%
  select(resp_suffix_form, condition, task, language)

xtabs(~resp_suffix_form + language + condition + task, data = xtabs_df)
#data_m1$condition = factor(data_m1$condition, levels = c(3, 1, 2)) 

data_familiar = data_m1 %>%
  filter(stem_condition == 'familiar')

data_novel = data_m1 %>%
  filter(stem_condition == 'novel')


#length(unique(data_m1$participant))
#length(unique(data_familiar$participant))


# priors_m1 = c(
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'mufreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'muinfreqcompetitor'),
#   prior(student_t(3, 0, 2), class = 'Intercept', dpar = 'muinfreq'),
#   prior(student_t(3, 0, 2), class = 'sd', dpar = 'muinfreq'),
#   prior(student_t(3, 0, 2), class = 'b', dpar = 'muinfreq')
# )

priors_m1 = c(
  prior(student_t(3, 0, 0.5), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 0.5), class = 'b'),
  prior(student_t(3, 0, 0.5), class = 'sd'),
  prior(lkj_corr_cholesky(2), class = 'cor'))
  
# 
# 
# m1 = brm(freq_choice ~ pretraining*condition*stem_condition*task + (1 + stem_condition*task|participant) + (pretraining*condition*task|resp_stem),
#          data = data_m1,
#          family = bernoulli(link = 'logit'),
#          iter = 16000, 
#          warmup = 8000,
#          chains = 4,
#          cores = 4,
#          prior = priors_m1,
#          control = list(adapt_delta = 0.98),
#          file = '../Data/model1')

# 
# m1_smaller = brm(freq_choice ~ (pretraining + condition + stem_condition + task)^3 + (1 + stem_condition*task|participant) + (pretraining*condition*task|resp_stem),
#          data = data_m1,
#          family = bernoulli(link = 'logit'),
#          iter = 10000, 
#          warmup = 5000,
#          chains = 4,
#          cores = 4,
#          prior = priors_m1,
#          #control = list(adapt_delta = 0.98),
#          file = '../Data/model1_small')


m1_smaller = brm(freq_choice ~ condition + stem_condition + task + task:condition + condition:stem_condition + stem_condition:task #rerun this model
                 + (1 + stem_condition*task|participant) + (condition|resp_stem),
         data = data_m1,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/model1_small')

fixef(m1_smaller)
# 
# test = glmer(freq_choice ~ pretraining + condition + stem_condition + task + task:condition + pretraining:condition + condition:stem_condition + pretraining:stem_condition 
#                  + (1 + stem_condition*task|participant) + (pretraining*condition|resp_stem),
#          data = data_m1,
#          family = "binomial")




m1_only_familiar_stems = brm(freq_choice ~ condition*task + (1 + task|participant) + (condition*task|resp_stem),
         data = data_familiar,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model_familiar')



m1_only_novel_stems = brm(freq_choice ~ condition*task + (1 + task|participant) + (condition*task|resp_stem),
         data = data_novel,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/model_novel')

fixef(m1_only_familiar_stems)
fixef(m1_only_novel_stems)

conditional_effects(m1_smaller)
conditional_effects(m1_only_familiar_stems)
conditional_effects(m1_only_novel_stems)
```

```{r}
plot_model(m1_smaller, type = 'int')
plot_model(m1_only_familiar_stems, type = 'int')
plot_model(m1_only_novel_stems, type = 'int')
```

```{r}
data_prod = data_m1 %>%
  filter(task == 'prod')

data_2afc = data_m1 %>%
  filter(task == '2afc')

m1_prod_small = brm(freq_choice ~ condition + stem_condition + condition:stem_condition
                 + (1 + stem_condition|participant) + (condition|resp_stem),
         data = data_prod,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/m1_prod_small')

fixef(m1_prod_small)

m1_2afc_small = brm(freq_choice ~ condition + stem_condition + condition:stem_condition
                 + (1 + stem_condition|participant) + (condition|resp_stem),
         data = data_2afc,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         prior = priors_m1,
         control = list(adapt_delta = 0.98),
         file = '../Data/m1_2afc_small')

fixef(m1_2afc_small)

conditional_effects(m1_prod_small)
conditional_effects(m1_2afc_small)


##### even smaller models

data_familiar_prod = data_familiar %>%
  filter(task == 'prod')
data_familiar_2afc = data_familiar %>%
  filter(task == '2afc')

data_novel_prod = data_novel %>%
  filter(task == 'prod')
data_novel_2afc = data_novel %>%
  filter(task == '2afc')


m1_prod_familiar = brm(freq_choice ~ condition
                 + (1 |participant) + (condition|resp_stem),
         data = data_familiar_prod,
         family = bernoulli(link = 'logit'),
         iter = 12000, 
         warmup = 6000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         control = list(adapt_delta = 0.99, max_treedepth=12),
         file = '../Data/m1_prod_familiar')


m1_2afc_familiar = brm(freq_choice ~ condition
                 + (1 |participant) + (condition|resp_stem),
         data = data_familiar_2afc,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc_familiar')


m1_prod_novel = brm(freq_choice ~ condition
                 + (1 |participant) + (condition|resp_stem),
         data = data_novel_prod,
         family = bernoulli(link = 'logit'),
         iter = 25000, 
         warmup = 13000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_prod_novel')

m1_2afc_novel = brm(freq_choice ~ condition
                 + (1 |participant) + (condition|resp_stem),
         data = data_novel_2afc,
         family = bernoulli(link = 'logit'),
         iter = 18000, 
         warmup = 10000,
         chains = 4,
         cores = 4,
         #prior = priors_m1,
         control = list(adapt_delta = 0.99),
         file = '../Data/m1_2afc_novel')




fixef(m1_prod_familiar)
fixef(m1_2afc_familiar)
fixef(m1_prod_novel)
fixef(m1_2afc_novel)


conditional_effects(m1_prod_familiar)
conditional_effects(m1_2afc_familiar)
conditional_effects(m1_prod_novel)
conditional_effects(m1_2afc_novel)
```

Comprehension analysis:
