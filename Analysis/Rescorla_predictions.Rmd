---
title: "Token Frequency Rescorla"
author: "Zachary Houghton"
date: "2023-11-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Rescorla Predictions

Libraries:

```{r}
library(tidyverse)
library(ndl)
library(arm)
#logistic perceptron from neural net
source("RescorlaLogistic.R")
```

Let's test what the RW predictions for our experiment are.

## Conditions Tables

Table1:

|  |  |  |  |  |  |  |  |  |
|--------|--------|--------|--------|--------|--------|--------|--------|--------|
| **Condition1** | #of tokens | #of types | **Condition2** | #of tokens | #of types | **Condition3** | #of tokens | #of types |
| *dan* | 12 | 12 | *dan* | 12 | 3 | *dan* | 12 | 12 |
| *nem* | 12 | 3 | *nem* | 3 | 3 | *nem* | 3 | 3 |
| *sil* | 6 | 6 | *sil* | 6 | 6 | *sil* | 6 | 6 |
| *shoon* | 6 | 6 | *shoon* | 6 | 6 | *shoon* | 6 | 6 |
| **Condition4** |  |  | **Condition5** |  |  | **Condition6** | #of tokens | #of types |
| *dan* | 12 | 3 | *dan* | 3 | 3 | *dan* | 3 | 3 |
| *nem* | 12 | 12 | *nem* | 12 | 3 | *nem* | 12 | 12 |
| *sil* | 6 | 6 | *sil* | 6 | 6 | *sil* | 6 | 6 |
| *shoon* | 6 | 6 | *shoon* | 6 | 6 | *shoon* | 6 | 6 |

Table2

|  |  |  |  |  |  |  |  |  |
|--------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|
| **Condition** | **dan token** | **nem token** | **sil token** | **shoon token** | **dan type** | **nem type** | **sil type** | **shoon type** |
| 1 | 12 | 12 | 6 | 6 | 12 | 3 | 6 | 6 |
| 2 | 12 | 3 | 6 | 6 | 3 | 3 | 6 | 6 |
| 3 | 12 | 3 | 6 | 6 | 12 | 3 | 6 | 6 |
| 4 | 12 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |
| 5 | 3 | 12 | 6 | 6 | 3 | 3 | 6 | 6 |
| 6 | 3 | 12 | 6 | 6 | 3 | 12 | 6 | 6 |

## Condition 1 (dan type): 12 token, 12 type (nem 12 tokens 3 types)

### Preparing Data

```{r}
cond1 = read_csv('../Conditions/Condition1.csv') 
cond1 = cond1 %>%
  mutate(stem = orthoCoding(stem)) %>%
  mutate(type = case_when(
    suffix == 'dan' | suffix == 'sil' ~ 'big_pl',
    suffix == 'none' ~ 'big_sg',
    suffix == 'nem' | suffix == 'shoon' ~ 'dim_sg'
  ))
  

cond1 = cond1 %>%
  mutate(key = paste0(stem, '_', type))

cond1_key = cond1 %>%
  group_by(key, suffix) %>%
  summarize(frequency = table(key))

colnames(cond1_key) = c('Cues', 'Outcomes', 'Frequency')

data_cond1 = cond1_key %>%
  mutate(Frequency = as.numeric(Frequency) * 5) %>% 
  mutate(Cues = paste0("cx_", Cues))

```

### Rescorla Predictions

We'll use the RW-model with logistic function.

As a reminder, the question we're investigating is whether type or token frequency (or some combination of both) affects the generalizability of a morpheme (this is operationalized as whether type or token frequency affects the *associability,* or the weight, of one cue with the plural outcome outcome).

```{r}
n = 10
b = 0.4
b2 = 0.5
a = 0.5
ap_setting = F

big_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

cx_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='cx', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

cx_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='cx', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
  
#big_dan_cond1_test = RescorlaLogistic(data_cond1_test, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

dim_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='dim', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='big', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

dim_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='dim', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

big_pl_dan_cond1 = big_dan_cond1$weightvector + pl_dan_cond1$weightvector
dim_pl_dan_cond1 = dim_dan_cond1$weightvector + pl_dan_cond1$weightvector
big_pl_nem_cond1 = big_nem_cond1$weightvector + pl_nem_cond1$weightvector
dim_pl_nem_cond1 = dim_nem_cond1$weightvector + pl_nem_cond1$weightvector

sg_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='sg', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
dim_sg_nem_cond1 = dim_nem_cond1$weightvector + sg_nem_cond1$weightvector

plot(big_pl_dan_cond1, type='l' )
plot(dim_pl_dan_cond1, type = 'l')

plot(big_pl_nem_cond1, type = 'l')
plot(dim_pl_nem_cond1, type = 'l')

plot(big_pl_dan_cond1 - big_pl_nem_cond1, type = 'l')
plot(dim_pl_dan_cond1 - dim_pl_nem_cond1, type = 'l')


```

## Condition 2 (dan token): 12 tokens, 3 types

```{r}

cond2 = read_csv('../Conditions/Condition2.csv') 
cond2 = cond2 %>%
    mutate(stem = orthoCoding(stem)) %>%
  mutate(type = case_when(
    suffix == 'dan' | suffix == 'sil' ~ 'big_pl',
    suffix == 'none' ~ 'big_sg',
    suffix == 'nem' | suffix == 'shoon' ~ 'dim_sg'
  ))
  

cond2 = cond2 %>%
  mutate(key = paste0(stem, '_', type))

cond2_key = cond2 %>%
  group_by(key, suffix) %>%
  summarize(frequency = table(key))

colnames(cond2_key) = c('Cues', 'Outcomes', 'Frequency')

data_cond2 = cond2_key %>%
  mutate(Frequency = as.numeric(Frequency) * 5) %>% 
  mutate(Cues = paste0("cx_", Cues))
```

### Rescorla Predictions

```{r}


cx_dan_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='cx', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

cx_nem_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='cx', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

big_dan_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
pl_dan_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

dim_dan_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='dim', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='big', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
pl_nem_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

dim_nem_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='dim', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

sg_nem_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='sg', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
dim_sg_nem_cond2 = dim_nem_cond2$weightvector + sg_nem_cond2$weightvector

big_pl_dan_cond2 = big_dan_cond2$weightvector + pl_dan_cond2$weightvector
dim_pl_dan_cond2 = dim_dan_cond2$weightvector + pl_dan_cond2$weightvector
big_pl_nem_cond2 = big_nem_cond2$weightvector + pl_nem_cond2$weightvector
dim_pl_nem_cond2 = dim_nem_cond2$weightvector + pl_nem_cond2$weightvector


plot(big_pl_dan_cond2, type='l' )
plot(dim_pl_dan_cond2, type = 'l')

plot(big_pl_nem_cond2, type = 'l')
plot(dim_pl_nem_cond2, type = 'l')

plot(big_pl_dan_cond2 - big_pl_nem_cond2, type = 'l')
plot(dim_pl_dan_cond2 - dim_pl_nem_cond2, type = 'l')

```

## Condition 3 (dan type and token): 12 tokens, 12 types (nem 3 tokens, 3 types)

```{r}

cond3 = read_csv('../Conditions/Condition3.csv') 
cond3 = cond3 %>%
    mutate(stem = orthoCoding(stem)) %>%
  mutate(type = case_when(
    suffix == 'dan' | suffix == 'sil' ~ 'big_pl',
    suffix == 'none' ~ 'big_sg',
    suffix == 'nem' | suffix == 'shoon' ~ 'dim_sg'
  ))
  

cond3 = cond3 %>%
  mutate(key = paste0(stem, '_', type))

cond3_key = cond3 %>%
  group_by(key, suffix) %>%
  summarize(frequency = table(key))

colnames(cond3_key) = c('Cues', 'Outcomes', 'Frequency')

data_cond3 = cond3_key %>%
  mutate(Frequency = as.numeric(Frequency) * 5) %>% 
  mutate(Cues = paste0("cx_", Cues))
```

### Rescorla Predictions

```{r}


cx_dan_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='cx', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

cx_nem_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='cx', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

big_dan_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
pl_dan_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

dim_dan_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='dim', traceOutcome = 'dan', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='big', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
pl_nem_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 

dim_nem_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='dim', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
sg_nem_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='sg', traceOutcome = 'nem', beta2=b2, alpha=a, beta1=b, ap = ap_setting) #ap = T means you're learning something if the cue is absent 
dim_sg_nem_cond3 = dim_nem_cond3$weightvector + sg_nem_cond3$weightvector

big_pl_dan_cond3 = big_dan_cond3$weightvector + pl_dan_cond3$weightvector
dim_pl_dan_cond3 = dim_dan_cond3$weightvector + pl_dan_cond3$weightvector
big_pl_nem_cond3 = big_nem_cond3$weightvector + pl_nem_cond3$weightvector
dim_pl_nem_cond3 = dim_nem_cond3$weightvector + pl_nem_cond3$weightvector


plot(big_pl_dan_cond3, type='l' )
plot(dim_pl_dan_cond3, type = 'l')

plot(big_pl_nem_cond3, type = 'l')
plot(dim_pl_nem_cond3, type = 'l')

plot(big_pl_dan_cond3 - big_pl_nem_cond3, type = 'l')
plot(dim_pl_dan_cond3 - dim_pl_nem_cond3, type = 'l')

cx_dan_cond1 = cx_dan_cond1$weightvector
cx_dan_cond2 = cx_dan_cond2$weightvector
cx_dan_cond3 = cx_dan_cond3$weightvector

cx_nem_cond1 = cx_nem_cond1$weightvector
cx_nem_cond2 = cx_nem_cond2$weightvector
cx_nem_cond3 = cx_nem_cond3$weightvector
```

## Condition 4 (nem type): 12 token, 12 type (dan 12 token, 3 type)

```{r}

cond4 = read_csv('../Conditions/Condition4.csv') 
cond4 = cond4 %>%
    mutate(stem = orthoCoding(stem)) %>%
  mutate(type = case_when(
    suffix == 'dan' | suffix == 'sil' ~ 'big_pl',
    suffix == 'none' ~ 'big_sg',
    suffix == 'nem' | suffix == 'shoon' ~ 'dim_sg'
  ))
  

cond4 = cond4 %>%
  mutate(key = paste0(stem, '_', type))

cond4_key = cond4 %>%
  group_by(key, suffix) %>%
  summarize(frequency = table(key))

colnames(cond4_key) = c('Cues', 'Outcomes', 'Frequency')

data_cond4 = cond4_key %>%
  mutate(Frequency = as.numeric(Frequency) * 5) 
```

### Rescorla Predictions

```{r}
n = 10
b = sqrt(.1)

big_dan_cond4 = RescorlaLogistic(data_cond4, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F) #ap = T means you're learning something if the cue is absent 
pl_dan_cond4 = RescorlaLogistic(data_cond4, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

dim_dan_cond4 = RescorlaLogistic(data_cond4, nruns = n, traceCue='dim', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond4 = RescorlaLogistic(data_cond4, nruns = n, traceCue='big', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
pl_nem_cond4 = RescorlaLogistic(data_cond4, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

dim_nem_cond4 = RescorlaLogistic(data_cond4, nruns = n, traceCue='dim', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

big_pl_dan_cond4 = big_dan_cond4$weightvector + pl_dan_cond4$weightvector
dim_pl_dan_cond4 = dim_dan_cond4$weightvector + pl_dan_cond4$weightvector
big_pl_nem_cond4 = big_nem_cond4$weightvector + pl_nem_cond4$weightvector
dim_pl_nem_cond4 = dim_nem_cond4$weightvector + pl_nem_cond4$weightvector


plot(big_pl_dan_cond4, type='l' )
plot(dim_pl_dan_cond4, type = 'l')

plot(big_pl_nem_cond4, type = 'l')
plot(dim_pl_nem_cond4, type = 'l')

plot(big_pl_dan_cond4 - big_pl_nem_cond4, type = 'l')
plot(dim_pl_dan_cond4 - dim_pl_nem_cond4, type = 'l')
```

## Condition 5 (nem token): 12 token, 3 types (dan 3 token, 3 type)

```{r}

cond5 = read_csv('../Conditions/Condition5.csv') 
cond5 = cond5 %>%
    mutate(stem = orthoCoding(stem)) %>%
  mutate(type = case_when(
    suffix == 'dan' | suffix == 'sil' ~ 'big_pl',
    suffix == 'none' ~ 'big_sg',
    suffix == 'nem' | suffix == 'shoon' ~ 'dim_sg'
  ))
  

cond5 = cond5 %>%
  mutate(key = paste0(stem, '_', type))

cond5_key = cond5 %>%
  group_by(key, suffix) %>%
  summarize(frequency = table(key))

colnames(cond5_key) = c('Cues', 'Outcomes', 'Frequency')

data_cond5 = cond5_key %>%
  mutate(Frequency = as.numeric(Frequency) * 5)
```

### Rescorla Predictions

```{r}
n = 10
b = sqrt(.1)

big_dan_cond5 = RescorlaLogistic(data_cond5, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F) #ap = T means you're learning something if the cue is absent 
pl_dan_cond5 = RescorlaLogistic(data_cond5, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

dim_dan_cond5 = RescorlaLogistic(data_cond5, nruns = n, traceCue='dim', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond5 = RescorlaLogistic(data_cond5, nruns = n, traceCue='big', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
pl_nem_cond5 = RescorlaLogistic(data_cond5, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

dim_nem_cond5 = RescorlaLogistic(data_cond5, nruns = n, traceCue='dim', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

big_pl_dan_cond5 = big_dan_cond5$weightvector + pl_dan_cond5$weightvector
dim_pl_dan_cond5 = dim_dan_cond5$weightvector + pl_dan_cond5$weightvector
big_pl_nem_cond5 = big_nem_cond5$weightvector + pl_nem_cond5$weightvector
dim_pl_nem_cond5 = dim_nem_cond5$weightvector + pl_nem_cond5$weightvector


plot(big_pl_dan_cond5, type='l' )
plot(dim_pl_dan_cond5, type = 'l')

plot(big_pl_nem_cond5, type = 'l')
plot(dim_pl_nem_cond5, type = 'l')

plot(big_pl_dan_cond5 - big_pl_nem_cond5, type = 'l')
plot(dim_pl_dan_cond5 - dim_pl_nem_cond5, type = 'l')
```

## Condition 6: (nem type and token) 12 token 12 type (dan 3 token 3 type)

```{r}

cond6 = read_csv('../Conditions/Condition6.csv') 
cond6 = cond6 %>%
    mutate(stem = orthoCoding(stem)) %>%
  mutate(type = case_when(
    suffix == 'dan' | suffix == 'sil' ~ 'big_pl',
    suffix == 'none' ~ 'big_sg',
    suffix == 'nem' | suffix == 'shoon' ~ 'dim_sg'
  ))
  
cond6 = cond6 %>%
  mutate(key = paste0(stem, '_', type))

cond6_key = cond6 %>%
  group_by(key, suffix) %>%
  summarize(frequency = table(key))

colnames(cond6_key) = c('Cues', 'Outcomes', 'Frequency')

data_cond6 = cond6_key %>%
  mutate(Frequency = as.numeric(Frequency) * 5)
```

### Rescorla Predictions

I played around with `purrr::map_dfr` in this section, but it does exactly the same thing as the code for the previous sections.

```{r}
n = 10
b = sqrt(.1)

cond_6_df = as.data.frame(rep(c('big', 'pl', 'dim'), times = 2)) %>%
  mutate(traceOutcome = rep(c('dan', 'nem'), each = 3))

colnames(cond_6_df) = c('traceCue', 'traceOutcome')

rw_preds_cond6 = pmap_dfr(cond_6_df, ~data.frame(weightvector = RescorlaLogistic(data_cond6, nruns = n, traceCue = ..1, traceOutcome = ..2, beta2 = b, alpha = b, beta1 = b, ap = T)[[1]], 'cue' = ..1, 'outcome' = ..2)) %>%
  group_by(cue, outcome) %>%
  group_split()

big_dan_cond6 = rw_preds_cond6[[1]] #ap = T means you're learning something if the cue is absent 
pl_dan_cond6 = rw_preds_cond6[[5]]

dim_dan_cond6 = rw_preds_cond6[[3]] 
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond6 = rw_preds_cond6[[2]] 
pl_nem_cond6 = rw_preds_cond6[[6]] 

dim_nem_cond6 = rw_preds_cond6[[4]] 
#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

big_pl_dan_cond6 = big_dan_cond6$weightvector + pl_dan_cond6$weightvector
dim_pl_dan_cond6 = dim_dan_cond6$weightvector + pl_dan_cond6$weightvector
big_pl_nem_cond6 = big_nem_cond6$weightvector + pl_nem_cond6$weightvector
dim_pl_nem_cond6 = dim_nem_cond6$weightvector + pl_nem_cond6$weightvector


plot(big_pl_dan_cond6, type='l' )
plot(dim_pl_dan_cond6, type = 'l')

plot(big_pl_nem_cond6, type = 'l')
plot(dim_pl_nem_cond6, type = 'l')

plot(big_pl_dan_cond6 - big_pl_nem_cond6, type = 'l')
plot(dim_pl_dan_cond6 - dim_pl_nem_cond6, type = 'l')
```

## Theoretically Interesting Comparisons

### High type vs low type

#### dan language:

```{r}
plot(dim_pl_dan_cond2 - dim_pl_nem_cond3, type = 'l') #not as high type frequency
plot(dim_pl_dan_cond3 - dim_pl_nem_cond3, type = 'l') #dan has higher type frequency
```

#### nem language:

```{r}
plot(dim_pl_dan_cond5 - dim_pl_nem_cond5, type = 'l') #nem not as high type frequency
plot(dim_pl_dan_cond6 - dim_pl_nem_cond6, type = 'l') #nem not as high type frequency
```

### High type vs high token

### High token vs low token

#### dan language:

```{r}
plot(dim_pl_dan_cond1 - dim_pl_nem_cond1, type = 'l') #higher token frequency for dan
plot(dim_pl_dan_cond3 - dim_pl_nem_cond3, type = 'l') #lower token frequency for dan
```

#### nem language:

```{r}
plot(dim_pl_dan_cond4 - dim_pl_nem_cond4, type = 'l') #higher token frequency for nem
plot(dim_pl_dan_cond6 - dim_pl_nem_cond6, type = 'l') #lower token frequency for nem
```

# Plots for Paper

## dan vs nem when dan is frequent in original vs novel

```{r}

#### four lines per condition:
# one is dan for big_pl, 2 is nem for dim_sg, 3 is dan for dim_pl, and 4 is nem for dim_pl



big_pl_dan_cond1_weights = data.frame(weights = big_pl_dan_cond1) %>%
  mutate(Meaning = 'Original',
         Frequency = 'Frequent')

dim_sg_nem_cond1_weights = data.frame(weights = dim_sg_nem_cond1) %>%
  mutate(Meaning = 'Original',
         Frequency = 'Inrequent')

dim_pl_dan_cond1_weights = data.frame(weights = dim_pl_dan_cond1) %>%
  mutate(Meaning = 'Novel',
         Frequency = 'Frequent')

dim_pl_nem_cond1_weights = data.frame(weights = dim_pl_nem_cond1) %>%
  mutate(Meaning = 'Novel',
         Frequency = 'Infrequent')

plot_df_cond1_data = bind_rows(big_pl_dan_cond1_weights, dim_sg_nem_cond1_weights, dim_pl_dan_cond1_weights, dim_pl_nem_cond1_weights) %>%
  group_by(Meaning, Frequency) %>%
  mutate(row_number = row_number()) %>%
  ungroup() %>%
  mutate(label = paste(Meaning, Frequency, sep = " "))

plot_df_cond1 = ggplot(plot_df_cond1_data, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Association Weight",
    color = "Meaning and Frequency",
    title = "Type Frequency Condition"
  ) +
  ylim(-2,4) +
  theme_minimal()


```

```{r}
big_pl_dan_cond2_weights = data.frame(weights = big_pl_dan_cond2) %>%
  mutate(Meaning = 'Original',
         Frequency = 'Frequent')

dim_sg_nem_cond2_weights = data.frame(weights = dim_sg_nem_cond2) %>%
  mutate(Meaning = 'Original',
         Frequency = 'Inrequent')

dim_pl_dan_cond2_weights = data.frame(weights = dim_pl_dan_cond2) %>%
  mutate(Meaning = 'Novel',
         Frequency = 'Frequent')

dim_pl_nem_cond2_weights = data.frame(weights = dim_pl_nem_cond2) %>%
  mutate(Meaning = 'Novel',
         Frequency = 'Infrequent')

plot_df_cond2_data = bind_rows(big_pl_dan_cond2_weights, dim_sg_nem_cond2_weights, dim_pl_dan_cond2_weights, dim_pl_nem_cond2_weights) %>%
  group_by(Meaning, Frequency) %>%
  mutate(row_number = row_number()) %>%
  ungroup() %>%
  mutate(label = paste(Meaning, Frequency, sep = " "))

plot_df_cond2 = ggplot(plot_df_cond2_data, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Association Weight",
    color = "Meaning and Frequency",
    title = "Token Frequency Condition"
  ) +
  ylim(-2,4) +
  theme_minimal()

```

```{r}
big_pl_dan_cond3_weights = data.frame(weights = big_pl_dan_cond3) %>%
  mutate(Meaning = 'Original',
         Frequency = 'Frequent')

dim_sg_nem_cond3_weights = data.frame(weights = dim_sg_nem_cond3) %>%
  mutate(Meaning = 'Original',
         Frequency = 'Infrequent')

dim_pl_dan_cond3_weights = data.frame(weights = dim_pl_dan_cond3) %>%
  mutate(Meaning = 'Novel',
         Frequency = 'Frequent')

dim_pl_nem_cond3_weights = data.frame(weights = dim_pl_nem_cond3) %>%
  mutate(Meaning = 'Novel',
         Frequency = 'Infrequent')

plot_df_cond3_data = bind_rows(big_pl_dan_cond3_weights, dim_sg_nem_cond3_weights, dim_pl_dan_cond3_weights, dim_pl_nem_cond3_weights) %>%
  group_by(Meaning, Frequency) %>%
  mutate(row_number = row_number()) %>%
  ungroup() %>%
  mutate(label = paste(Meaning, Frequency, sep = " "))

plot_df_cond3 = ggplot(plot_df_cond3_data, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Association Weight",              
    color = "Meaning and Frequency",
    title = "Type-Token Frequency Condition"
  ) +
  ylim(-2,4) +
  theme_minimal()

```

```{r}
library(ggpubr)
ggarrange(plot_df_cond1, plot_df_cond2, plot_df_cond3, common.legend = T)
```

## Novel stem vs Familiar Stem

to-do: get list of familiar and novel stems, get associability weights, average them. Then add the weights for "big" and "pl" or whatever meanings I want

```{r}

#cond1 familiar: bal, berko, kora, nako, pipa, bani, chool, kudom, osto, vorke, bin, mero
#cond 2 familiar: bal, berko, kora
#cond 3 familiar: bal, berko, kora, nako, pipa, bani, chool, kudom, osto, vorke, bin, mero
familiar_stems_cond1 = c('bal', 'berko', 'kora', 'nako', 'pipa', 'bani', 'chool', 'kudom', 'osto', 'vorke', 'bin', 'mero')
familiar_stems_cond1 = unname(orthoCoding(familiar_stems_cond1))


familiar_stems_cond2 = c('bal', 'berko', 'kora')
familiar_stems_cond2 = unname(orthoCoding(familiar_stems_cond2))

familiar_stems_cond3 = c('bal', 'berko', 'kora', 'nako', 'pipa', 'bani', 'chool', 'kudom', 'osto', 'vorke', 'bin', 'mero')
familiar_stems_cond3 = unname(orthoCoding(familiar_stems_cond3))


novel_stems = c('pil', 'shinti', 'mero')
novel_stems = orthoCoding(novel_stems)



process_trace_cue = function(full_string, trace_outcome, data_df) {
  substrings = strsplit(full_string, "_")[[1]]
  
  #empty_dataframe = data.frame()
  result_list = map(substrings, function(cue) {
    out = RescorlaLogistic(
      data_df, 
      nruns = n,
      traceCue = cue,
      traceOutcome = trace_outcome, 
      beta2 = b,
      alpha = b,
      beta1 = b,
      ap = F
    )

    out_tibble = as_tibble_col(out$weightvector) %>%
      set_names(cue)
    
    
    return(out_tibble)
  }) 
    final_df = bind_cols(result_list) %>%
      mutate(totalweight = rowSums(across(where(is.numeric)), na.rm = T),
             traceCue_combined = full_string) %>%
      dplyr::select(totalweight, traceCue_combined) %>%
      mutate(Index = row_number())
    
  return(final_df)
}



big_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='big', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F) #ap = T means you're learning something if the cue is absent 
pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

dim_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='dim', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)
#pl_dan_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'dan', beta2=b, alpha=b, beta1=b, ap = F)

big_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='big', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

dim_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='dim', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)
#pl_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='pl', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

sg_nem_cond1 = RescorlaLogistic(data_cond1, nruns = n, traceCue='sg', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)



big_pl_dan_cond1 = big_dan_cond1$weightvector + pl_dan_cond1$weightvector #+ cx_dan_cond1
dim_pl_dan_cond1 = dim_dan_cond1$weightvector + pl_dan_cond1$weightvector #+ cx_dan_cond1
big_pl_nem_cond1 = big_nem_cond1$weightvector + pl_nem_cond1$weightvector #+ cx_nem_cond1
dim_pl_nem_cond1 = dim_nem_cond1$weightvector + pl_nem_cond1$weightvector #+ cx_nem_cond1 
dim_sg_nem_cond1 = dim_nem_cond1$weightvector + sg_nem_cond1$weightvector #+ cx_nem_cond1


results_familiar_stems_dan_cond1 = map_df(familiar_stems_cond1, trace_outcome = 'dan', data_df = data_cond1, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_novel_stems_dan_cond1 = map_df(novel_stems, trace_outcome = 'dan', data_df = data_cond1, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_familiar_stems_nem_cond1 = map_df(familiar_stems_cond1, trace_outcome = 'nem', data_df = data_cond1, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_novel_stems_nem_cond1 = map_df(novel_stems, trace_outcome = 'nem', data_df = data_cond1, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))




#get the predicted association for #b, ba, al, l# with dan. Sum them. Do this for each familiar stem, take the mean across stems. Do the same for novel stems. Do the same for both novel and familiar stems but with nem instead of dan.

#Then get the predicted associations for big with dan and nem, dim with dan and nem, sg with dan and nem, and pl with dan and nem. 

#then for e.g., familiar stem original meanings, sum the association weights for familiar stems with association weights of big with dan and pl with dan.



  

familiar_big_pl_dan_cond1 = big_pl_dan_cond1 + results_familiar_stems_dan_cond1$`mean(totalweight)`
familiar_dim_pl_dan_cond1 = dim_pl_dan_cond1 + results_familiar_stems_dan_cond1$`mean(totalweight)` 

novel_big_pl_dan_cond1 = big_pl_dan_cond1 + results_novel_stems_dan_cond1$`mean(totalweight)` 
novel_dim_pl_dan_cond1 = dim_pl_dan_cond1 + results_novel_stems_dan_cond1$`mean(totalweight)` 

##subtract infrequent activations to compare across conditions

familiar_big_pl_nem_cond1 = big_pl_nem_cond1 + results_familiar_stems_nem_cond1$`mean(totalweight)`
familiar_dim_pl_nem_cond1 = dim_pl_nem_cond1 + results_familiar_stems_nem_cond1$`mean(totalweight)` 

novel_big_pl_nem_cond1 = big_pl_nem_cond1 + results_novel_stems_nem_cond1$`mean(totalweight)`
novel_dim_pl_nem_cond1 = dim_pl_nem_cond1 + results_novel_stems_nem_cond1$`mean(totalweight)` 


familiar_dim_sg_nem_cond1 = dim_sg_nem_cond1 + results_familiar_stems_nem_cond1$`mean(totalweight)`
novel_dim_sg_nem_cond1 = dim_sg_nem_cond1 + results_novel_stems_nem_cond1$`mean(totalweight)`

#frequent_minus_infrequent_activations_familiar_big_pl_cond3 = familiar_big_pl_dan_cond3 - familiar_big_pl_nem_cond3
frequent_minus_infrequent_activations_familiar_big_pl_cond1 = familiar_big_pl_dan_cond1 - familiar_dim_sg_nem_cond1
frequent_minus_infrequent_activations_familiar_dim_pl_cond1 = familiar_dim_pl_dan_cond1 - familiar_dim_pl_nem_cond1

#frequent_minus_infrequent_activations_novel_big_pl_cond3 = novel_big_pl_dan_cond3 - novel_big_pl_nem_cond3
frequent_minus_infrequent_activations_novel_big_pl_cond1 = novel_big_pl_dan_cond1 - novel_dim_sg_nem_cond1
frequent_minus_infrequent_activations_novel_dim_pl_cond1 = novel_dim_pl_dan_cond1 - novel_dim_pl_nem_cond1


#### Plot:


frequent_minus_infrequent_activations_familiar_big_pl_cond1_weights = data.frame(weights = frequent_minus_infrequent_activations_familiar_big_pl_cond1) %>%
  mutate(Meaning = 'Original',
         Stem = 'Familiar')

frequent_minus_infrequent_activations_familiar_dim_pl_cond1_weights = data.frame(weights = frequent_minus_infrequent_activations_familiar_dim_pl_cond1) %>%
  mutate(Meaning = 'Novel',
         Stem = 'Familiar')

frequent_minus_infrequent_activations_novel_big_pl_cond1_weights = data.frame(weights = frequent_minus_infrequent_activations_novel_big_pl_cond1) %>%
  mutate(Meaning = 'Original',
         Stem = 'Novel')

frequent_minus_infrequent_activations_novel_dim_pl_cond1_weights = data.frame(weights = frequent_minus_infrequent_activations_novel_dim_pl_cond1) %>%
  mutate(Meaning = 'Novel',
         Stem = 'Novel')

plot_df_frequent_minus_infrequent_cond1 = bind_rows(frequent_minus_infrequent_activations_familiar_big_pl_cond1_weights, frequent_minus_infrequent_activations_familiar_dim_pl_cond1_weights, frequent_minus_infrequent_activations_novel_big_pl_cond1_weights, frequent_minus_infrequent_activations_novel_dim_pl_cond1_weights) %>%
  group_by(Meaning, Stem) %>%
  mutate(row_number = row_number()) %>%
  ungroup() 

plot_df_frequent_minus_infrequent_cond1 = ggplot(plot_df_frequent_minus_infrequent_cond1, aes(x = row_number, y = weights, color = Meaning)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Frequent Activation Weight - Infrequent Activation Weight",
    color = "Meaning",
    title = "Type Frequency Condition"
  ) +
  ylim(0,4) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_frequent_minus_infrequent_cond1

```

```{r}

sg_nem_cond2 = RescorlaLogistic(data_cond2, nruns = n, traceCue='sg', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)

  

big_pl_dan_cond2 = big_dan_cond2$weightvector + pl_dan_cond2$weightvector
dim_pl_dan_cond2 = dim_dan_cond2$weightvector + pl_dan_cond2$weightvector
big_pl_nem_cond2 = big_nem_cond2$weightvector + pl_nem_cond2$weightvector
dim_pl_nem_cond2 = dim_nem_cond2$weightvector + pl_nem_cond2$weightvector
dim_sg_nem_cond2 = dim_nem_cond2$weightvector + sg_nem_cond2$weightvector


results_familiar_stems_dan_cond2 = map_df(familiar_stems_cond2, trace_outcome = 'dan', data_df = data_cond2, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_novel_stems_dan_cond2 = map_df(novel_stems, trace_outcome = 'dan', data_df = data_cond2, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_familiar_stems_nem_cond2 = map_df(familiar_stems_cond2, trace_outcome = 'nem', data_df = data_cond2, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_novel_stems_nem_cond2 = map_df(novel_stems, trace_outcome = 'nem', data_df = data_cond2, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))








familiar_big_pl_dan_cond2 = big_pl_dan_cond2 + results_familiar_stems_dan_cond2$`mean(totalweight)`
familiar_dim_pl_dan_cond2 = dim_pl_dan_cond2 + results_familiar_stems_dan_cond2$`mean(totalweight)`

novel_big_pl_dan_cond2 = big_pl_dan_cond2 + results_novel_stems_dan_cond2$`mean(totalweight)` 
novel_dim_pl_dan_cond2 = dim_pl_dan_cond2 + results_novel_stems_dan_cond2$`mean(totalweight)`

##subtract infrequent activations to compare across conditions

familiar_big_pl_nem_cond2 = big_pl_nem_cond2 + results_familiar_stems_nem_cond2$`mean(totalweight)` 
familiar_dim_pl_nem_cond2 = dim_pl_nem_cond2 + results_familiar_stems_nem_cond2$`mean(totalweight)`

novel_big_pl_nem_cond2 = big_pl_nem_cond2 + results_novel_stems_nem_cond2$`mean(totalweight)`
novel_dim_pl_nem_cond2 = dim_pl_nem_cond2 + results_novel_stems_nem_cond2$`mean(totalweight)` 


familiar_dim_sg_nem_cond2 = dim_sg_nem_cond2 + results_familiar_stems_nem_cond2$`mean(totalweight)` 
novel_dim_sg_nem_cond2 = dim_sg_nem_cond2 + results_novel_stems_nem_cond2$`mean(totalweight)` 

#frequent_minus_infrequent_activations_familiar_big_pl_cond3 = familiar_big_pl_dan_cond3 - familiar_big_pl_nem_cond3
frequent_minus_infrequent_activations_familiar_big_pl_cond2 = familiar_big_pl_dan_cond2 - familiar_dim_sg_nem_cond2
frequent_minus_infrequent_activations_familiar_dim_pl_cond2 = familiar_dim_pl_dan_cond2 - familiar_dim_pl_nem_cond2

#frequent_minus_infrequent_activations_novel_big_pl_cond3 = novel_big_pl_dan_cond3 - novel_big_pl_nem_cond3
frequent_minus_infrequent_activations_novel_big_pl_cond2 = novel_big_pl_dan_cond2 - novel_dim_sg_nem_cond2
frequent_minus_infrequent_activations_novel_dim_pl_cond2 = novel_dim_pl_dan_cond2 - novel_dim_pl_nem_cond2


#### Plot:


frequent_minus_infrequent_activations_familiar_big_pl_cond2_weights = data.frame(weights = frequent_minus_infrequent_activations_familiar_big_pl_cond2) %>%
  mutate(Meaning = 'Original',
         Stem = 'Familiar')

frequent_minus_infrequent_activations_familiar_dim_pl_cond2_weights = data.frame(weights = frequent_minus_infrequent_activations_familiar_dim_pl_cond2) %>%
  mutate(Meaning = 'Novel',
         Stem = 'Familiar')

frequent_minus_infrequent_activations_novel_big_pl_cond2_weights = data.frame(weights = frequent_minus_infrequent_activations_novel_big_pl_cond2) %>%
  mutate(Meaning = 'Original',
         Stem = 'Novel')

frequent_minus_infrequent_activations_novel_dim_pl_cond2_weights = data.frame(weights = frequent_minus_infrequent_activations_novel_dim_pl_cond2) %>%
  mutate(Meaning = 'Novel',
         Stem = 'Novel')

plot_df_frequent_minus_infrequent_cond2 = bind_rows(frequent_minus_infrequent_activations_familiar_big_pl_cond2_weights, frequent_minus_infrequent_activations_familiar_dim_pl_cond2_weights, frequent_minus_infrequent_activations_novel_big_pl_cond2_weights, frequent_minus_infrequent_activations_novel_dim_pl_cond2_weights) %>%
  group_by(Meaning, Stem) %>%
  mutate(row_number = row_number()) %>%
  ungroup() 

plot_df_frequent_minus_infrequent_cond2 = ggplot(plot_df_frequent_minus_infrequent_cond2, aes(x = row_number, y = weights, color = Meaning)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Frequent Activation Weight - Infrequent Activation Weight",
    color = "Meaning",
    title = "Token Frequency Condition"
  ) +
  ylim(0,4) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_frequent_minus_infrequent_cond2
```

```{r}
sg_nem_cond3 = RescorlaLogistic(data_cond3, nruns = n, traceCue='sg', traceOutcome = 'nem', beta2=b, alpha=b, beta1=b, ap = F)


  
big_pl_dan_cond3 = big_dan_cond3$weightvector + pl_dan_cond3$weightvector
dim_pl_dan_cond3 = dim_dan_cond3$weightvector + pl_dan_cond3$weightvector
big_pl_nem_cond3 = big_nem_cond3$weightvector + pl_nem_cond3$weightvector
dim_pl_nem_cond3 = dim_nem_cond3$weightvector + pl_nem_cond3$weightvector
dim_sg_nem_cond3 = dim_nem_cond3$weightvector + sg_nem_cond3$weightvector



results_familiar_stems_dan_cond3 = map_df(familiar_stems_cond3, trace_outcome = 'dan', data_df = data_cond3, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_novel_stems_dan_cond3 = map_df(novel_stems, trace_outcome = 'dan', data_df = data_cond3, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_familiar_stems_nem_cond3 = map_df(familiar_stems_cond3, trace_outcome = 'nem', data_df = data_cond3, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))

results_novel_stems_nem_cond3 = map_df(novel_stems, trace_outcome = 'nem', data_df = data_cond3, process_trace_cue) %>%
  group_by(Index) %>%
  summarize(mean(totalweight))








familiar_big_pl_dan_cond3 = big_pl_dan_cond3 + results_familiar_stems_dan_cond3$`mean(totalweight)`
familiar_dim_pl_dan_cond3 = dim_pl_dan_cond3 + results_familiar_stems_dan_cond3$`mean(totalweight)` 

novel_big_pl_dan_cond3 = big_pl_dan_cond3 + results_novel_stems_dan_cond3$`mean(totalweight)` 
novel_dim_pl_dan_cond3 = dim_pl_dan_cond3 + results_novel_stems_dan_cond3$`mean(totalweight)` 

##subtract infrequent activations to compare across conditions

familiar_big_pl_nem_cond3 = big_pl_nem_cond3 + results_familiar_stems_nem_cond3$`mean(totalweight)` 
familiar_dim_pl_nem_cond3 = dim_pl_nem_cond3 + results_familiar_stems_nem_cond3$`mean(totalweight)`

novel_big_pl_nem_cond3 = big_pl_nem_cond3 + results_novel_stems_nem_cond3$`mean(totalweight)` 
novel_dim_pl_nem_cond3 = dim_pl_nem_cond3 + results_novel_stems_nem_cond3$`mean(totalweight)` 

familiar_dim_sg_nem_cond3 = dim_sg_nem_cond3 + results_familiar_stems_nem_cond3$`mean(totalweight)` 
novel_dim_sg_nem_cond3 = dim_sg_nem_cond3 + results_novel_stems_nem_cond3$`mean(totalweight)`

#frequent_minus_infrequent_activations_familiar_big_pl_cond3 = familiar_big_pl_dan_cond3 - familiar_big_pl_nem_cond3
frequent_minus_infrequent_activations_familiar_big_pl_cond3 = familiar_big_pl_dan_cond3 - familiar_dim_sg_nem_cond3
frequent_minus_infrequent_activations_familiar_dim_pl_cond3 = familiar_dim_pl_dan_cond3 - familiar_dim_pl_nem_cond3

#frequent_minus_infrequent_activations_novel_big_pl_cond3 = novel_big_pl_dan_cond3 - novel_big_pl_nem_cond3
frequent_minus_infrequent_activations_novel_big_pl_cond3 = novel_big_pl_dan_cond3 - novel_dim_sg_nem_cond3
frequent_minus_infrequent_activations_novel_dim_pl_cond3 = novel_dim_pl_dan_cond3 - novel_dim_pl_nem_cond3


#### Plot:


frequent_minus_infrequent_activations_familiar_big_pl_cond3_weights = data.frame(weights = frequent_minus_infrequent_activations_familiar_big_pl_cond3) %>%
  mutate(Meaning = 'Original',
         Stem = 'Familiar')

frequent_minus_infrequent_activations_familiar_dim_pl_cond3_weights = data.frame(weights = frequent_minus_infrequent_activations_familiar_dim_pl_cond3) %>%
  mutate(Meaning = 'Novel',
         Stem = 'Familiar')

frequent_minus_infrequent_activations_novel_big_pl_cond3_weights = data.frame(weights = frequent_minus_infrequent_activations_novel_big_pl_cond3) %>%
  mutate(Meaning = 'Original',
         Stem = 'Novel')

frequent_minus_infrequent_activations_novel_dim_pl_cond3_weights = data.frame(weights = frequent_minus_infrequent_activations_novel_dim_pl_cond3) %>%
  mutate(Meaning = 'Novel',
         Stem = 'Novel')

plot_df_frequent_minus_infrequent_cond3 = bind_rows(frequent_minus_infrequent_activations_familiar_big_pl_cond3_weights, frequent_minus_infrequent_activations_familiar_dim_pl_cond3_weights, frequent_minus_infrequent_activations_novel_big_pl_cond3_weights, frequent_minus_infrequent_activations_novel_dim_pl_cond3_weights) %>%
  group_by(Meaning, Stem) %>%
  mutate(row_number = row_number()) %>%
  ungroup() 

plot_df_frequent_minus_infrequent_cond3 = ggplot(plot_df_frequent_minus_infrequent_cond3, aes(x = row_number, y = weights, color = Meaning)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Frequent Activation Weight - Infrequent Activation Weight",
    color = "Meaning",
    title = "Type-Token Condition"
  ) +
  ylim(0,4) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_frequent_minus_infrequent_cond3
```

```{r}
ggarrange(plot_df_frequent_minus_infrequent_cond1, plot_df_frequent_minus_infrequent_cond2, plot_df_frequent_minus_infrequent_cond3)
```

## without subtracting out infrequent

```{r}


familiar_big_pl_dan_cond1 = big_pl_dan_cond1 + results_familiar_stems_dan_cond1$`mean(totalweight)` #+ cx_dan_cond1
familiar_dim_pl_dan_cond1 = dim_pl_dan_cond1 + results_familiar_stems_dan_cond1$`mean(totalweight)` #+ cx_dan_cond1

novel_big_pl_dan_cond1 = big_pl_dan_cond1 + results_novel_stems_dan_cond1$`mean(totalweight)` #+ cx_dan_cond1 
novel_dim_pl_dan_cond1 = dim_pl_dan_cond1 + results_novel_stems_dan_cond1$`mean(totalweight)` #+ cx_dan_cond1

familiar_big_pl_nem_cond1 = big_pl_nem_cond1 + results_familiar_stems_nem_cond1$`mean(totalweight)`  #+ cx_nem_cond1
familiar_dim_pl_nem_cond1 = dim_pl_nem_cond1 + results_familiar_stems_nem_cond1$`mean(totalweight)`  #+ cx_nem_cond1
 
novel_big_pl_nem_cond1 = big_pl_nem_cond1 + results_novel_stems_nem_cond1$`mean(totalweight)`  #+ cx_nem_cond1
novel_dim_pl_nem_cond1 = dim_pl_nem_cond1 + results_novel_stems_nem_cond1$`mean(totalweight)` #+ cx_nem_cond1


familiar_dim_sg_nem_cond1 = dim_sg_nem_cond1 + results_familiar_stems_nem_cond1$`mean(totalweight)`  #+ cx_nem_cond1
novel_dim_sg_nem_cond1 = dim_sg_nem_cond1 + results_novel_stems_nem_cond1$`mean(totalweight)`  #+ cx_nem_cond1


#### Plot:

plot_familiar_big_pl_dan_cond1 = data.frame(weights = familiar_big_pl_dan_cond1) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Original',
    Frequency = 'Frequent'
  )

plot_familiar_dim_pl_dan_cond1 = data.frame(weights = familiar_dim_pl_dan_cond1) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Novel',
    Frequency = 'Frequent'
  )

plot_novel_big_pl_dan_cond1 = data.frame(weights = novel_big_pl_dan_cond1) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Original',
    Frequency = 'Frequent'
  )

plot_novel_dim_pl_dan_cond1 = data.frame(weights = novel_dim_pl_dan_cond1) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Novel',
    Frequency = 'Frequent'
  )

## now with nem

plot_familiar_dim_sg_nem_cond1 = data.frame(weights = familiar_dim_sg_nem_cond1) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Original',
    Frequency = 'Infrequent'
  )

plot_familiar_dim_pl_nem_cond1 = data.frame(weights = familiar_dim_pl_nem_cond1) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Novel',
    Frequency = 'Infrequent'
  )

plot_novel_dim_sg_nem_cond1 = data.frame(weights = novel_dim_sg_nem_cond1) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Original',
    Frequency = 'Infrequent'
  )

plot_novel_dim_pl_nem_cond1 = data.frame(weights = novel_dim_pl_nem_cond1) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Novel',
    Frequency = 'Infrequent'
  )





plot_df_stems_all_cond1 = bind_rows(plot_familiar_big_pl_dan_cond1,
                              plot_familiar_dim_pl_dan_cond1,
                              plot_novel_big_pl_dan_cond1,
                              plot_novel_dim_pl_dan_cond1,
                              plot_familiar_dim_sg_nem_cond1,
                              plot_familiar_dim_pl_nem_cond1,
                              plot_novel_dim_sg_nem_cond1,
                              plot_novel_dim_pl_nem_cond1) %>%
  group_by(Meaning, Stem, Frequency) %>%
  mutate(row_number = row_number()) %>%
  ungroup() %>%
  mutate(label = paste(Meaning, Frequency, sep = " "))

plot_df_stems_cond1 = ggplot(plot_df_stems_all_cond1, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Type Frequency Condition"
  ) +
  #ylim(-2,4) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond1

```

```{r}



familiar_big_pl_dan_cond2 = big_pl_dan_cond2 + results_familiar_stems_dan_cond2$`mean(totalweight)` #+ cx_dan_cond2
familiar_dim_pl_dan_cond2 = dim_pl_dan_cond2 + results_familiar_stems_dan_cond2$`mean(totalweight)` #+ cx_dan_cond2 

novel_big_pl_dan_cond2 = big_pl_dan_cond2 + results_novel_stems_dan_cond2$`mean(totalweight)` #+ cx_dan_cond2 
novel_dim_pl_dan_cond2 = dim_pl_dan_cond2 + results_novel_stems_dan_cond2$`mean(totalweight)` #+ cx_dan_cond2 


familiar_big_pl_nem_cond2 = big_pl_nem_cond2 + results_familiar_stems_nem_cond2$`mean(totalweight)`   #+ cx_nem_cond2
familiar_dim_pl_nem_cond2 = dim_pl_nem_cond2 + results_familiar_stems_nem_cond2$`mean(totalweight)` #+ cx_nem_cond2 

novel_big_pl_nem_cond2 = big_pl_nem_cond2 + results_novel_stems_nem_cond2$`mean(totalweight)` #+ cx_nem_cond2
novel_dim_pl_nem_cond2 = dim_pl_nem_cond2 + results_novel_stems_nem_cond2$`mean(totalweight)` #+ cx_nem_cond2 


familiar_dim_sg_nem_cond2 = dim_sg_nem_cond2 + results_familiar_stems_nem_cond2$`mean(totalweight)` #+ cx_nem_cond2
novel_dim_sg_nem_cond2 = dim_sg_nem_cond2 + results_novel_stems_nem_cond2$`mean(totalweight)` #+ cx_nem_cond2


#### Plot:

plot_familiar_big_pl_dan_cond2 = data.frame(weights = familiar_big_pl_dan_cond2) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Original',
    Frequency = 'Frequent'
  )

plot_familiar_dim_pl_dan_cond2 = data.frame(weights = familiar_dim_pl_dan_cond2) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Novel',
    Frequency = 'Frequent'
  )

plot_novel_big_pl_dan_cond2 = data.frame(weights = novel_big_pl_dan_cond2) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Original',
    Frequency = 'Frequent'
  )

plot_novel_dim_pl_dan_cond2 = data.frame(weights = novel_dim_pl_dan_cond2) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Novel',
    Frequency = 'Frequent'
  )

## now with nem

plot_familiar_dim_sg_nem_cond2 = data.frame(weights = familiar_dim_sg_nem_cond2) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Original',
    Frequency = 'Infrequent'
  )

plot_familiar_dim_pl_nem_cond2 = data.frame(weights = familiar_dim_pl_nem_cond2) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Novel',
    Frequency = 'Infrequent'
  )

plot_novel_dim_sg_nem_cond2 = data.frame(weights = novel_dim_sg_nem_cond2) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Original',
    Frequency = 'Infrequent'
  )

plot_novel_dim_pl_nem_cond2 = data.frame(weights = novel_dim_pl_nem_cond2) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Novel',
    Frequency = 'Infrequent'
  )





plot_df_stems_all_cond2 = bind_rows(plot_familiar_big_pl_dan_cond2,
                              plot_familiar_dim_pl_dan_cond2,
                              plot_novel_big_pl_dan_cond2,
                              plot_novel_dim_pl_dan_cond2,
                              plot_familiar_dim_sg_nem_cond2,
                              plot_familiar_dim_pl_nem_cond2,
                              plot_novel_dim_sg_nem_cond2,
                              plot_novel_dim_pl_nem_cond2) %>%
  group_by(Meaning, Stem, Frequency) %>%
  mutate(row_number = row_number()) %>%
  ungroup() %>%
  mutate(label = paste(Meaning, Frequency, sep = " "))

plot_df_stems_cond2 = ggplot(plot_df_stems_all_cond2, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Token Frequency Condition"
  ) +
  #ylim(-2,4) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond2

#write_csv(plot_df_stems_all_cond2, '../Data/plot_df_stems_all_cond2.csv')

```

```{r}
familiar_big_pl_dan_cond3 = big_pl_dan_cond3 + results_familiar_stems_dan_cond3$`mean(totalweight)` #+ cx_dan_cond3 
familiar_dim_pl_dan_cond3 = dim_pl_dan_cond3 + results_familiar_stems_dan_cond3$`mean(totalweight)` #+ cx_dan_cond3 

novel_big_pl_dan_cond3 = big_pl_dan_cond3 + results_novel_stems_dan_cond3$`mean(totalweight)` #+ cx_dan_cond3 
novel_dim_pl_dan_cond3 = dim_pl_dan_cond3 + results_novel_stems_dan_cond3$`mean(totalweight)` #+ cx_dan_cond3  


familiar_big_pl_nem_cond3 = big_pl_nem_cond3 + results_familiar_stems_nem_cond3$`mean(totalweight)` #+ cx_nem_cond3 
familiar_dim_pl_nem_cond3 = dim_pl_nem_cond3 + results_familiar_stems_nem_cond3$`mean(totalweight)` #+ cx_nem_cond3

novel_big_pl_nem_cond3 = big_pl_nem_cond3 + results_novel_stems_nem_cond3$`mean(totalweight)` #+ cx_nem_cond3 
novel_dim_pl_nem_cond3 = dim_pl_nem_cond3 + results_novel_stems_nem_cond3$`mean(totalweight)` #+ cx_nem_cond3


familiar_dim_sg_nem_cond3 = dim_sg_nem_cond3 + results_familiar_stems_nem_cond3$`mean(totalweight)` #+ cx_nem_cond3
novel_dim_sg_nem_cond3 = dim_sg_nem_cond3 + results_novel_stems_nem_cond3$`mean(totalweight)` #+ cx_nem_cond3


#### Plot:

plot_familiar_big_pl_dan_cond3 = data.frame(weights = familiar_big_pl_dan_cond3) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Original',
    Frequency = 'Frequent'
  )

plot_familiar_dim_pl_dan_cond3 = data.frame(weights = familiar_dim_pl_dan_cond3) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Novel',
    Frequency = 'Frequent'
  )

plot_novel_big_pl_dan_cond3 = data.frame(weights = novel_big_pl_dan_cond3) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Original',
    Frequency = 'Frequent'
  )

plot_novel_dim_pl_dan_cond3 = data.frame(weights = novel_dim_pl_dan_cond3) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Novel',
    Frequency = 'Frequent'
  )

## now with nem

plot_familiar_dim_sg_nem_cond3 = data.frame(weights = familiar_dim_sg_nem_cond3) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Original',
    Frequency = 'Infrequent'
  )

plot_familiar_dim_pl_nem_cond3 = data.frame(weights = familiar_dim_pl_nem_cond3) %>%
  mutate(
    Stem = 'Familiar',
    Meaning = 'Novel',
    Frequency = 'Infrequent'
  )

plot_novel_dim_sg_nem_cond3 = data.frame(weights = novel_dim_sg_nem_cond3) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Original',
    Frequency = 'Infrequent'
  )

plot_novel_dim_pl_nem_cond3 = data.frame(weights = novel_dim_pl_nem_cond3) %>%
  mutate(
    Stem = 'Novel',
    Meaning = 'Novel',
    Frequency = 'Infrequent'
  )





plot_df_stems_all_cond3 = bind_rows(plot_familiar_big_pl_dan_cond3,
                              plot_familiar_dim_pl_dan_cond3,
                              plot_novel_big_pl_dan_cond3,
                              plot_novel_dim_pl_dan_cond3,
                              plot_familiar_dim_sg_nem_cond3,
                              plot_familiar_dim_pl_nem_cond3,
                              plot_novel_dim_sg_nem_cond3,
                              plot_novel_dim_pl_nem_cond3) %>%
  group_by(Meaning, Stem, Frequency) %>%
  mutate(row_number = row_number()) %>%
  ungroup() %>%
  mutate(label = paste(Meaning, Frequency, sep = " "))


#write_csv(plot_df_stems_all_cond1, '../Data/plot_df_stems_all_cond1.csv')

plot_df_stems_cond3 = ggplot(plot_df_stems_all_cond3, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Type-Token Frequency Condition"
  ) +
  #ylim(-2,4) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond3


```

### full plot

```{r}
ggarrange(plot_df_stems_cond1, plot_df_stems_cond2, plot_df_stems_cond3, common.legend = T)
```

```{r}
cond1_estimates = plot_df_stems_all_cond1 %>%
  group_by(Stem, Meaning, Frequency) %>%
  slice_tail(n=1) %>%
  ungroup() %>%
  dplyr::select(Stem, Meaning, Frequency, weights) %>%
  group_by(Stem, Meaning) %>%
  pivot_wider(names_from = Frequency, values_from = weights) %>%
  mutate(freq_to_infreq = Frequent - Infrequent) %>%
  mutate(Condition = 'Type Frequency')


cond2_estimates = plot_df_stems_all_cond2 %>%
  group_by(Stem, Meaning, Frequency) %>%
  slice_tail(n=1) %>%
  ungroup() %>%
  dplyr::select(Stem, Meaning, Frequency, weights) %>%
  group_by(Stem, Meaning) %>%
  pivot_wider(names_from = Frequency, values_from = weights) %>%
  mutate(freq_to_infreq = Frequent - Infrequent) %>%
  mutate(Condition = 'Token Frequency')

cond3_estimates = plot_df_stems_all_cond3 %>%
  group_by(Stem, Meaning, Frequency) %>%
  slice_tail(n=1) %>%
  ungroup() %>%
  dplyr::select(Stem, Meaning, Frequency, weights) %>%
  group_by(Stem, Meaning) %>%
  pivot_wider(names_from = Frequency, values_from = weights) %>%
  mutate(freq_to_infreq = Frequent - Infrequent) %>%
  mutate(Condition = 'Type-Token Frequency')


all_cond_estimates = rbind(cond1_estimates, cond2_estimates, cond3_estimates) %>%
  mutate(label = paste(Stem, Meaning))


all_cond_estimates = all_cond_estimates %>%
  mutate(freq = invlogit(Frequent),
         infreq = invlogit(Infrequent),
         freq_probs = freq / (freq + infreq))
         

#write_csv(all_cond_estimates, '../Data/all_cond_estimates.csv')
  
all_cond_estimates$Condition = factor(all_cond_estimates$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))

ggplot(data = all_cond_estimates) +
  geom_col(aes(x = Condition, y = freq_probs, fill = Meaning), position='dodge') +
  facet_wrap(~Stem) +
  theme_bw()


```
