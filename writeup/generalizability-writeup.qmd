---
#title: "generalizability-writeup"
format: 
  pdf:
    fontsize: 12pt
    mainfont: "Crimson"        # Primary text font
    CJKmainfont: "Noto Serif KR"  # Font for Korean text
    geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in
    

header-includes:
- \usepackage{amsmath}
- \usepackage{fontspec}    % Ensure font support
- \usepackage{placeins}
- \usepackage{float}
- \usepackage{setspace}
- \usepackage{indentfirst}


echo: false
warning: false
message: false

editor: visual
bibliography: references.bib
csl: apa.csl
---

```{r, echo = F, warning = F, message = F}
library(tidyverse)
library(knitr)
library(kableExtra)
library(brms)
library(sjPlot)


fixed_effects_df_all = read_csv('../Data/fixed_effects_df_all.csv')
subject_effects = read_csv('../Data/subject_effects.csv')

fixed_effects_df_all$Task = factor(fixed_effects_df_all$Task, levels = c('prod', '2afc', 'comprehension'))

subject_effects$Task = factor(subject_effects$Task, levels = c('prod', '2afc', 'comprehension'))



condition_labels = c("cond1" = "Type Frequency", 
                      "cond2" = "Token Frequency", 
                      "cond3" = "Type-Token Frequency")
task_labels = c("prod" = "Production",
                "2afc" = "Form-Choice",
                "comprehension" = "Comprehension")

fixed_effects_df_all$Meaning = factor(fixed_effects_df_all$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

subject_effects$Meaning = factor(subject_effects$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

fixed_effects_df_all$Stem = factor(fixed_effects_df_all$Stem, 
                                  levels = c("familiar", "novel"), 
                                  labels = c("Familiar", "Novel"))

subject_effects$Stem = factor(subject_effects$Stem, 
                                  levels = c("familiar", "novel"), 
                                  labels = c("Familiar", "Novel"))


# model_prod_original = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
#                                        data = data_prod_original,
#                                        family = bernoulli(link = 'logit'),
#                                        iter = 14000, 
#                                        warmup = 7000,
#                                        chains = 4,
#                                        cores = 4,
#                                        prior = priors_m1,
#                                        control = list(adapt_delta = 0.99),
#                                        file = '../Data/model_prod_original')
# 
# model_prod_novel = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
#                                        data = data_prod_novel,
#                                        family = bernoulli(link = 'logit'),
#                                        iter = 14000, 
#                                        warmup = 7000,
#                                        chains = 4,
#                                        cores = 4,
#                                        prior = priors_m1,
#                                        control = list(adapt_delta = 0.99),
#                                        file = '../Data/model_prod_novel')



model_prod_both = brm(frequency ~ condition*meaning + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_both')



percent_greater_zero_both = data.frame(fixef(model_prod_both, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'condition1:meaning1', 'condition2:meaning1')))


fixefs_model_prod_both = as.data.frame(fixef(model_prod_both)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_prod_both_stems = brm(frequency ~ condition*meaning*stem_condition + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_both_stem')



percent_greater_zero_both_stems = data.frame(fixef(model_prod_both_stems, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both_stems = percent_greater_zero_both_stems %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_model_prod_both_stems = as.data.frame(fixef(model_prod_both_stems)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both_stems$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


rownames(fixefs_model_prod_both_stems) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')


model_2afc_both = brm(frequency ~ condition*meaning + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both')


percent_greater_zero_both = data.frame(fixef(model_2afc_both, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'condition1:meaning1', 'condition2:meaning1')))


fixefs_model_2afc_both = as.data.frame(fixef(model_2afc_both)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_2afc_both) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Type Frequency:Novel', 'Token Frequency:Novel')



model_2afc_both_stem = brm(frequency ~ condition*meaning*stem_condition + (1 + meaning | participant),
                                       data = data_2afc_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both_stem')




percent_greater_zero_both = data.frame(fixef(model_2afc_both_stem, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_model_2afc_both_stem = as.data.frame(fixef(model_2afc_both_stem)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_2afc_both_stem) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')



model_2afc_prod_both_stem = brm(frequency ~ condition*meaning*stem_condition*task + (1 + meaning * task | participant),
                                       data = data_prod_2afc_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_prod_both_stem')


percent_greater_zero_both = data.frame(fixef(model_2afc_prod_both_stem, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient,gsub(":", ".", rownames(data.frame(fixef(model_2afc_prod_both_stem))))))


fixefs_model_prod_2afc_both_stem = as.data.frame(fixef(model_2afc_prod_both_stem)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



#rownames(fixefs_model_prod_2afc_both_stem) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')





model_comprehension_numeric = brm(meaning ~ condition_numeric + (1 | participant),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric')

percent_greater_zero_comprehension_numeric = data.frame(fixef(model_comprehension_numeric, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_comprehension_numeric = percent_greater_zero_comprehension_numeric %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition_numeric12M12', 'condition_numeric3M3')))


fixefs_model_comprehension_numeric = as.data.frame(fixef(model_comprehension_numeric)) %>%
    mutate(percent_greater_zero = percent_greater_zero_comprehension_numeric$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_comprehension_numeric) = c('Intercept', '12-12', '3-3')


model_comprehension_numeric_stem = brm(meaning ~ condition_numeric*stem_condition + (1 | participant),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric_stem_test')

percent_greater_zero_comprehension_numeric_stem = data.frame(fixef(model_comprehension_numeric_stem, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_comprehension_numeric_stem = percent_greater_zero_comprehension_numeric_stem %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition_numeric12M12', 'condition_numeric3M3', 'stem_condition1', 'condition_numeric12M12.stem_condition1', 'condition_numeric3M3.stem_condition1')))



fixefs_model_comprehension_numeric_stem = as.data.frame(fixef(model_comprehension_numeric_stem)) %>%
    mutate(percent_greater_zero = percent_greater_zero_comprehension_numeric_stem$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_comprehension_numeric_stem) = c('Intercept', '12-12', '3-3', 'Novel Stem', '12-12:Novel Stem', '3-3:Novel Stem')


plot_df_stems_all_cond1 = read_csv('../Data/plot_df_stems_all_cond1_linear.csv')
plot_df_stems_all_cond2 = read_csv('../Data/plot_df_stems_all_cond2_linear.csv')
plot_df_stems_all_cond3 = read_csv('../Data/plot_df_stems_all_cond3_linear.csv')

plot_df_stems_cond1 = ggplot(plot_df_stems_all_cond1, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Type Frequency Condition"
  ) +
  ylim(-1.5,2) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond2 = ggplot(plot_df_stems_all_cond2, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Token Frequency Condition"
  ) +
  ylim(-1.5,2) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond3 = ggplot(plot_df_stems_all_cond3, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Type-Token Frequency Condition"
  ) +
  ylim(-1.5,2) +
  facet_wrap(~Stem) +
  theme_minimal()

all_cond_estimates_paper = read_csv('../Data/all_cond_estimates_linear.csv')

all_cond_estimates_paper$Condition = factor(all_cond_estimates_paper$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))

all_cond_estimates_paper2 = read_csv('../Data/all_cond_estimates_for_paper2.csv')

all_cond_estimates_paper2$Condition = factor(all_cond_estimates_paper2$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))




model_prod_both_stem_rw = brm(frequency ~ condition*meaning*stem_condition + freq_minus_infreq + (1 + stem_condition*meaning | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_both_stem_rw_preds_final')


percent_greater_zero_rw_preds = data.frame(fixef(model_prod_both_stem_rw, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_rw_preds = percent_greater_zero_rw_preds %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'freq_minus_infreq', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_model_rw_preds = as.data.frame(fixef(model_prod_both_stem_rw)) %>%
    mutate(percent_greater_zero = percent_greater_zero_rw_preds$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)

#fixefs_model_rw_preds

rownames(fixefs_model_rw_preds) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Frequent - Infrequent (RW)', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')


model_human_rw_preds = brm(frequency ~ freq_minus_infreq + (1 | participant) + (1|resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 15000, 
                                       warmup = 7500,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_rw_preds')

model_prod_both_stem_rw_simple = brm(frequency ~ condition*meaning*stem_condition + freq_minus_infreq + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_both_stem_rw_simple')


model_prod_both_stem_simple_humans = brm(frequency ~ condition*meaning*stem_condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_both_stem_simple_humans')

model_prod_rw_stem_suffix_vary = brm(frequency ~ freq_minus_infreq_stem + freq_minus_infreq_suffix + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_stem_suffix_vary,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_rw_stem_suffix_vary')

percent_greater_zero_rw_preds_stem_suffix_vary = data.frame(fixef(model_prod_rw_stem_suffix_vary, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_rw_preds_stem_suffix_vary = percent_greater_zero_rw_preds_stem_suffix_vary %>%
  arrange(match(beta_coefficient, c('Intercept', 'freq_minus_infreq_stem', 'freq_minus_infreq_suffix')))


fixefs_model_rw_preds_stem_suffix_vary = as.data.frame(fixef(model_prod_rw_stem_suffix_vary)) %>%
    mutate(percent_greater_zero = percent_greater_zero_rw_preds_stem_suffix_vary$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_prod_rw_stem_suffix_vary_by_condition = brm(frequency ~ freq_minus_infreq_stem + freq_minus_infreq_suffix + condition + freq_minus_infreq_stem:condition + freq_minus_infreq_suffix:condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_stem_suffix_vary,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_rw_stem_suffix_vary_by_condition')

percent_greater_zero_rw_preds_stem_suffix_vary_by_condition = data.frame(fixef(model_prod_rw_stem_suffix_vary_by_condition, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_rw_preds_stem_suffix_vary_by_condition = percent_greater_zero_rw_preds_stem_suffix_vary_by_condition %>%
  arrange(match(beta_coefficient, c('Intercept', 'freq_minus_infreq_stem', 'freq_minus_infreq_suffix', 'condition1', 'condition2', 'freq_minus_infreq_stem.condition1', 'freq_minus_infreq_stem.condition2', 'freq_minus_infreq_suffix.condition1', 'freq_minus_infreq_suffix.condition2')))


fixefs_model_rw_preds_stem_suffix_vary_by_condition = as.data.frame(fixef(model_prod_rw_stem_suffix_vary_by_condition)) %>%
    mutate(percent_greater_zero = percent_greater_zero_rw_preds_stem_suffix_vary_by_condition$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_prod_rw_stem_suffix_vary_by_condition_original_preds = brm(frequency ~ condition*meaning*stem_condition + freq_minus_infreq_stem + freq_minus_infreq_suffix + freq_minus_infreq_stem:condition + freq_minus_infreq_suffix:condition + (1 | participant) + (1 | resp_stem), 
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_stem_suffix_vary,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_rw_stem_suffix_vary_by_condition_original_preds')

percent_greater_zero_rw_preds_stem_suffix_vary_by_condition_original_preds = data.frame(fixef(model_prod_rw_stem_suffix_vary_by_condition_original_preds, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_rw_preds_stem_suffix_vary_by_condition_original_preds = percent_greater_zero_rw_preds_stem_suffix_vary_by_condition_original_preds %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'freq_minus_infreq_stem', 'freq_minus_infreq_suffix', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.freq_minus_infreq_stem', 'condition2.freq_minus_infreq_stem', 'condition1.freq_minus_infreq_suffix', 'condition2.freq_minus_infreq_suffix', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1'))) 

model_prod_rw_stem_suffix_vary_no_interaction = brm(frequency ~ freq_minus_infreq_stem + freq_minus_infreq_suffix + condition + (1 | participant) + (1 | resp_stem), #resp_stem intercept removed because it's redundant with freq_minus_infreq_stem
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_stem_suffix_vary,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_rw_stem_suffix_vary_no_interaction')


fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds = as.data.frame(fixef(model_prod_rw_stem_suffix_vary_by_condition_original_preds)) %>%
    mutate(percent_greater_zero = percent_greater_zero_rw_preds_stem_suffix_vary_by_condition_original_preds$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_human_conf_sem_preds = brm(frequency ~ freq_minus_infreq + (1 | participant) + (1|resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_sem_alpha,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_conf_sem_preds')


percent_greater_zero_model_human_conf_sem_preds = data.frame(fixef(model_human_conf_sem_preds, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_model_human_conf_sem_preds = percent_greater_zero_model_human_conf_sem_preds %>%
  arrange(match(beta_coefficient, c('Intercept', 'freq_minus_infreq_stem', 'freq_minus_infreq_suffix', 'freq_minus_infreq_stem.freq_minus_infreq_suffix')))


fixefs_model_model_human_conf_sem_preds = as.data.frame(fixef(model_human_conf_sem_preds)) %>%
    mutate(percent_greater_zero = percent_greater_zero_model_human_conf_sem_preds$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_human_conf_sem_preds_original_preds = brm(frequency ~ freq_minus_infreq + condition*meaning*stem_condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_sem_alpha,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_conf_sem_preds_original_preds')


loo_co_results = data.frame(loo_compare(model_human_rw_preds, model_prod_rw_stem_suffix_vary, model_prod_both_stem_rw_simple, model_prod_both_stem_simple_humans, model_prod_rw_stem_suffix_vary_by_condition, model_prod_rw_stem_suffix_vary_by_condition_original_preds)) %>%
  mutate('term' = c('Original Predictors Plus RW Activations', 'Original Statistical Predictors', 'Stem and Meaning Activations by Condition Plus Original Predictors', 'Stem and Meaning Activations by Condition', 'Stem and Meaning Activations as Separate Predictors', 'Only RW Activation')) 


  




fixed_effects_df = read_csv('../Data/fixed_effects_df_all.csv') %>%
  filter(Task == 'prod')

observed_estimates = fixed_effects_df 


observed_estimates_plot = ggplot(data = observed_estimates, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = "dodge") +
  ylim(c(0,1)) +
  facet_wrap(~Condition)




model_human_conf = brm(frequency ~ freq_minus_infreq + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_conf,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_conf')


model_human_conf_original_preds = brm(frequency ~ freq_minus_infreq + condition*meaning*stem_condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_conf,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_conf_original_preds')

model_human_conf_sem_preds_vary_by_condition = brm(frequency ~ freq_minus_infreq*condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_sem_alpha,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_conf_sem_preds_vary_by_condition')

model_human_mod_sem_alpha = brm(frequency ~ freq_minus_infreq + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_nonconf_sem_alpha,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_mod_sem_alpha')

model_human_mod_sem_alpha_original_preds = brm(frequency ~ freq_minus_infreq + condition*meaning*stem_condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_nonconf_sem_alpha,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_mod_sem_alpha_original_preds')



#loo_co_results_add = data.frame(loo_compare(model_human_rw_preds, model_prod_rw_stem_suffix_vary, model_prod_both_stem_rw_simple, model_prod_both_stem_simple_humans, model_prod_rw_stem_suffix_vary_by_condition, model_prod_rw_stem_suffix_vary_by_condition_original_preds, model_human_conf_sem_preds)) %>%
  #mutate('term' = c('Configural Cues and Increased Saliency of Semantic Cues', 'Original Predictors Plus RW Activations', 'Original Statistical Predictors', 'Stem and Meaning Activations by Condition Plus Original Predictors', 'Stem and Meaning Activations by Condition', 'Stem and Meaning Activations as Separate Predictors', 'Only RW Activation')) 

loo_co_results_add = data.frame(loo_compare(model_human_rw_preds, model_prod_both_stem_simple_humans, model_prod_rw_stem_suffix_vary_no_interaction,  model_prod_rw_stem_suffix_vary_by_condition, model_human_conf_sem_preds, model_human_conf, model_human_conf_sem_preds_original_preds, model_human_conf_sem_preds_vary_by_condition, model_human_mod_sem_alpha)) %>%
  mutate('term' = c('Configural Cues, Increased Saliency of Semantic Cues, and Original Statistical Predictors',
                    'Configural Cues and Increased Saliency of Semantic Cues',
                    'Configural Cues and Increased Saliency of Semantic Cues Varying by Condition',
                    'Only Increased Saliency of Semantic Cues',
                    'Only Configural Cues',
                    'Original Statistical Predictors', 
                    'Stem and Meaning Activations by Condition',
                    'Only RW Activation',
                    'Stem and Meaning Activations (not by Condition)')) 





######### RW COMPREHENSION ######################
#################################################


priors_m1 = c(
  prior(student_t(3, 0, 1), class = 'Intercept'), #0.5 might seem small, but in logistic regression this is still quite large since a-prior exp(1) = 2.7 is still plausible.
  prior(student_t(3, 0, 1), class = 'b'),
  prior(student_t(3, 0, 1), class = 'sd'))



model_comprehension_numeric_rw = brm(meaning ~ new_minus_old + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 16000, 
                                       warmup = 8000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric_rw')

model_comprehension_numeric_rw_by_cond = brm(meaning ~ condition_numeric*new_minus_old + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric_rw_by_cond')



percent_greater_zero_model_comprehension_numeric_rw_by_cond = data.frame(fixef(model_comprehension_numeric_rw_by_cond, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_model_comprehension_numeric_rw_by_cond = percent_greater_zero_model_comprehension_numeric_rw_by_cond %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition_numeric12M12', 'condition_numeric3M3', 'new_minus_old', 'condition_numeric12M12.new_minus_old', 'condition_numeric3M3.new_minus_old')))


fixefs_model_comprehension_numeric_rw_by_cond = as.data.frame(fixef(model_comprehension_numeric_rw_by_cond)) %>%
    mutate(percent_greater_zero = percent_greater_zero_model_comprehension_numeric_rw_by_cond$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_comprehension_numeric_stem_rw = brm(meaning ~ condition_numeric*stem_condition*new_minus_old + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 18000, 
                                       warmup = 9000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       control = list(adapt_delta = 0.99, max_treedepth = 15),
                                       file = '../Data/model_comprehension_numeric_stem_rw')





model_comprehension_stem_rw = brm(meaning ~ stem_condition*new_minus_old + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 18000, 
                                       warmup = 9000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       control = list(adapt_delta = 0.99, max_treedepth = 15),
                                       file = '../Data/model_comprehension_stem_rw')


model_comprehension_numeric_humans = brm(meaning ~ condition_numeric + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds, #even though this says "plus_rw_plus", we are not using any RW predictors here
                                       family = bernoulli(link = 'logit'), 
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric_humans')

model_comprehension_numeric_stem_humans = brm(meaning ~ condition_numeric*stem_condition + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 40000, 
                                       warmup = 20000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       control = list(adapt_delta = 0.999, max_treedepth = 20),
                                       file = '../Data/model_comprehension_numeric_stem_humans')


model_rw_preds_by_statistical_preds = brm(new_minus_old ~ condition_numeric*stem_condition + (1 | participant) + (1 | stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       #family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       save_pars = save_pars(all = TRUE),
                                       #control = list(adapt_delta = 0.99, max_treedepth = 15),
                                       file = '../Data/model_rw_preds_by_statistical_preds')


model_rw_preds_by_statistical_preds_nsims = brm(new_minus_old ~ condition_numeric*stem_condition + (1 | sim) + (1 | stem),
                                       data = data_all_conds_test,
                                       #family = bernoulli(link = 'logit'),
                                       iter = 8000, 
                                       warmup = 4000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1b,
                                       save_pars = save_pars(all = TRUE),
                                       control = list(adapt_delta = 0.99, max_treedepth = 20),
                                       file = '../Data/model_rw_preds_by_statistical_preds_nsims')


loo_results_rwcomp = data.frame(loo_compare(
  model_comprehension_numeric_rw,
  model_comprehension_numeric_stem_rw,
  model_comprehension_stem_rw,
  model_comprehension_numeric_humans,
  model_comprehension_numeric_stem_humans,
  model_comprehension_numeric_rw_by_cond
)) %>%
  mutate('term' = c('RW Predictions, Condition, and Stem Familiarity',
                    'RW Predictions and Condition',
                    'RW Predictions and Stem Familiarity',
                    'Only Condition',
                    'Condition and Stem Familiarity',
                    'Only RW Predictions'))
```

# The effects of type and token frequency on semantic extension

\doublespacing

\setlength{\parindent}{4em}

## Introduction

## Methods

Following @harmonPuttingOldTools2017, two artificial languages were used: called Dan and Nem (See @fig-fig1). In each language, the same four suffixes were used: -*sil~PL~*, *-dan~PL~*, *-nem~DIM~*, and -*shoon~DIM~*. Notably, in our language *-dan* and *-sil* overlap in meaning (they both occur in plural contexts), and -*nem* and *-shoon* also overlap in meaning (they both occur in diminutive contexts). Since all four suffixes are possible candidates for the diminutive plural meaning, we can examine how properties of a suffix distribution (type frequency and token frequency) affect its likelihood of being extended to express the diminutive plural meaning.

![A description of the suffixes in our artificial languages. The thicker lines denote the more frequent form in each language: the plural -*dan~PL~* in the Dan language and the diminutive -*nem~DIM~* in the Nem language.](languages.pdf){#fig-fig1}

During the exposure phase, each suffix was paired with an image. The suffixes -*sil~PL~* and *-dan~PL~* were always paired with a picture of multiple large pictures. On the other hand, the suffixes *-nem~DIM~* and -*shoon~DIM~* were always paired with a picture of a single small creature. The design of the stimuli results in participants being able to learn that -*sil* and *-dan* are either simply plural or simply non-diminutive. Similarly, *-nem* and *-shoon* can be learned as either simply singular or simply diminutive.

Our Experiment comprised of three different conditions (see @tbl-conditionslist), one in which the type frequency of the frequent suffix (i.e., *dan* in Dan and *nem* in Nem) was higher than the type frequency of the infrequent suffix (by a factor of 4 or 12 vs. 3) while the token frequency of the two suffixes was matched and set equal to the type frequency of the frequent suffix (both at 12). We refer to this condition as Type. In the second condition, the token frequency of the frequent suffix was higher than the token frequency of the infrequent suffix (by a factor of 4 or 12 vs. 3) while holding the type frequency of the two suffixes equal to the type frequency of the infrequent suffix (both at 3). We refer to this condition as Token. Finally, in the third condition, we manipulated both the type and token frequency of the frequent suffix such that the token and type frequency of the frequent suffix were both greater than the token and type frequency of the infrequent suffix (by a factor of 4 or 12 vs. 3). We refer to this condition as Type-Token. In this context, a higher type frequency corresponds to the suffix appearing with a larger number of distinct stems relative to the competing suffix, while a larger token frequency corresponds to simply appearing a greater number of times relative to the competing suffix, regardless of the number of different stems it occurs with.

Our Experiment comprised of three different conditions (see @tbl-conditionslist), varying type and token frequencies of the competing suffixes. Type frequency corresponds to the number of distinct stems with which a suffix appears, while token frequency corresponds to the number of occurrences of a suffix, regardless of the number of different stems it occurs with. In the Type condition, the type frequency of the frequent suffix (i.e., *dan* in Dan and *nem* in Nem) was higher than the type frequency of the infrequent suffix (by a factor of 4 or 12 vs. 3) while the token frequency of the two suffixes was matched and set equal to the type frequency of the frequent suffix (both at 12). The frequent suffix in this condition has a lower token/type ratio than the rare suffix.

In the Token condition, the token frequency of the frequent suffix was higher than the token frequency of the infrequent suffix (by a factor of 4 or 12 vs. 3) while the type frequencies of the two suffixes were equal (both at 3). In this condition, both suffixes co-occurred with the same types. The frequent suffix in this condition has a higher token/type ratio than the rare suffix.

In the Type-Token condition, we manipulated both the type and token frequency of the frequent suffix such that the token and type frequency of the frequent suffix were both greater than the token and type frequency of the infrequent suffix (by a factor of 4 or 12 vs. 3). In this condition, the frequent and infrequent suffixes have the same token/type ratio.

```{r, echo = F, message = F}
#| label: tbl-conditionslist
#| tbl-cap: 'Description of each of our conditions. Note that in Condition 1, there are an equal number of tokens between the frequent and infrequent items, however there are a greater number of types in the frequent items. In Condition 2, the opposite is true: the frequent items occur more, but in the same number of types as the infrequent items. Finally, in Condition 3, the frequent items occur both a greater number of times and in a greater number of different contexts.'

# conditionslist = data.frame('Frequent Token' = c(12, 12, 12),
#                             'Frequent Type' = c(12, 3, 12),
#                             'Infrequent Token' = c(12, 3, 3),
#                             'Infrequent Type' = c(3, 3, 3))
# 
# conditionslist = conditionslist %>%
#   mutate(term = rep(c('Type', 'Token', 'Type-Token'), times = 1))
# 
# conditionslist %>%
#   dplyr::select(term, everything()) %>%
#   rename(` ` = term) %>%
#   kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
#   kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
#   #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
#   row_spec(0, bold = TRUE) %>%
#   column_spec(1, bold = T, width = '12em')
# 
# 

# your data
tbl <- data.frame(
  Condition        = c("Type", "Token", "Type-Token"),
  `Frequent.Type`  = c(12, 3, 12),
  `Frequent.Token` = c(12, 12, 12),
  `Infrequent.Type`= c(3, 3, 3),
  `Infrequent.Token`= c(12, 3, 3)
)

# --- Table ---
tbl %>%
  kable(
    format = "latex",
    booktabs = TRUE,
    digits = 2,
    escape = FALSE,
    col.names = c("Condition", "Type", "Token", "Type", "Token")
  ) %>%
  add_header_above(
    c(" " = 1, "Frequent Suffix" = 2, "Infrequent Suffix" = 2),
    bold = TRUE,
    escape = FALSE
  ) %>%
  kable_styling(
    latex_options = c("HOLD_position", "striped"),
    stripe_color = "gray!6",
    font_size = 11,
    full_width = FALSE
  ) %>%
  row_spec(0, bold = TRUE) %>%  # header row
  row_spec(1, bold = TRUE) %>%  # row 1 shaded & bold
  row_spec(3, bold = TRUE) %>%  # row 3 shaded & bold
  column_spec(1, bold = TRUE, width = "12em")

```

### Procedure

175 participants were recruited from Prolific, a crowd sourcing platform. 42 participants were excluded for failing to complete the task properly or achieving below 75% accuracy on control items. Each participant was randomly assigned one of the conditions. In each condition, participants were first presented with an exposure phase. After the exposure phase, participants were tested using a production task, a form choice task, and a comprehension task. We describe each of these below. Each participant was randomly assigned one of the conditions. In each condition, participants were first presented with an exposure phase. After the exposure phase, participants were tested using a production task, a form choice task, and a comprehension task. We describe each of these below.[^1]

[^1]: Additionally, a demo of the experiment can be found at the following link: <https://run.pavlovia.org/znhoughton/generalizability_demo>.

#### Exposure Phase

Following @harmonPuttingOldTools2017, each exposure trial consisted of the presentation of a picture on the computer screen which was followed by a written label for the image as well as an audio presentation of that label. Specifically, the image first appeared on the screen and then 1.25 seconds later was followed by both the label (positioned directly below the image with a letter height equal to 0.05 times the height of the user's screen) as well as the audio corresponding to the label (22050 Hz, 16 bit) timed to start simultaneously. The label remained on the screen for 3 seconds and the image remained on the screen for the duration of the label. Participants were instructed to type the name of the creature and press Enter. Participants had 4 seconds to respond after the onset of the presentation of the name of the creature and were given feedback as to whether they were correct immediately after pressing Enter.

Participants saw each trial within the exposure phase 5 times, each in a randomized order.

#### Production Task

After the exposure phase, participants were presented with a production task. In this task, participants were presented with images and told to produce a label for the image. Specifically, initially the unaffixed form appeared on the screen along with the corresponding image. Two seconds later, the label disappeared and the four different possible images of that creature appeared (a singular big creature, multiple big creatures, a single small creature, and multiple small creatures). Three of these images disappeared after 1.25 seconds, leaving a single image for the participant to produce a label for. Participants had 10 seconds to respond. In the production task, some of the stems were familiar (i.e., seen in training) and others were novel (i.e., not seen in training).

Participants saw each trial within the production task 4 times, each in a randomized order.

#### Form Choice Task

After the production task, participants were presented with a form choice task. In this task, participants were presented first with the text label for the base, unaffixed form and the corresponding image. Two seconds later, the label and the image disappeared and four images flashed on the screen, remained on the screen for 1.25 seconds before disappearing, leaving a single image. Along with the single image, participants were also presented with two possible labels (which differed in whether the suffix was *dan* or *nem*) for that image, one label on the bottom right of the screen and one label on the bottom left of the screen. Participants were given four seconds to press either the left arrow or the right arrow to choose the corresponding label. The labels were counterbalanced with respect to which side of the screen they appeared on. In the form choice task, some of the stems were familiar (i.e., seen in training) and others were novel (i.e., not seen in training). The goal of this task was to assess whether type and/or token frequency influence the form choice when accessibility differences between frequent and rare forms have been attenuated.

Participants saw each trial within the form choice task 2 times, each in a randomized order.

#### Comprehension Task

Finally, participants were presented with a comprehension task. In this task, participants were first given the label and corresponding audio for a given creature. After 0.25 seconds, the label remained on the screen and four images appeared on the screen. Participants had 4 seconds to click one of the images on the screen that corresponded to the label. Similar to the aforementioned tasks, in the comprehension task some of the stems were familiar (i.e., seen in training) and others were novel (i.e., not seen in training).

Participants saw each trial within the comprehension task 2 times, each in a randomized order.

## Analyses and Results

```{r eval = F}
# Before going into detail about each task, we first present a plot of our overall results  (@fig-fullresults)[^2]. In order to visualize the results, we subsetted the data by condition (type frequency, token frequency, or type-token frequency), stem (familiar or novel), task (production, form-choice, or comprehension), and meaning (original or novel). We then ran a logistic regression model. For the form-choice and production tasks, the dependent variable was 1 if the participant chose the frequent suffix for that trial or 0 if they chose the infrequent suffix. The model included an intercept as well as random intercepts for participant and stem identity. The frequent suffix was operationalized differently depending on the meaning of the item. For novel meanings (diminutive plural), the frequent suffix was simply whether they chose 
# *dan* in the Dan language or *nem* in the Nem language. However, for original meanings (big plural and diminutive singular), the frequent suffix was 1 if they chose *dan* for big plural and 0 if they chose *nem* for diminutive singular in the Dan language, and vice versa in the nem language.
# 
# For the comprehension task, the dependent variable was 1 if they chose the original meaning for the original meaning portion and 1 if they chose the novel meaning in the novel meaning portion and the independent variable was the intercept with random intercepts for participant and stem identity. For example, the larger estimates for the original meaning in the type frequency condition indicate that participants preferred to select the original meaning for both stem types. As a result, these bars are lower for the novel meaning since the original and novel estimates for a given stem type sum to 1. While this visualization for the comprehension is admittedly a bit awkward, the advantage is it allows us to visualize it alongside the results for production and form-choice tasks.
```

```{r, echo = F, out.width = '80%', fig.align = 'center', warning = F, message = F, eval = F}
#| label: fig-fullresults
#| fig-cap: "Plot of our results. Points indicate individual subject values. The x-axis indicates whether the meaning was original or novel. Green coloring corresponds to the frequent stem while blue corresponds to the infrequent stem. The y-axis indicates the response probability. For Production and Form-choice, it is the response probability of choosing the frequent form. Thus, a value closer to 1 indicates that participants chose the frequent form more than the infrequent form. For Comprehension, it is the response probability of choosing a given meaning. For example, a value closer to 1 for the original meaning with a novel stem indicates that when participants saw a novel stem with *dan*, they were more likely to select the big.pl meaning than the dim.pl meaning (as a result, for a given stem familiarity the original and novel bars sum to 1 in the comprehension condition). Facets indicate condition (type frequency, token frequency, or type-token frequency) and task (production, form-choice, comprehension). The results were obtained by running a separate regression model "
#| fig-height: 6
#| fig-width: 7

ggplot(fixed_effects_df_all, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_point(data = subject_effects, 
             aes(x = Meaning, y = subj_values, fill = Stem, color = Stem),  # Map fill and color
             shape = 21,   # Hollow circle with fill and outline
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, stroke = 0.7, alpha = 0.1,  # Adjust size, border thickness, and transparency
             show.legend = FALSE) +  # Hides points from legend
  scale_fill_manual(values = c("Familiar" = "#66c2a5", "Novel" = "#8da0cb")) +  # Bar & point fill colors
  scale_color_manual(values = c("Familiar" = "#1b7837", "Novel" = "#2b8cbe")) +  # Darker border colors for points
  facet_grid(Task ~ Condition, labeller = labeller(Condition = condition_labels, Task = task_labels)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  theme_bw() +
  ggtitle('Results by condition for each task') +
  xlab('Meaning') +
  ylab('Response Probability') +
  ylim(0, 1)
```

```{r eval = F}
# The plot demonstrates that participants were more likely to produce the frequent suffix with a novel meaning when the frequent suffix had a high type frequency, but were less likely to produce the frequent suffix with a novel meaning when the frequent suffix had a high token frequency. Our results also demonstrate that this effect disappears when both forms are made accessible in the form-choice task. Further, the results also demonstrate that in comprehension, regardless of the condition or stem familiarity, the original meaning is chosen far more than the novel meaning for a given suffix.
```

We explore the results for each task in depth in the next sections.[^2]

[^2]: All data and code for the analyses can be found here: <https://github.com/znhoughton/Generalizability-Type-Token>.

### Production Task

<!--# Freq bar in original is choosing dan for big_pl or nem for dim_sg in the dan language and infreq bar is choosing dan for big_pl and nem for dim_sg in the nem language -->

In order to determine whether the effect of frequency on semantic extension differed between conditions, we ran a Bayesian logistic mixed-effects model on the production data. The dependent variable was whether the participant produced the frequent suffix. The frequent suffix was coded as 1 if participants chose *dan* in the Dan language or chose *nem* in the Nem language.

We treatment coded condition such that the intercept was the type-token condition. Thus, a larger intercept indicates that the frequent suffix was more likely to be produced than the infrequent suffix when it had a higher type and token frequency.

A larger coefficient estimate for a condition indicates that the frequent form was more likely to be produced than the infrequent form in that condition relative to the type-token frequency condition.

We also included meaning and stem novelty as sum-coded variables. Meaning was a categorical variable with two levels: original and novel. An original meaning referred to big plural if the suffix was *dan* or diminutive singular if the suffix was *nem*. A meaning was novel if it was diminutive plural regardless of the suffix. Stem novelty similarly was a categorical variable with two levels, familiar or novel. A familiar stem was one that participants saw in training while a novel stem was one that they did not see in training. We also included a random intercept for participant and random slopes for meaning by participant and stem novelty by participant. The syntax for our model is included below in @eq-prodmodelstem. The results are reported in @tbl-prodresultsstem and visualized in @fig-prodresultstemcoef and @fig-prodresultsstem.

$$
\text{frequent\_suffix} \sim \text{condition}*\text{meaning}*\text{stem} + (1 + \text{meaning} * \text{stem} | \text{participant})
$$ {#eq-prodmodelstem}

We find a meaningful effect for the intercept, suggesting that the frequent suffix is chosen more than the infrequent suffix when it was higher in both type and high token frequency.

We also find a meaningful effect for novel stems, suggesting that the effect of suffix frequency is greater for novel stems than for familiar stems in the Type-Token condition. The effect of stem novelty is even greater in the Type condition, where there is a preference for the frequent suffix over the infrequent suffix when the stem is novel but not when it is familiar (evidenced by the interaction effect between type frequency and novel stem). In contrast, there is no suffix-frequency-by-stem-novelty interaction in the Token condition.

Finally, we find a three-way interaction between Type frequency condition, novel meaning, and novel stem, suggesting that learners are especially likely to produce a frequent suffix in the Type frequency condition when both the stem and meaning are novel.

Overall, our results suggest that in production, learners generally use the frequent suffix more regardless of meaning or stem familiarity if the suffix has both a high type and high token frequency. When the frequent suffix has a higher type frequency than the infrequent suffix, learners are especially likely to use it if the stem is novel. When the stem is familiar, the frequent suffix is preferred over the infrequent one only if they differ in token frequency. Finally, a frequent suffix is preferred over the infrequent suffix in the novel meaning only if they differ in type frequency.

```{r, echo = F, message = F}
#| label: tbl-prodresultsstem
#| tbl-cap: 'Results of the statistical models for the production task.'

prod_both_meanings_stems = bind_rows(fixefs_model_prod_both_stems, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem'), times = 1))


prod_both_meanings_stems = prod_both_meanings_stems %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

prod_both_meanings_stems %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '20em')
```

```{r, echo = F, out.width = '65%', fig.align = 'center', warning = F, message = F}
#| label: fig-prodresultstemcoef
#| fig-cap: "Plot of the coefficient values in the statistical model presented in @tbl-prodresultsstem. The x-axis indicates the coefficient estimate while the y-axis indicates the different coefficients in the model. Blue points indicate the posterior mean estimate for each coefficient while the gray bars indicate the 95\/% credible interval for each estimate. The intercept represents the baseline condition (Type-Token Frequency). All other coefficients are expressed as changes relative to this baseline, so the intercept is omitted from the plot."



df = fixefs_model_prod_both_stems %>%
  rownames_to_column("Term") %>%
  mutate(
    Term = gsub(":", ".", Term),
    Estimate = as.numeric(Estimate),
    Q2.5 = as.numeric(Q2.5),
    Q97.5 = as.numeric(Q97.5)
  )

# Order by estimate for readability
df$Term = factor(df$Term, levels = rev(df$Term)) #df$Term[order(df$Estimate)])

# Plot
df_noint <- df %>%
  filter(Term != "Intercept")

ggplot(df_noint, aes(x = Estimate, y = Term)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5),
                 height = 0.2, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 13) +
  labs(
    x = "Coefficient Estimate",
    y = "Coefficient"
  )


```

```{r, echo = F, out.width = '100%', fig.align = 'center', warning = F, message = F}
#| label: fig-prodresultsstem
#| fig-cap: "Plot of the statistical model estimates for the production task. The x-axis indicates the condition (type frequency, token frequency, or type-token frequency). The y-axis corresponds to the proportion of responses with a frequent suffix. Blue points indicate that the meaning was novel while purple points indicate that the meaning was original. The facet indicates whether the stem was novel or familiar."
#| fig-height: 5
#| fig-width: 7


plot_prod_stem = plot_model(model_prod_both_stems, type = 'int',
                            axis.title = c('Condition', 'Frequency'),
                            axis.labels = "condition",
                            legend.title = 'Meaning',
                            title = "",
                            dot.size = 2,
                            line.size = 1,
                            colors = c('#298c8c', '#800074'))[[4]] 
plot_prod_stem[[11]]$linetype = 'Meaning'
plot_prod_stem[[11]]$shape = 'Meaning'

plot_prod_stem[[1]]$group_col = factor(plot_prod_stem[[1]]$group_col, levels = c('novel', 'original'), labels = c('Novel Meaning', 'Original Meaning'))

plot_prod_stem[[1]]$group = factor(plot_prod_stem[[1]]$group, levels = c('novel', 'original'), labels = c('Novel Meaning', 'Original Meaning'))

plot_prod_stem[[1]]$facet = factor(plot_prod_stem[[1]]$facet, levels = c('novel', 'familiar'), labels = c('Novel Stem', 'Familiar Stem'))

#plot_prod_stem[[1]]$x

plot_prod_stem +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency')) +
  ylab('Proportion of Responses with Frequent Suffix') +
  scale_y_continuous(limits=c(0,1), breaks=seq(0, 1, by=0.25)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, color = 'black', size = 10),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        axis.text.y = element_text(color = 'black', size = 10)) 

```

### Form Choice Task

In order to examine the effects of form-choice, we similarly ran a model analogous to the one we ran for the production task (@eq-prodmodelstem). In the context of the form-choice task, the dependent variable reflects whether participants chose the option with the frequent suffix or the one with the infrequent suffix. The model was exactly the same as in production. The results are presented in @tbl-2afcresultsstem and visualized in @fig-2afcresultstemcoef and @fig-2afcresultsstem.

```{r, echo = F, message = F}
#| label: tbl-2afcresultsstem
#| tbl-cap: 'Results of the statistical models for the form-choice task.'

c2afc_both_stem = bind_rows(fixefs_model_2afc_both_stem, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem'), times = 1))


c2afc_both_stem = c2afc_both_stem %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

c2afc_both_stem %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '20em')
```

```{r, echo = F, out.width = '65%', fig.align = 'center', warning = F, message = F}
#| label: fig-2afcresultstemcoef
#| fig-cap: "Plot of the coefficient values in the statistical model presented in @tbl-2afcresultsstem. The x-axis indicates the coefficient estimate while the y-axis indicates the different coefficients in the model. Blue points indicate the posterior mean estimate for each coefficient while the gray bars indicate the 95\/% credible interval for each estimate. The intercept represents the baseline condition (Type-Token Frequency). All other coefficients are expressed as changes relative to this baseline, so the intercept is omitted from the plot."




df = fixefs_model_2afc_both_stem %>%
  rownames_to_column("Term") %>%
  mutate(
    Term = gsub(":", ".", Term),
    Estimate = as.numeric(Estimate),
    Q2.5 = as.numeric(Q2.5),
    Q97.5 = as.numeric(Q97.5)
  )

# Order by estimate for readability
df$Term = factor(df$Term, levels = rev(df$Term)) #df$Term[order(df$Estimate)])

# Plot
df_noint <- df %>%
  filter(Term != "Intercept")

ggplot(df_noint, aes(x = Estimate, y = Term)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5),
                 height = 0.2, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 13) +
  labs(
    x = "Coefficient Estimate",
    y = "Coefficient"
  )


```

```{r, echo = F, out.width = '100%', fig.align = 'center', warning = F, message = F}
#| label: fig-2afcresultsstem
#| fig-cap: "Plot of the statistical model estimates for the form-choice task. The x-axis indicates the condition (type frequency, token frequency, or type-token frequency). The y-axis corresponds to the proportion of responses with a frequent suffix. Blue points indicate that the meaning was novel while purple points indicate that the meaning was original. The facet indicates whether the stem was novel or familiar."
#| fig-height: 5
#| fig-width: 7

plot_prod_stem = plot_model(model_2afc_both_stem, type = 'int',
                            axis.title = c('Condition', 'Frequency'),
                            axis.labels = "condition",
                            legend.title = 'Meaning',
                            title = "",
                            dot.size = 2,
                            line.size = 1,
                            colors = c('#298c8c', '#800074'))[[4]] 
plot_prod_stem[[11]]$linetype = 'Meaning'
plot_prod_stem[[11]]$shape = 'Meaning'

plot_prod_stem[[1]]$group_col = factor(plot_prod_stem[[1]]$group_col, levels = c('novel', 'original'), labels = c('Novel Meaning', 'Original Meaning'))

plot_prod_stem[[1]]$group = factor(plot_prod_stem[[1]]$group, levels = c('novel', 'original'), labels = c('Novel Meaning', 'Original Meaning'))

plot_prod_stem[[1]]$facet = factor(plot_prod_stem[[1]]$facet, levels = c('novel', 'familiar'), labels = c('Novel Stem', 'Familiar Stem'))

#plot_prod_stem[[1]]$x

plot_prod_stem +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency')) +
  scale_y_continuous(limits=c(0,1), breaks=seq(0, 1, by=0.25)) +
  ylab('Proportion of Responses with Frequent Suffix') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, color = 'black', size = 10),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        axis.text.y = element_text(color = 'black', size = 10)) 

```

In general we find no reliable effects except for an interaction effect between type frequency and novel meaning, suggesting that there may be a preference for the frequent suffix when it has a higher type frequency than the infrequent suffix. However, the small size of this effect and the lack of any other meaningful effects suggests that when participants are presented with both possible options, for all conditions (except when there is a novel meaning in the type frequency condition), participants are equally likely to choose the frequent suffix as the infrequent suffix (i.e.,token and type frequency don't seem to effect this).

Finally, in order to verify that the differences in the results between form-choice and production are meaningful, we ran a model with task (form-choice vs production) as an interaction effect. The results are presented in @tbl-2afcprodresultsstem and visualized in @fig-2afcprodresultsstem. The results demonstrate that learners are overall more likely to select the frequent suffix in the production task than in the form-choice task. The results also confirm that there is an effect of stem familiarity in production, but this effect is greatly reduced in the form-choice task. Additionally, the results demonstrate that in production, there is an interaction effect between type frequency, novel stems, and novel meanings, such that learners are especially likely to select the frequent suffix when both the stem and meaning are novel. However, this effect is diminished in the form-choice task (as demonstrated by the negative four-way interaction effect between type frequency, novel meaning, novel stem, and form-choice task). Finally, the results also demonstrate that in the token frequency condition, the effect of stem familiarity is greater in the form-choice task than in production however in the type frequency condition the opposite is found: the effect of stem familiarity is greater in the production task than in the form-choice task.

```{r echo = F, message = F}
#| label: tbl-2afcprodresultsstem
#| tbl-cap: 'Results of the statistical models with task (2afc vs production) as an interaction effect.'

#task1 = production?
fixefs_model_prod_2afc_both_stem = bind_rows(fixefs_model_prod_2afc_both_stem, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Form-Choice', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Form-Choice', 'Token Frequency:Form-Choice', 'Novel Meaning:Form-Choice', 'Novel Stem:Form-Choice', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Form-Choice', 'Token Frequency:Novel Meaning:Form-Choice', 'Type Frequency:Novel Stem:Form-Choice', 'Token Frequency:Novel Stem:Form-Choice', 'Novel Meaning:Novel Stem:Form-Choice', 'Type Frequency:Novel Meaning:Novel Stem:Form-Choice', 'Token Frequency:Novel Meaning:Novel Stem:Form-Choice'), times = 1))


fixefs_model_prod_2afc_both_stem = fixefs_model_prod_2afc_both_stem %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

fixefs_model_prod_2afc_both_stem %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '20em')

```

```{r, echo = F, out.width = '100%', fig.align = 'center', warning = F, message = F}
#| label: fig-2afcprodresultsstem
#| fig-cap: "Plot of the statistical model estimates for task-interaction model. The x-axis indicates the condition (type frequency, token frequency, or type-token frequency). The y-axis corresponds to the proportion of responses with a frequent suffix. Blue points indicate that the meaning was novel while purple points indicate that the meaning was original. The facet indicates whether the stem was novel or familiar. The production results are shown in the top plot and the form-choice results are shown in the bottom plot."
#| fig-height: 5
#| fig-width: 7

# ======================================================
# 1. Extract interaction plots from plot_model()
# ======================================================
library(patchwork)

# 1. Get the plot_model output
pm <- plot_model(
  model_2afc_prod_both_stem,
  type = "int",
  #axis.title = c("condition", "frequency"),
  #axis.labels = "Condition",
  #legend.title = c('Meaning', 'Meaning'),
  #title = "",
  dot.size = 2,
  line.size = 1,
  colors = c('#298c8c', '#800074')
)

library(grid)
library(gridExtra)

# --- 1. extract the two plots you told me ---
p_fc_raw   <- pm[[11]][[1]]   # Form-choice
p_prod_raw <- pm[[11]][[2]]   # Production


# --- 2. cleaning function ---
clean_plot <- function(p) {

  # Meaning relabel
  if ("group" %in% names(p$data)) {
    p$data$group <- factor(
      p$data$group,
      levels = c("novel","original"),
      labels = c("Novel Meaning","Original Meaning")
    )
  }
  if ("group_col" %in% names(p$data)) {
    p$data$group_col <- factor(
      p$data$group_col,
      levels = c("novel","original"),
      labels = c("Novel Meaning","Original Meaning")
    )
  }

  # Stem relabel (Novel  Novel Stem)
  if ("facet" %in% names(p$data) &&
      any(p$data$facet %in% c("novel","familiar"))) {
    p$data$facet <- factor(
      p$data$facet,
      levels = c("novel","familiar"),
      labels = c("Novel Stem","Familiar Stem")
    )
  }

  # --- Standardize appearance ---
  p <- p +
    labs(                       # <-- remove sjPlot's title/subtitle
      title    = NULL,
      subtitle = NULL
    ) +
    scale_x_continuous(
      breaks  = c(1,2,3),
      labels  = c("Type Frequency","Token Frequency","Type-Token Frequency")
    ) +
    scale_y_continuous(
      limits  = c(0,1),
      breaks  = seq(0,1,0.25)
    ) +
    labs(
      colour   = "Meaning",
      linetype = "Meaning",
      shape    = "Meaning"
    ) +
    theme_bw() +
    theme(
      axis.text.x  = element_text(angle=45, hjust=1, color="black"),
      axis.text.y  = element_text(color="black"),
      axis.title.x = element_blank(),
      axis.title.y = element_blank(),
      strip.text   = element_text(size=12, face = "plain"),
      plot.title   = element_blank(),
      plot.subtitle = element_blank()  # <-- makes sure "task = ..." disappears**
    )

  return(p)
}


# --- 3. apply cleaning ---
p_prod_clean <- clean_plot(p_prod_raw)
p_fc_clean   <- clean_plot(p_fc_raw)

# add axis labels
p_prod_clean <- p_prod_clean + ylab("") + xlab("Condition")
p_fc_clean   <- p_fc_clean   + xlab("Condition")

# --- 4. add custom top titles using textGrobs ---
title_prod <- textGrob(
  "Production",
  x = unit(0.03, "npc"),   # left side of panel
  hjust = 0,            # left-align text
  gp = gpar(fontsize = 14, fontface = "bold")
)

title_fc <- textGrob(
  "Form-Choice",
  x = unit(0.03, "npc"),   # left side of panel
  hjust = 0,
  gp = gpar(fontsize = 14, fontface = "bold")
)


prod_with_title <- arrangeGrob(
  title_prod,
  p_prod_clean,
  ncol = 1,
  heights = c(0.12, 1)
)

fc_with_title <- arrangeGrob(
  title_fc,
  p_fc_clean,
  ncol = 1,
  heights = c(0.12, 1)
)



# --- 5. stack them ---
stacked <- arrangeGrob(prod_with_title, fc_with_title, ncol = 1)

ylab_grob <- textGrob(
  "Proportion of Responses with Frequent Suffix",
  rot = 90,
  gp = gpar(fontsize = 12)
)

final_plot <- grid.arrange(
  ylab_grob,
  stacked,
  widths = c(1, 20)
)

grid.newpage()
grid.draw(final_plot)




```

### Comprehension Task

In order to examine the results for the comprehension task, similar to the previous tasks we ran a mixed-effects regression model. The dependent variable was whether the meaning that participants selected was novel or original. A positive estimate indicates that participants chose the novel meaning while a negative estimate indicates that participants were more likely to choose the original meaning. In production and form-choice, participants are choosing between suffixes that differ in frequency. In comprehension, participants instead are presented with a single affix that has a certain type frequency, token frequency, and token/type ratio, and a frequent suffix from one condition can have the same characteristics as an infrequent suffix from another condition. Since participants are not comparing suffixes in comprehension, we expect equally distributed suffixes to have the same effect. Thus, the independent variable chosen was the distribution of the presented suffix: 12 tokens and 12 types, 12 tokens and 3 types, or 3 tokens and 3 types. By comparing the 12-3 condition to the 12-12 and 3-3 conditions, we can see how an increase in type frequency and a decrease in token frequency affect participants' choice of the novel vs. original meaning. Thus, hereafter we refer to the 12-3 distribution as the baseline distribution, the 12-12 distribution as Higher Type and the 3-3 distribution as Lower Token. Another way to classify the distributions is that the baseline distribution is a suffix that has a higher token/type ratio than the others (4 tokens per type vs 1 token per type).

We treatment coded distribution such that the intercept was the baseline condition. As a result, for each distribution, a positive coefficient indicates that participants are more likely to choose a novel meaning (relative to the baseline distribution/intercept). We also included a slope for stem familiarity, a random intercept for participant, and a random slope for stem familiarity by participant.

The model syntax is included below in @eq-comprehensionmodel. Our results for the comprehension task are included in @tbl-comprehensionresultsstem and visualized in @fig-comprehensionresultstemcoef and @fig-comprehensionresults.

$$
\text{meaning} \sim \text{condition\_numeric} * \text{stem\_condition} + (1 + \text{stem} | \text{participant})
$$ {#eq-comprehensionmodel}

First, we find a meaningful effect for the baseline distribution (Intercept), suggesting that participants are more likely to select the original meaning than the novel meaning. Additionally, we find positive coefficient estimates for both Higher Type and Lower Token conditions, suggesting that decreasing the token-to-type ratio, whether by increasing type frequency or decreasing token frequency, makes participants more likely to select the novel meaning. Finally, we find no effect of stem familiarity. These results suggest that it may not be type or token frequency independently that drives semantic entrenchment, but rather the ratio between type and token frequency.

```{r, echo = F, message = F, eval = F}
#| label: tbl-comprehensionresults
#| tbl-cap: 'Results of the statistical model for the comprehension task with stem as a fixed-effect.'
#| 

fixefs_model_comprehension_numeric = fixefs_model_comprehension_numeric %>%
  mutate(term = rep(c('Intercept (Control)', 'Higher Type', 'Lower Token'), times = 1))


fixefs_model_comprehension_numeric = fixefs_model_comprehension_numeric %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_model_comprehension_numeric %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')


```

```{r, echo = F, message = F}
#| label: tbl-comprehensionresultsstem
#| tbl-cap: 'Results of the statistical model for the comprehension task with stem as a fixed-effect.'
#| 

fixefs_model_comprehension_numeric_stem = fixefs_model_comprehension_numeric_stem %>%
  mutate(term = rep(c('Intercept', '12-12', '3-3', 'Novel Stem', '12-12:Novel Stem', '3-3:Novel Stem'), times = 1))


fixefs_model_comprehension_numeric_stem = fixefs_model_comprehension_numeric_stem %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_model_comprehension_numeric_stem %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')


```

```{r, echo = F, out.width = '65%', fig.align = 'center', warning = F, message = F}
#| label: fig-comprehensionresultstemcoef
#| fig-cap: "Plot of the coefficient values in the statistical model presented in @tbl-comprehensionresultsstem. The x-axis indicates the coefficient estimate while the y-axis indicates the different coefficients in the model. Blue points indicate the posterior mean estimate for each coefficient while the gray bars indicate the 95\/% credible interval for each estimate. The intercept represents the baseline condition (Type-Token Frequency). All other coefficients are expressed as changes relative to this baseline, so the intercept is omitted from the plot."




df = fixefs_model_comprehension_numeric_stem %>%
  rownames_to_column("Term") %>%
  mutate(
    Term = gsub(":", ".", Term),
    Estimate = as.numeric(Estimate),
    Q2.5 = as.numeric(Q2.5),
    Q97.5 = as.numeric(Q97.5)
  )

# Order by estimate for readability
df$Term = factor(df$Term, levels = rev(df$Term)) #df$Term[order(df$Estimate)])

# Plot
df_noint <- df %>%
  filter(Term != "Intercept")

ggplot(df_noint, aes(x = Estimate, y = Term)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5),
                 height = 0.2, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 13) +
  labs(
    x = "Coefficient Estimate",
    y = "Coefficient"
  )


```

```{r, echo = F, message = F,  out.width = '100%', fig.align = 'center',}
#| label: fig-comprehensionresults
#| fig-cap: 'Plot of the model estimates for the comprehension task.'

plot_comprehension_no_stem = conditional_effects(model_comprehension_numeric)
plot(plot_comprehension_no_stem, plot = FALSE)[[1]] +
  theme_bw() +
  ylab('Probability of Novel Meaning') +
  xlab('Condition') +
  ylim(c(0,1)) +
  geom_errorbar(width = 0.1) +
  scale_x_discrete(labels = c("Control", "Higher Type", "Lower Token")) +
  scale_y_continuous(limits=c(0,1), breaks=seq(0, 1, by=0.25))


```

Overall, the comprehension results demonstrate that participants are more likely to select the original meaning when there is a high token-to-type ratio. However, when the token-to-type ratio is equivalent (either 12-12 or 3-3) then participants are more likely to select the novel meaning than when there is a high token-to-type ratio. One caveat is that participants still prefer the original meaning over the novel meaning in general (this is evident because adding the upper CI estimate to the intercept for both conditions still results in a negative estimate). In other words, while decreasing the token-to-type ratio decreases the preference for the original meaning, it does not eliminate it.

## Connectionist Models

In this section we examine whether the results are accurately accounted for by a simple connectionist model implementing error-driven predictive learning; specifically, the logistic perceptron [@rumelhart1986], which is an extension of the Rescorla-Wagner model to categorical outcomes [@dawson2008mindsmachinesconnectionism; @kapatsinskiLearningFastAvoiding2021]. The logistic perceptron can be considered a standard model for learning to predict categorical outcomes and serves as the final layer in all modern neural network models. It is also the online counterpart to logistic regression. These models do not have a categorical distinction between types, but do generally adjust network beliefs more when a token from a novel type because a token from a novel type is generally less expected and learning is proportional to prediction error. Furthermore, type frequency helps generalization because it increases the likelihood that the generalization stimuli are within the similarity space covered by known stimuli [@hare1995defaultgeneralisationconnectionist]. Therefore, much previous work has debated whether such models can capture effects of type frequency on morphological productivity, or if additional, symbolic mechanisms are needed to differentiate types [@caballero2022howagglutinativesearching; @hare1995defaultgeneralisationconnectionist; @xuWordLearningBayesian2007; @delpradomartin2004typetokeneffects; @pinker1988languageconnectionismanalysis].

The Rescorla-Wagner model is an error-driven predictive learning model that takes as its input a set of cues and predicts an outcome or set of outcomes as output [@rescorla1972theorypavlovianconditioning]. The model is defined below in @eq-rwmodel and @eq-rwmodelabsent, which differ in whether the predicted outcome is present or not. The model learns the weight of an association between cues and outcomes ($V_{C\rightarrow O }$) . In the equation, $\alpha_C$ denotes the salience of a cue, $\beta^P_O$ denotes the salience of an outcome when it is present, and $\beta^A_O$ denotes the salience of an outcome when it is absent. Absent cues are generally assumed to have $\alpha_C=0$ and are therefore not to be updated. An outcome's activation, $A_O$, denotes the sum of the association weights (V) from the present cues to that outcome, i.e., $\sum_cV_{C\rightarrow O}$. Subtracting $A_O$ from the appropriate limit (1 for present outcomes and 0 for absent ones) defines prediction error. The model is error-driven because the change in weight is proportional to prediction error: more is learned when the presence or absence of an outcome is surprising.

$$
\Delta V_{C\rightarrow O } = \alpha_C\beta^P_O(1-A_O)
$$ {#eq-rwmodel}

$$
\Delta V_{C\rightarrow O } = \alpha_C\beta^A_O(0-A_O)
$$ {#eq-rwmodelabsent}

The logistic perceptron simply redefines prediction error as shown below, passing an outcome's activation through a logistic activation function before subtracting it from the limit (1 or 0; @eq-rwlogistic). This ensures that the prediction error is always positive for present outcomes and negative for absent outcomes. The logistic perceptron is the standard way to predict categorical outcomes in neural networks [following @rumelhart1986learningrepresentationsbackpropagating]. Furthermore, @caballero2022howagglutinativesearching along with @kapatsinskiLearningFastAvoiding2021 show that this modification eliminates an incorrect prediction of the Rescorla-Wagner model, which otherwise sometimes learns associations between cues and outcomes that never co-occur, explains the transient nature of cue competition effects like blocking and overshadowing, and can account for S-shaped learning curves.

$$
A_O = logit^{-1}(\sum_cV_{C\rightarrow O})
$$ {#eq-rwlogistic}

### Production Models

In this section, we examine whether the logistic perceptron can account for the results of our production task.

The model was trained on the same series of training trials as our human subjects, presented in random order. The cues represented stem identity along with the meaning (e.g., bal_dim_pl) and the outcome was the suffix that the stem occurred with on that trial (i.e., *dan*, *nem*, *sil*, or *shoon*).

For each of the items in the production task, we computed activation of each outcome suffix. For example, given the item *baldan* and the meaning BIG PLURAL, we summed the weights of associations from *bal*, BIG, and PLURAL to *dan*. The activation of *dan* corresponds to its expected log odds given these cues. Passing it through the logistic activation function then generates its expected production probability. For this initial simulation, since we had no reason to believe some cues or outcomes are more salient than others, we assumed that $\alpha_C=0.1$ for all present cues and $\beta=1$ for both present and absent outcomes, yielding a learning rate of 0.1. The results for the simple connectionist model were qualitatively stable across different learning rates.

We then calculated the difference in activation between the frequent suffix and the infrequent suffix given the semantic cues and the stem cue present on a particular trial. This corresponds to the expected effect of frequency on the log odds of choosing these suffixes when presented with a particular meaning and a particular stem. For example, the activation *nem* receives when the subject is presented with its original meaning is the sum of activations from DIMINUTIVE, SINGULAR and the stem. It is the log odds of *nem* in its original meaning. If the frequent suffix is *dan*, then the activation of *nem* would be subtracted from the activation *dan* would receive in its original meaning, i.e., from BIG, PLURAL and the same stem. If *nem* is the frequent suffix, then the subtraction is in the opposite direction. For the novel meaning, the semantic cues are DIMINITUVE and PLURAL for both suffixes. This results in a single value for each trial that is the models expected log odds of the frequent suffix relative to the infrequent suffix given the stem and meaning (original or novel) on that trial.


In order to examine the model predictions, we conducted several statistical analyses. In each model, the dependent variable was whether the human learner, for a given trial, selected the frequent suffix or the infrequent suffix. In the baseline analysis, we used expected difference in log odds (referred to as freq_minus_infreq) with random intercepts for participant and stem identity (@eq-rwmodel1). In our second model, we calculated separately the activation received by the suffix from the stem and from the meaning (using the perceptron). The motivation behind this is that the perceptron is agnostic to whether the cue is a stem or a meaning, but participants may show varying sensitivity to one over the other [e.g., @gagliardi2017modelingstatisticalinsensitivity argue that learners are more sensitive to form cues than to semantic cues]. Using the activation from the stem and the meaning as separate predictors allows the statistical model to fit different slopes for the stem activations and the meaning activations. We then added a fixed-effect for condition as well (@eq-rwmodel2). Our third model was identical to the second model except we included an interaction effect between condition and the stem activations, and an interaction between the meaning activations and condition (@eq-rwmodel3). This model tests whether the perceptron captures the effects of type and token frequency and their interactions with meaning and stem novelty, or if some effects are not captured by the perceptron and therefore provide support for additional mechanisms.

We evaluated the discrepancies between model predictions and human data by using expected log odds from the model as predictors in a Bayesian logistic regression models. In each model, the dependent variable was whether the human learner, for a given trial, selected the frequent suffix or the infrequent suffix.

Specifically, we used expected difference in log odds (referred to as freq_minus_infreq) with random intercepts for participant and stem identity (@eq-rwmodel1). This model serves as a baseline. In our second model, we calculated separately the activation received by the suffix from the stem and from the meaning (using the perceptron). The motivation behind this is that the perceptron is agnostic to whether the cue is a stem or a meaning, but participants may show varying sensitivity to one over the other [e.g., @gagliardi2017modelingstatisticalinsensitivity argue that learners are more sensitive to form cues than to semantic cues]. Using the activation from the stem and the meaning as separate predictors allows the statistical model to fit different slopes for the stem activations and the meaning activations. We then added a fixed-effect for condition as well (@eq-rwmodel2). Finally, our third model was identical to the second model except we included an interaction effect between condition and the stem activations, and an interaction between the meaning activations and condition (@eq-rwmodel3). This model tests whether the perceptron captures the effects of type and token frequency and their interactions with meaning and stem novelty, or if some effects are not captured by the perceptron and therefore provide support for additional mechanisms.

$$
\text{frequency} \sim \text{freq\_minus\_infreq} + (1 | \text{participant}) + (1|\text{resp\_stem})
$$ {#eq-rwmodel1}

$$
\begin{aligned}
\text{frequency} & \sim \text{freq\_minus\_infreq\_stem} + \text{freq\_minus\_infreq\_meaning} + \text{condition} \\ & +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwmodel2}

$$
\begin{aligned}
\text{frequency} & \sim \text{freq\_minus\_infreq\_stem} + \text{freq\_minus\_infreq\_meaning} + \text{condition} \\ & + \text{freq\_minus\_infreq\_stem:condition} + \text{freq\_minus\_infreq\_meaning:condition} \\ & + (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwmodel3}


In addition to this simple logistic RW model, we also evaluated more complex models that allowed for configural cues as well as different weighting of semantic vs phonetic cues. This is well-motivated by previous work. For example, there is evidence that linguistic units can have associations that their parts do not have [@kapatsinskiTestingTheoriesLinguistic2009; @kapatsinskiLearningFastAvoiding2021; @houghton2025multiwordrepresentationsminds; see also @saavedra1975pavloviancompoundconditioning for stimuli in classical conditioning]. Additionally, there is also evidence that adult native English speakers show greater reliance on semantic cues than phonological cues in production [@culbertson2018childrenprivilegephonological]. For these models, there was qualitatively more variability across different parameter values. In order to address this, we conducted a grid search to determine the optimal values for each of the model parameters (the salience of the phonetic cues, the salience of the semantic cues, and the salience of outcomes). The ground truth of this grid search was the model estimates for the human data across condition, stem familiarity, and meaning. Model predictions were compared using mean squared error. This grid search yielded $\alpha_{SemC}=0.65$ for all present semantic cues, $\alpha_c=0.05$ for present phonological cues and $\beta=0.65$ for both present and absent outcomes.


Similarly, in order to examine the effect of configural cues and modified semantic salience, we ran five additional statistical models: one with configural cues and modified semantic salience, one with configural cues and modified semantic salience, both of which were allowed to vary by condition, one with configural cues, increased semantic salience, and the original statistical predictors (condition:meaning:stem_condition), one with only configural cues (no modified semantic salience), and one with only modified semantic salience (no configural cues). As before, all statistical models included random intercepts for participant and stem identity.

We then compared the results of these statistical models to the model with only statistical predictors, and the three models described previously (@eq-rwmodel1, @eq-rwmodel2, and @eq-rwmodel3) using leave-one-out-cross-validation (@tbl-loocv_addsims). The results of the leave-one-out cross-validation suggest that the models that include configural cues or increased sensitivity to semantic cues outperform all other models. Further, allowing the configural cues and increased semantic saliency to vary by condition does not result in further improvement of the model. Among those models, any of the models that include special salience of semantic cues perform better than any model that does not. 

In order to visualize the Rescorla-Wagner model predictions, we also included a side-by-side plot of the human data with the RW activations from the model that included both modified semantic salience and configural cues (@fig-rwvshumanpreds).

```{r, echo = F, message = F}
#| label: tbl-loocv_addsims 
#| tbl-cap: "Results of the leave-one-out cross-validation for the additional simulations."

loo_co_results_add = loo_co_results_add %>%
  dplyr::select(elpd_diff, se_diff, elpd_loo, se_elpd_loo, term) 


loo_co_results_add %>%
  dplyr::select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '22em')

```

<!--# to add: in-depth explanation of the configural cue and semantic  -->

```{r, echo = F, message = F, eval = F}
#| label: tbl-rwconfsem 
#| tbl-cap: 'Results of the statistical analysis containing the predictions from the Rescorla-Wagner logistic model with configural cues and increased saliency for semantic cues.'

fixefs_model_model_human_conf_sem_preds = fixefs_model_model_human_conf_sem_preds %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric)) %>%
  mutate(term = c('Intercept', 'RW Model Predictions'))


fixefs_model_model_human_conf_sem_preds %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

```{r, echo = F, out.width = '65%', fig.align = 'center', warning = F, message = F, eval = F}
#| label: fig-rwconfsemcoef
#| fig-cap: "Plot of the coefficient values in the statistical model presented in @tbl-rwconfsem. The x-axis indicates the coefficient estimate while the y-axis indicates the different coefficients in the model. Blue points indicate the posterior mean estimate for each coefficient while the gray bars indicate the 95\\% credible interval for each estimate. The red dashed line indicates 0. Coefficients whose credible intervals do not cross 0 can be interpreted as meaningful effects."




df = fixefs_model_model_human_conf_sem_preds %>%
  rownames_to_column("Term") %>%
  mutate(
    Term = gsub(":", ".", Term),
    Estimate = as.numeric(Estimate),
    Q2.5 = as.numeric(Q2.5),
    Q97.5 = as.numeric(Q97.5)
  )

# Order by estimate for readability
df$Term = factor(df$Term, levels = rev(df$Term)) #df$Term[order(df$Estimate)])

# Plot
df_noint <- df %>%
  filter(Term != "Intercept")

ggplot(df_noint, aes(x = Estimate, y = Term)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5),
                 height = 0.2, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 13) +
  labs(
    x = "Coefficient Estimate",
    y = "Coefficient"
  )

```

```{r, echo = F, out.width = '90%', fig.align = 'center', warning = F, message = F}
#| label: fig-rwvshumanpreds
#| fig-cap: "Plot of the RW suffix activations for the best performing model (configural cues plus modified salience of semantic cues) versus the human results. The y-axis is the probability of producing the frequent meaning. The top facet corresponds to novel meanings and the bottom axis corresponds to original meanings. Along the x-axis, the human results are indicated by bars labeled 'Human' and the Rescorla-Wagner model results are indicated by bars labeled 'RW Sims'. The results demonstrate that the RW model qualitatively captures the results in the Type Frequency and Type-Token Frequency conditions, but falls short of capturing the human results in the Token Frequency condition."
#| fig-height: 6
#| fig-width: 7

#best parameters for production are SemALpha = 0.65, Beta = 0.6, Alpha = 0.05

config_mod_sem = read_csv('../Data/grid_search_results_best_params.csv') %>%
  mutate(model_type = 'Modified Sim', 
         Prob = arm::invlogit(mean_freq_diff_v2),
         Lower = arm::invlogit(ci2.5),
         Upper = arm::invlogit(ci97.5)) %>%
  dplyr::select('meaning', 'prod_condition', 'condition', 'Prob', 'model_type', 'Lower', 'Upper')

fixed_effects_df = read_csv('../Data/fixed_effects_df_all.csv') %>%
  filter(Task == 'prod') %>%
  mutate(model_type = 'Human') %>%
  rename('meaning' = 'Meaning', 'condition' = 'Condition', 'mean_freq_diff' = 'Estimate', 'prod_condition' = 'Stem') %>%
  mutate(condition = case_when(
    condition == 'cond1' ~ 1,
    condition == 'cond2' ~ 2,
    condition == 'cond3' ~ 3
  )) %>%
  dplyr::select('meaning', 'prod_condition', 'condition', 'Prob', 'model_type', 'Lower', 'Upper')

# no_config_cues = read_csv('../Data/data_all_conds_logistic.csv') %>%
#   mutate(model_type = 'RW Logistic', 
#          Prob = arm::invlogit(mean_freq_diff_v2),
#          Lower = arm::invlogit(ci2.5),
#          Upper = arm::invlogit(ci97.5)) %>%
#   dplyr::select('meaning', 'prod_condition', 'condition', 'Prob', 'model_type', 'Lower', 'Upper')
  

all_data = config_mod_sem %>%
  full_join(fixed_effects_df) #%>%
  #full_join(no_config_cues)

#all_data = read_csv('../Data/model_preds_and_human_data.csv')

all_data$Meaning = all_data$meaning
all_data$Condition = all_data$condition
all_data$Stem = all_data$prod_condition


all_data = all_data %>%
  mutate(across(where(is.character), str_to_title)) %>%
  mutate(Condition = case_when(
    Condition == 1 ~ 'Type Frequency',
    Condition == 2 ~ 'Token Frequency', 
    Condition == 3 ~ 'Type-Token Frequency'
  ))

all_data$Condition = factor(all_data$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))

observed_vs_model_plot =
  ggplot(all_data, aes(x = model_type, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) +
  geom_errorbar(
    aes(ymin = Lower, ymax = Upper),
    width = 0.2,
    position = position_dodge(width = 0.9)
  ) +
  xlab('Human Data vs Model Predictions') +
  ylab('Probability of the Frequent Meaning') +  
  scale_fill_manual(values = c("Familiar" = "#66c2a5", "Novel" = "#8da0cb")) +
  ylim(c(0,1)) +
  facet_grid(Meaning~Condition) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


observed_vs_model_plot

#ggarrange(observed_estimates_plot, rw_plot, nrow = 2, common.legend = T)
```

Overall, the results of our simulations suggest that a simple connectionist model fits the human data well. Further, a model with configural cues and increased salience of semantic cues fits the human data better than even the original statistical predictors. This parallels previous findings in demonstrating that humans learn associations for configural cues and that humans are more sensitive to semantic cues than phonological cues, and provides support for a connectionist approach to human cognition.

```{r, echo = F, message = F, eval = F}
#| label: tbl-loocv 
#| tbl-cap: 'Results of our leave-one-out cross-validation.'
#| 
terms_of_interest = c('Only RW Activation', 'Stem and Meaning Activations by Condition', 'Original Statistical Predictors')

loo_co_results = loo_co_results %>%
  select(elpd_diff, se_diff, elpd_loo, se_elpd_loo, term) %>%
  filter(term %in% terms_of_interest)
  

loo_co_results %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '22em')
```

```{r eval = F}
#@fig-rwvshumanpreds provides a visualization of the model predictions compared to the human results. The visualization demonstrates high agreement between the predictions and human results for the type frequency condition and the type-token frequency condition, but falls short in predicting the human results for the token frequency condition. More specifically, the model predicts an effect of stem familiarity for the token frequency condition that does not appear in the human data. One possible explanation for this difference is that humans be sensitive to the fact that stem identity is a useful predictor of the meaning in the type frequency condition but not in the token frequency condition. Specifically, in the type frequency condition, certain stems appeared only with one suffix, however in the token frequency condition all the stems occurred with all of the suffixes. This may lead to learners paying attention to the stem identity in the type frequency condition but not in the token frequency condition. On the other hand, the model learns to associate all of the cues with the present outcomes irregardless of whether that cue occurs with more than one outcome.
```

<!--# could test this with eye-tracking if we really wanted to, do people fixate longer on stems in the type frequency condition compared to the token frequency condition? -->

```{r eval = F}
# $$
#\begin{aligned}
#\text{frequency} & \sim \text{freq\_minus\_infreq\_stem} * \text{freq\_minus\_infreq\_meaning} \\ & + (1 | \text{participant}) + (1|\text{resp\_stem})
#\end{aligned}
#$$ {#eq-rwmodel2}

# $$
# \begin{aligned}
# \text{frequency} &\sim  \text{condition}*\text{meaning}*\text{stem\_condition} + \text{freq\_minus\_infreq} \\ & + (1  | \text{participant}) + (1 | \text{resp\_stem})
# \end{aligned}
# $$ {#eq-rwmodel4}
# 
# $$
# \begin{aligned}
# \text{frequency} &\sim  \text{condition}*\text{meaning}*\text{stem\_condition} \\ & + \text{freq\_minus\_infreq\_stem} * \text{freq\_minus\_infreq\_meaning} * \text{condition} \\ & + (1  | \text{participant}) + (1 | \text{resp\_stem})
# \end{aligned}
# $$ {#eq-rwmodel5}
```

```{r, echo = F, message = F, eval = F}
#| label: tbl-rwsim1
#| tbl-cap: 'Results of the statistical model with only the RW predictions (@eq-rwmodel1).'


fixefs_human_rw_preds = as.data.frame(fixef(model_human_rw_preds)) %>%
  mutate(term = rep(c('Intercept', 'RW Predictions'), times = 1))


fixefs_human_rw_preds = fixefs_human_rw_preds %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5), as.numeric))


fixefs_human_rw_preds %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')

```

```{r, echo = F, message = F, eval = F}
#| label: tbl-rwsim2 
#| tbl-cap: 'Results of the statistical analysis containing the predictions from the Rescorla-Wagner logistic model separated into stem activations and meaning activations. The results demonstrate that the human data is predicted well by both the suffix activations and the stem activations (eq-rwmodel2).'

fixefs_model_rw_preds_stem_suffix_vary = bind_rows(fixefs_model_rw_preds_stem_suffix_vary, .id = "ID") %>%
  mutate(term = rep(c('Intercept', 'Stem Activations', 'Meaning Activations'), times = 1))


fixefs_model_rw_preds_stem_suffix_vary = fixefs_model_rw_preds_stem_suffix_vary %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

fixefs_model_rw_preds_stem_suffix_vary %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

```{r, echo = F, message = F, eval = F}
#| label: tbl-rwsim3 
#| tbl-cap: 'Results of the statistical analysis containing the separated stem and meaning activations and condition as a fixed-effect (@eq-rwmodel3).'

fixefs_model_rw_preds_stem_suffix_vary_by_condition = bind_rows(fixefs_model_rw_preds_stem_suffix_vary_by_condition, .id = "ID") %>%
  mutate(term = rep(c('Intercept', 'Stem Activations', 'Meaning Activations', 'Type Frequency', 'Token Frequency', 'Stem Activations:Type Frequency', 'Stem Activations:Token Frequency', 'Meaning Activations:Type Frequency', 'Meaning Activations:Token Frequency'), times = 1))

fixefs_model_rw_preds_stem_suffix_vary_by_condition = fixefs_model_rw_preds_stem_suffix_vary_by_condition %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

fixefs_model_rw_preds_stem_suffix_vary_by_condition %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

```{r, echo = F, out.width = '65%', fig.align = 'center', warning = F, message = F, eval = F}
#| label: fig-rwsim1coef
#| fig-cap: "Plot of the coefficient values in the statistical model presented in @tbl-rwsim1. The x-axis indicates the coefficient estimate while the y-axis indicates the different coefficients in the model. Blue points indicate the posterior mean estimate for each coefficient while the gray bars indicate the 95\/% credible interval for each estimate. The intercept represents the baseline condition (Type-Token Frequency). All other coefficients are expressed as changes relative to this baseline, so the intercept is omitted from the plot."




df = fixefs_human_rw_preds %>%
  rownames_to_column("Term") %>%
  mutate(
    Term = gsub(":", ".", Term),
    Estimate = as.numeric(Estimate),
    Q2.5 = as.numeric(Q2.5),
    Q97.5 = as.numeric(Q97.5)
  )

# Order by estimate for readability
df$Term = factor(df$Term, levels = rev(df$Term)) #df$Term[order(df$Estimate)])

df_noint <- df %>%
  filter(Term != "Intercept")

ggplot(df_noint, aes(x = Estimate, y = Term)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5),
                 height = 0.2, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 13) +
  labs(
    x = "Coefficient Estimate",
    y = "Coefficient"
  )

```

```{r, echo = F, out.width = '65%', fig.align = 'center', warning = F, message = F, eval = F}
#| label: fig-rwsim3coef
#| fig-cap: "Plot of the coefficient values in the statistical model presented in @tbl-rwsim3. The x-axis indicates the coefficient estimate while the y-axis indicates the different coefficients in the model. Blue points indicate the posterior mean estimate for each coefficient while the gray bars indicate the 95\/% credible interval for each estimate. The intercept represents the baseline condition (Type-Token Frequency). All other coefficients are expressed as changes relative to this baseline, so the intercept is omitted from the plot."




df = fixefs_model_rw_preds_stem_suffix_vary_by_condition %>%
  #rownames_to_column("Term") %>%
  mutate(
    Term = gsub(":", ".", term),
    Estimate = as.numeric(Estimate),
    Q2.5 = as.numeric(Q2.5),
    Q97.5 = as.numeric(Q97.5)
  )

# Order by estimate for readability
df$Term = factor(df$Term, levels = rev(df$Term)) #df$Term[order(df$Estimate)])

df_noint <- df %>%
  filter(Term != "Intercept")

ggplot(df_noint, aes(x = Estimate, y = Term)) +
  geom_point(size = 3, color = "steelblue") +
  geom_errorbarh(aes(xmin = Q2.5, xmax = Q97.5),
                 height = 0.2, color = "gray40") +
  geom_vline(xintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal(base_size = 13) +
  labs(
    x = "Coefficient Estimate",
    y = "Coefficient"
  )

```

```{r, echo = F, message = F, eval = F}
#| label: tbl-rwsim4
#| tbl-cap: 'Results of the statistical model with the RW predictions alongside the original predictors (@eq-rwmodel4).'


percent_greater_zero = data.frame(fixef(model_prod_both_stem_rw_simple, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_model_human_and_rw = percent_greater_zero %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'freq_minus_infreq', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_human_and_rw_predictors = as.data.frame(fixef(model_prod_both_stem_rw_simple)) %>%
    mutate(percent_greater_zero = percent_greater_zero_model_human_and_rw$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


fixefs_human_and_rw_predictors = fixefs_human_and_rw_predictors %>%
  mutate(term = rep(c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Frequent - Infrequent (RW)', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem'), times = 1))

fixefs_human_and_rw_predictors = fixefs_human_and_rw_predictors %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_human_and_rw_predictors %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')
```

```{r, echo = F, message = F, eval = F}
#| label: tbl-rwsim5
#| tbl-cap: 'Results of the statistical model with the RW predictions separated into stem and meaning activations alongside the predictors from the human model (@eq-rwmodel5).'


percent_greater_zero = data.frame(fixef(model_prod_rw_stem_suffix_vary_by_condition_original_preds, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_model_rw_preds_stem_suffix_vary_by_condition_original_preds = percent_greater_zero %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'freq_minus_infreq_stem', 'infreq_minus_infreq_suffix', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.freq_minus_infreq_stem', 'condition2.freq_minus_infreq_stem', 'condition1.freq_minus_infreq_suffix', 'condition2.freq_minus_infreq_suffix',  'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))



fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds = as.data.frame(fixef(model_prod_rw_stem_suffix_vary_by_condition_original_preds)) %>%
    mutate(percent_greater_zero = percent_greater_zero_model_rw_preds_stem_suffix_vary_by_condition_original_preds$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds = fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds %>%
  mutate(term = rep(c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Stem Activations', 'Meaning Activations', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Stem Activations', 'Token Frequency:Stem Activations', 'Type Frequency:Suffix Activations', 'Token Frequency:Suffix Activations', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem'), times = 1)) #need to fix this

fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds = fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_model_rw_preds_stem_suffix_vary_by_condition_original_preds %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')
```

### Comprehension Models

In this section, we present the results of modeling the comprehension data using the Rescorla-Wagner logistic model. Similar to the production data, the RW model was trained on the same series of training trials as our human subjects (presented in a random order). However, instead of modeling the data with the cues being stem identity and meaning, since we were modeling comprehension the cues instead were the steam identity and suffix. Additionally, the outcome was the meaning.

As before, we used a grid search to identify the best parameters for modeling the comprehension data. The best parameters were an alpha value of 0.45 and a beta value of 0.25.

For each of the items in the comprehension task, we computed the activation of that item for the novel meaning (diminutive plural) and the familiar meaning (big plural for *dan* and diminutive singular for *nem*). We then calculated the difference in activation between the new meaning and the familiar meaning. This served as our value for the RW prediction. A larger value indicates the RW model predicts a higher probability of choosing the novel meaning while a smaller (more negative) value indicates the RW model predicts a higher probability of choosing the familiar meaning.

In order to examine the fit of the RW model to the human data, we ran six Bayesian logistic regression models. The dependent variable for all the models was whether the participant chose the novel meaning (1) or the familiar meaning (0). The independent variables varied across models. For the first model, the independent variable was simply the RW predictions (new_minus_old). In the second model, we also included condition (baseline, High Type, and Low Token) along with an interaction between condition and the RW predictions. In the third model, instead of condition we included stem familiarity (and interaction). The fourth model included all three (along with the two-way interactions and the three-way interaction). The final two models included only the original statistical predictors instead the RW predictors. More specifically, the fifth model included only condition, and the sixth model included condition and stem familiarity (along with their interaction). All six models included a random intercept for participant and a random intercept for stem identity. The model equations for each are included below.

$$
\begin{aligned}
\text{meaning} & \sim \text{new\_minus\_old} \\ 
& +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwcomp1}

$$
\begin{aligned}
\text{meaning} & \sim \text{new\_minus\_old} * \text{condition} \\ 
& +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwcomp2}

$$
\begin{aligned}
\text{meaning} & \sim \text{new\_minus\_old} * \text{stem\_familiarity} \\ 
& +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwcomp3}

$$
\begin{aligned}
\text{meaning} & \sim \text{new\_minus\_old} * \text{condition} * \text{stem\_familiarity} \\ 
& +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwcomp4}

$$
\begin{aligned}
\text{meaning} & \sim \text{condition} \\ 
& +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwcomp5}

$$
\begin{aligned}
\text{meaning} & \sim \text{condition} * \text{stem\_familiarity} \\ 
& +  (1 | \text{participant}) + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwcomp6}

In order to examine which model fit the human data best, we once again turned to leave-one-out cross-validation. The results are presented below in @tbl-rwcomploocv. The results suggest that the RW predictions capture the effect of stem familiarity (because adding stem familiarity does not improve the model fit much) but the model is not fully capturing the effect of condition (because adding condition does improve the model fit).

```{r, echo = F, message = F}
#| label: tbl-rwcomploocv
#| tbl-cap: "Results of the leave-one-out cross-validation for the additional simulation. The results suggest that the RW predictions capture the effect of stem familiarity (because adding stem familiarity does not improve the model fit much) but the model is not fully capturing the effect of condition (because adding condition does improve the model fit)."

loo_results_rwcomp = loo_results_rwcomp %>%
  dplyr::select(elpd_diff, se_diff, elpd_loo, se_elpd_loo, term) 


loo_results_rwcomp %>%
  dplyr::select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '22em')

```

In order to further understand where the differences between the model predictions and the human behavior, we compared the results of the statistical analysis including fixed-effects for the RW predictions, stem familiarity, and their interaction (@eq-rwcomp3; @tbl-rwcomp3). The model results are visualized side-by-side with the human results in @fig-rwcomp3.. The visualization demonstrates that the model predicts the Low Token condition (3-3) well, but falls short in its predictions for the other two conditions (baseline and High Type), demonstrated by the interaction effect between the low token condition and the RW predictions. Qualitatively, this appears to be due to the model predicting a strong effect of stem familiarity in the High Type condition and a minor effect of stem familiarity in the baseline condition (as demonstrated in @fig-rwcomp3) while humans do not show any effect of stem familiarity.

```{r, echo = F, message = F}
#| label: tbl-rwcomp3 
#| tbl-cap: 'Results of the model in @eq-rwcomp3 containing the predictions from the Rescorla-Wagner logistic model along with condition and stem familiarity. The results suggest the model does a good job of explaining the human data for the Low Token condition, but not for the High Type or baseline conditions.'

#3-3 is mathem

fixefs_model_comprehension_numeric_rw_by_cond = fixefs_model_comprehension_numeric_rw_by_cond %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric)) %>%
  mutate(term = c('Intercept (Baseline/12-3)', 'High Type (12-12)', 'Low Token (3-3)', 'RW Predictions', 'High Type:RW Predictions', 'Low Token:RW Predictions'))


fixefs_model_comprehension_numeric_rw_by_cond %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

```{r eval = F}
#| label: fig-rwcomp3old
#| fig-cap: "Plot of the comprehension data and the RW model predictions from the model presented in @eq-rwcomp3."

library(brms)
library(ggplot2)

ce <- conditional_effects(
  model_comprehension_numeric_rw_by_cond, #model_comprehension_numeric_stem_rw;model_comprehension_numeric_stem_humans
  effects = "new_minus_old:condition_numeric"
)

p <- plot(ce, plot = FALSE)[[1]]

colors <- c("#0072B2", "#D50E00", "#009E73")

# desired legend order and labels
breaks <- c("12-3", "12-12", "3-3")
labels <- c("Baseline (12-3)", "High Type (12-12)", "Low Token (3-3)")

p +
  scale_color_manual(
    values = colors,
    breaks = breaks,
    labels = labels
  ) +
  scale_fill_manual(
    values = colors,
    breaks = breaks,
    labels = labels
  ) +
  guides(fill = "none") +
  labs(
    x = "Meaning (new minus old)",
    y = "Predicted Probability of Human Response",
    color = "Condition"
  ) +
  theme_bw() +
  theme(
    text = element_text(size = 14),
    legend.position = "right"
  )


```

```{r echo = F, message = F}
#| label: fig-rwcomp3
#| fig-cap: "Plot of the RW predictions as a function of condition and stem familiarity (left) and human results as a function of condition and stem familiarity (right). The x-axis denotes the condition and the coloring denotes whether the stem was novel (purple) or familiar (blue)."
#| fig-height: 8
#| fig-width: 12

library(brms)
library(ggplot2)

#best parameters for comprehension were Beta = 0.25, Alpha = 0.45

#p1 <- plot(ce1, points = FALSE)[[3]]  # third plot
#p2 <- plot(ce2, points = FALSE)[[3]]

ce1 <- conditional_effects(model_rw_preds_by_statistical_preds_nsims)
ce2 <- conditional_effects(model_comprehension_numeric_stem_humans)

#p1_raw <- plots1[[3]]
#p2_raw <- plots2[[3]]
p1_mod <- plot(ce1, plot = FALSE)[[3]] +
  scale_color_manual(
    values = c("familiar"="#1F77B4","novel"="#4B0082"),
    labels = c("familiar"="Familiar","novel"="Novel")
  ) +
  scale_fill_manual(
    values = c("familiar"="#1F77B4","novel"="#4B0082"),
    labels = c("familiar"="Familiar","novel"="Novel")
  ) +
  scale_x_discrete(
    name="Condition",
    labels=c("12-3"="High Type","12-12"="Baseline","3-3"="Low Token")
  ) +
  labs(color = "Stem Familiarity", fill = "Stem Familiarity") +
  ylab("RW Predictions") +
  theme_bw(base_size = 14) +
  theme(
    axis.text.x  = element_text(size = 14),
    axis.text.y  = element_text(size = 14),
    axis.title.x = element_text(size = 16, margin = margin(t = 12)),
    axis.title.y = element_text(size = 16, margin = margin(r = 12))
  )


p2_mod <- plot(ce2, plot = FALSE)[[3]] +
  scale_color_manual(
    values = c("familiar"="#1F77B4","novel"="#4B0082"),
    labels = c("familiar"="Familiar","novel"="Novel")
  ) +
  scale_fill_manual(
    values = c("familiar"="#1F77B4","novel"="#4B0082"),
    labels = c("familiar"="Familiar","novel"="Novel")
  ) +
  scale_x_discrete(
    name="Condition",
    labels=c("12-3"="High Type","12-12"="Baseline","3-3"="Low Token")
  ) +
  labs(color = "Stem Familiarity", fill = "Stem Familiarity") +
  ylab("Human Data") +
  theme_bw(base_size = 14) +
  theme(
    axis.text.x  = element_text(size = 14),
    axis.text.y  = element_text(size = 14),
    axis.title.x = element_text(size = 16, margin = margin(t = 12)),
    axis.title.y = element_text(size = 16, margin = margin(r = 12))
  )


library(patchwork)

combined_plot <- (p1_mod + p2_mod) +
  plot_layout(guides = "collect") &
  theme(legend.position = "right")

combined_plot





```

## Discussion

Our results suggest that in production, having a high type and high token frequency together lead to a preference for the frequent suffix, and this preference is even stronger if the stem is novel. On the other hand, when there is a high type frequency but not a high token frequency, there is only a preference for the frequent form when the stem and meaning are both novel. Finally, for token frequency there is only a preference for the frequent form when the meaning is original. Overall, these results suggest that type frequency and token frequency both play a role in semantic extension, with a high type frequency encouraging semantic extension while a high token frequency encourages using the suffix to communicate the original meaning. Similar to @harmonPuttingOldTools2017, these effects are mitigated when both forms are brought into memory.

A similar pattern emerges in comprehension. When there is a high token-to-type ratio, the original meaning is preferred more. However, when there are as many types as there are tokens, there is an increased preference for the novel meaning relative to when there is a high token-to-type ratio.

Our results also demonstrate that the Rescorla-Wagner model with a logistic activation function is able to capture the human data. Further, the model matches the human data best when it includes configural cues and an increased salience for semantic cues relative to phonological cues.

\newpage
