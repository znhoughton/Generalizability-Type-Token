---
#title: "generalizability-writeup"
format: 
  pdf:
    fontsize: 12pt
    mainfont: "Crimson"        # Primary text font
    CJKmainfont: "Noto Serif KR"  # Font for Korean text
    geometry:
      - left=1in
      - right=1in
      - top=1in
      - bottom=1in
    

header-includes:
- \usepackage{amsmath}
- \usepackage{fontspec}    % Ensure font support
- \usepackage{placeins}
- \usepackage{float}
- \usepackage{setspace}
- \usepackage{indentfirst}


echo: false
warning: false
message: false

editor: visual
bibliography: references.bib
csl: apa.csl
---

```{r, echo = F, warning = F, message = F}
library(tidyverse)
library(knitr)
library(kableExtra)
library(brms)
library(sjPlot)


fixed_effects_df_all = read_csv('../Data/fixed_effects_df_all.csv')
subject_effects = read_csv('../Data/subject_effects.csv')

fixed_effects_df_all$Task = factor(fixed_effects_df_all$Task, levels = c('prod', '2afc', 'comprehension'))

subject_effects$Task = factor(subject_effects$Task, levels = c('prod', '2afc', 'comprehension'))



condition_labels = c("cond1" = "Type Frequency", 
                      "cond2" = "Token Frequency", 
                      "cond3" = "Type-Token Frequency")
task_labels = c("prod" = "Production",
                "2afc" = "Form-Choice",
                "comprehension" = "Comprehension")

fixed_effects_df_all$Meaning = factor(fixed_effects_df_all$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

subject_effects$Meaning = factor(subject_effects$Meaning, 
                                  levels = c("original", "novel"), 
                                  labels = c("Original", "Novel"))

fixed_effects_df_all$Stem = factor(fixed_effects_df_all$Stem, 
                                  levels = c("familiar", "novel"), 
                                  labels = c("Familiar", "Novel"))

subject_effects$Stem = factor(subject_effects$Stem, 
                                  levels = c("familiar", "novel"), 
                                  labels = c("Familiar", "Novel"))


# model_prod_original = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
#                                        data = data_prod_original,
#                                        family = bernoulli(link = 'logit'),
#                                        iter = 14000, 
#                                        warmup = 7000,
#                                        chains = 4,
#                                        cores = 4,
#                                        prior = priors_m1,
#                                        control = list(adapt_delta = 0.99),
#                                        file = '../Data/model_prod_original')
# 
# model_prod_novel = brm(frequency ~ condition + (1 | participant) + (condition | resp_stem),
#                                        data = data_prod_novel,
#                                        family = bernoulli(link = 'logit'),
#                                        iter = 14000, 
#                                        warmup = 7000,
#                                        chains = 4,
#                                        cores = 4,
#                                        prior = priors_m1,
#                                        control = list(adapt_delta = 0.99),
#                                        file = '../Data/model_prod_novel')



model_prod_both = brm(frequency ~ condition*meaning + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_both')



percent_greater_zero_both = data.frame(fixef(model_prod_both, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'condition1:meaning1', 'condition2:meaning1')))


fixefs_model_prod_both = as.data.frame(fixef(model_prod_both)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


model_prod_both_stems = brm(frequency ~ condition*meaning*stem_condition + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_prod_both_stem')



percent_greater_zero_both_stems = data.frame(fixef(model_prod_both_stems, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both_stems = percent_greater_zero_both_stems %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_model_prod_both_stems = as.data.frame(fixef(model_prod_both_stems)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both_stems$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


rownames(fixefs_model_prod_both_stems) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')


model_2afc_both = brm(frequency ~ condition*meaning + (1 + meaning | participant),
                                       data = data_prod_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both')





percent_greater_zero_both = data.frame(fixef(model_2afc_both, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'condition1:meaning1', 'condition2:meaning1')))


fixefs_model_2afc_both = as.data.frame(fixef(model_2afc_both)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_2afc_both) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Type Frequency:Novel', 'Token Frequency:Novel')



model_2afc_both_stem = brm(frequency ~ condition*meaning*stem_condition + (1 + meaning | participant),
                                       data = data_2afc_both,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       file = '../Data/model_2afc_both_stem')




percent_greater_zero_both = data.frame(fixef(model_2afc_both_stem, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)

percent_greater_zero_both = percent_greater_zero_both %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_model_2afc_both_stem = as.data.frame(fixef(model_2afc_both_stem)) %>%
    mutate(percent_greater_zero = percent_greater_zero_both$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
    mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_2afc_both_stem) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')





model_comprehension_numeric = brm(meaning ~ condition_numeric + (1 | participant),
                                       data = data_analysis_comprehension,
                                       family = bernoulli(link = 'logit'),
                                       iter = 10000, 
                                       warmup = 5000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       file = '../Data/model_comprehension_numeric')

percent_greater_zero_comprehension_numeric = data.frame(fixef(model_comprehension_numeric, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


fixefs_model_comprehension_numeric = as.data.frame(fixef(model_comprehension_numeric)) %>%
    mutate(percent_greater_zero = percent_greater_zero_comprehension_numeric$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)



rownames(fixefs_model_comprehension_numeric) = c('Intercept', '12-12', '3-3')

plot_df_stems_all_cond1 = read_csv('../Data/plot_df_stems_all_cond1_linear.csv')
plot_df_stems_all_cond2 = read_csv('../Data/plot_df_stems_all_cond2_linear.csv')
plot_df_stems_all_cond3 = read_csv('../Data/plot_df_stems_all_cond3_linear.csv')

plot_df_stems_cond1 = ggplot(plot_df_stems_all_cond1, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Type Frequency Condition"
  ) +
  ylim(-1.5,2) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond2 = ggplot(plot_df_stems_all_cond2, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Token Frequency Condition"
  ) +
  ylim(-1.5,2) +
  facet_wrap(~Stem) +
  theme_minimal()

plot_df_stems_cond3 = ggplot(plot_df_stems_all_cond3, aes(x = row_number, y = weights, color = label)) +
  geom_line() +
  labs(
    x = "Index",
    y = "Activation Weight",
    color = "Meaning and Frequency",
    title = "Type-Token Frequency Condition"
  ) +
  ylim(-1.5,2) +
  facet_wrap(~Stem) +
  theme_minimal()

all_cond_estimates_paper = read_csv('../Data/all_cond_estimates_linear.csv')

all_cond_estimates_paper$Condition = factor(all_cond_estimates_paper$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))

all_cond_estimates_paper2 = read_csv('../Data/all_cond_estimates_for_paper2.csv')

all_cond_estimates_paper2$Condition = factor(all_cond_estimates_paper2$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))




model_prod_both_stem_rw = brm(frequency ~ condition*meaning*stem_condition + freq_minus_infreq + (1 + stem_condition*meaning | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_both_stem_rw_preds_final')


percent_greater_zero_rw_preds = data.frame(fixef(model_prod_both_stem_rw, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_rw_preds = percent_greater_zero_rw_preds %>%
  arrange(match(beta_coefficient, c('Intercept', 'condition1', 'condition2', 'meaning1', 'stem_condition1', 'freq_minus_infreq', 'condition1.meaning1', 'condition2.meaning1', 'condition1.stem_condition1', 'condition2.stem_condition1', 'meaning1.stem_condition1', 'condition1.meaning1.stem_condition1', 'condition2.meaning1.stem_condition1')))


fixefs_model_rw_preds = as.data.frame(fixef(model_prod_both_stem_rw)) %>%
    mutate(percent_greater_zero = percent_greater_zero_rw_preds$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)

#fixefs_model_rw_preds

rownames(fixefs_model_rw_preds) = c('Intercept', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Frequent - Infrequent (RW)', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem')


model_human_rw_preds = brm(frequency ~ freq_minus_infreq + (1 | participant) + (1|resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 15000, 
                                       warmup = 7500,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       #control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_rw_preds')

model_prod_both_stem_rw_simple = brm(frequency ~ condition*meaning*stem_condition + freq_minus_infreq + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_both_stem_rw_simple')


model_prod_both_stem_simple_humans = brm(frequency ~ condition*meaning*stem_condition + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_both_stem_simple_humans')

model_prod_rw_stem_suffix_vary = brm(frequency ~ freq_minus_infreq_stem * freq_minus_infreq_suffix + (1 | participant) + (1 | resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_stem_suffix_vary,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_rw_stem_suffix_vary')

percent_greater_zero_rw_preds_stem_suffix_vary = data.frame(fixef(model_prod_rw_stem_suffix_vary, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_rw_preds_stem_suffix_vary = percent_greater_zero_rw_preds_stem_suffix_vary %>%
  arrange(match(beta_coefficient, c('Intercept', 'freq_minus_infreq_stem', 'freq_minus_infreq_suffix', 'freq_minus_infreq_stem.freq_minus_infreq_suffix')))


fixefs_model_rw_preds_stem_suffix_vary = as.data.frame(fixef(model_prod_rw_stem_suffix_vary)) %>%
    mutate(percent_greater_zero = percent_greater_zero_rw_preds_stem_suffix_vary$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)


loo_co_results = data.frame(loo_compare(model_human_rw_preds, model_prod_rw_stem_suffix_vary, model_prod_both_stem_rw_simple, model_prod_both_stem_simple_humans)) %>%
  mutate('term' = c('Stem and Meaning Activations as Separate Predictors', 'Original Predictiors Plus RW Activations', 'Only RW Activations', 'Only Original Predictors'))


fixed_effects_df = read_csv('../Data/fixed_effects_df_all.csv') %>%
  filter(Task == 'prod')

observed_estimates = fixed_effects_df 


observed_estimates_plot = ggplot(data = observed_estimates, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = "dodge") +
  ylim(c(0,1)) +
  facet_wrap(~Condition)


model_human_conf_sem_preds = brm(frequency ~ freq_minus_infreq + (1 | participant) + (1|resp_stem),
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_sem_alpha,
                                       family = bernoulli(link = 'logit'),
                                       iter = 22000, 
                                       warmup = 1100,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_human_conf_sem_preds')


percent_greater_zero_model_human_conf_sem_preds = data.frame(fixef(model_human_conf_sem_preds, summary = F)) %>%
  pivot_longer(cols = everything(), names_to = 'beta_coefficient', values_to = 'estimate') %>%
  group_by(beta_coefficient) %>%
  summarize((sum(estimate > 0) / length(estimate)) * 100)


percent_greater_zero_model_human_conf_sem_preds = percent_greater_zero_model_human_conf_sem_preds %>%
  arrange(match(beta_coefficient, c('Intercept', 'freq_minus_infreq_stem', 'freq_minus_infreq_suffix', 'freq_minus_infreq_stem.freq_minus_infreq_suffix')))


fixefs_model_model_human_conf_sem_preds = as.data.frame(fixef(model_human_conf_sem_preds)) %>%
    mutate(percent_greater_zero = percent_greater_zero_model_human_conf_sem_preds$`(sum(estimate > 0)/length(estimate)) * 100`) %>%
  mutate_if(is.numeric,
            formatC,
            format = 'f', 
            digits = 3) %>%
    rename('% Samples > 0' = `percent_greater_zero`)

# data_all_conds_logistic2 = read_csv('../Data/data_all_conds_logistic.csv') %>%
#   mutate(meaning = case_when(
#     type == 'dim_sg' | type == 'big_pl' ~ 'original',
#     type == 'dim_pl' ~ 'novel'
#   )) %>%
#   mutate(condition = case_when(
#     condition == 1 ~ 1,
#     condition == 2 ~ 2,
#     condition == 3 ~ 3, 
#     condition == 4 ~ 1, 
#     condition == 5 ~ 2,
#     condition == 6 ~ 3
#   )) %>%
#   group_by(meaning, prod_condition, condition) %>%
#   summarize(mean_freq_diff = mean(freq_minus_infreq), .groups = 'keep')
#  
# rw_plot = ggplot(data = data_all_conds_logistic2, aes(x = meaning, y = invlogit(mean_freq_diff), fill = prod_condition)) +
#   geom_col(position = "dodge") +
#   ylim(c(0,1)) +
#   facet_wrap(~condition)

model_prod_rw_stem_suffix_vary_match_human_model = brm(frequency ~ freq_minus_infreq_stem * freq_minus_infreq_suffix * condition * meaning * stem_condition + (1 | participant), #resp_stem intercept removed because it's redundant with freq_minus_infreq_stem
                                       data = human_data_no_sil_no_shoon_plus_rw_preds_stem_suffix_vary,
                                       family = bernoulli(link = 'logit'),
                                       iter = 14000, 
                                       warmup = 7000,
                                       chains = 4,
                                       cores = 4,
                                       prior = priors_m1,
                                       control = list(adapt_delta = 0.99),
                                       save_pars = save_pars(all = TRUE),
                                       file = '../Data/model_prod_rw_stem_suffix_vary_match_human_model')
```

# The effects of type and token frequency on semantic extension

\doublespacing

\setlength{\parindent}{4em}

## Introduction

## Methods

Following @harmonPuttingOldTools2017, two artificial languages were used: Dan and Nem (See @fig-fig1). In each language, the same four suffixes were used: -*sil~PL~*, *-dan~PL~*, *-nem~DIM~*, and -*shoon~DIM~*. Notably, in our language *-dan* and *-sil* overlap in meaning (they both occur in plural contexts), and -*nem* and *-shoon* also overlap in meaning (they both occur in diminutive contexts). Since all four suffixes are possible candidates for the diminutive plural meaning, we will examine how properties of the language affect which suffixes are extended to express the diminutive plural meaning.

![A description of the suffixes in our artificial languages. The thicker lines denote the more frequent form in each language: the plural -*dan~PL~* in the Dan language and the diminutive -*nem~DIM~* in the Nem language.](languages.pdf){#fig-fig1}

During the exposure phase, each suffix was was paired with an image. The suffixes -*sil~PL~* and *-dan~PL~* were always paired with a picture of multiple large pictures. On the other hand, the suffixes *-nem~DIM~* and -*shoon~DIM~* were always paired with a picture of a single small creature. The design of the stimuli results in participants being able to learn that -*sil* and *-dan* are either simply plural or simply non-diminutive. Similarly, *-nem* and *-shoon* can be learned as either simply singular or simply diminutive.

Our Experiment comprised of three different conditions (see @tbl-conditionslist), one in which the type frequency of the frequent language's suffix was manipulated (Type Frequency), one in which the token frequency was manipulated (Token Frequency), and one in which both were manipulated (Type-Token Frequency). In this context, a higher type frequency corresponds to the suffix appearing with a larger number of different stems relative to the competing suffix, while a larger token frequency corresponds to simply appearing a greater number of times relative to the competing suffx, regardless of the number of different stems it occurs with.

```{r, echo = F, message = F}
#| label: tbl-conditionslist
#| tbl-cap: 'Description of each of our conditions. Note that in Condition 1, there are an equal number of tokens between the frequent and infrequent items, however there are a greater number of types in the frequent items. In Condition 2, the opposite is true: the frequent items occur more, but in the same number of types as the infrequent items. Finally, in Condition 3, the frequent items occur both a greater number of times and in a greater number of different contexts.'

conditionslist = data.frame('Frequent Token' = c(12, 12, 12),
                            'Frequent Type' = c(12, 3, 12),
                            'Infrequent Token' = c(12, 3, 3),
                            'Infrequent Type' = c(3, 3, 3))

conditionslist = conditionslist %>%
  mutate(term = rep(c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'), times = 1))

conditionslist %>%
  dplyr::select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')
```

### Procedure

Each participant was randomly assigned one of the conditions. In each condition, participants were first presented with an exposure phase. After the exposure phase, participants were tested using a production task, a form choice task, and a comprehension task. We describe each of these below.[^1]

[^1]: Additionally, a demo of the experiment can be found at the following link: <https://run.pavlovia.org/znhoughton/generalizability_demo>.

#### Exposure Phase

Following @harmonPuttingOldTools2017, each exposure trial consisted of the presentation of a picture on the computer screen which was subsequently followed with a written label for the image as well as an audio presentation of that label. Specifically, the image first appeared on the screen and then 1.25 seconds later was followed by both the label of the creatures on the screen as well as the audio for that creature. Participants were instructed to type the name of the creature and press enter. Participants had 4 seconds to respond after the presentation of the name of the creature and were given feedback as to whether they were correct or not.

Participants saw each trial within the exposure phase 5 times, each in a randomized order.

#### Production Task

After the exposure phase, participants were presented with a production task. In this task, participants were presented with images and told to produce a label for the image. Specifically, initially the unafixxed form appeared on the screen along with the corresponding image. 2 seconds later, the four different possible images of that creature appeared (a singular big creature, multiple big creatures, a single small creature, and multiple small creatures). Three of these images disappeared after 1.25 seconds, leaving a single image for the participant to produce a label for. Participants had 10 seconds to respond. In the production task, some of the stems were familiar (i.e., seen in training) and others were novel (i.e., not seen in training).

Participants saw each trial within the production task 4 times, each in a randomized order.

#### Form Choice Task

After the production task, participants were presented with a form choice task. In this task, participants were presented first with the base, unaffixed form and the corresponding image. 2 seconds later four images flashed on the screen, remained on the screen for 1.25 seconds, and disappeared leaving a single image. Along with the single image, participants were also presented with two possible labels for that image, one label on the bottom right of the screen and one label on the bottom left of the screen. Participants were given four seconds to press either the left arrow or the right arrow to choose the corresponding label. The labels were counterbalanced with respect to which side of the screen they appeared on. In the form choice task, some of the stems were familiar (i.e., seen in training) and others were novel (i.e., not seen in training). The goal of this task was to assess whether type and/or token frequency influence the form choice when accessibility differences between frequent and rare forms have been attenuated.

Participants saw each trial within the form choice task 2 times, each in a randomized order.

#### Comprehension Task

Finally, participants were presented with a comprehension task. In this task, participants were first given the label and corresponding audio for a given creature. After 0.25 seconds, four images appeared on the screen and participants had 4 seconds to click one of the images on the screen that corresponded to the label. Similar to the before-mentioned tasks, in the comprehension task some of the stems were familiar (i.e., seen in training) and others were novel (i.e., not seen in training).

Participants saw each trial within the comprehension task 2 times, each in a randomized order.

## Analyses and Results

In order to examine the effects of type and token frequency on participants choice of suffix, we examined the effects of type and token frequency on the original meaning as well as the novel meaning (diminutive plural).[^2]

[^2]: All data and code for the analyses can be found here: <https://github.com/znhoughton/Generalizability-Type-Token>.

First we report a general plot of our results before going into detail about each task (@fig-fullresults). In order to visualize the results, we subsetted the data by condition (type frequency, token frequency, or type-token frequency), stem (familiar or novel), task (production, form-choice, or comprehension), and meaning (original or novel). We then ran a logistic regression model. For the form-choice and production tasks, the dependent variable was 1 if the participant chose the frequent suffix for that trial or 0 if they chose the infrequent suffix and the independent variable was the intercept with random intercepts for participant and stem identity. For the comprehension task, the dependent variable was 1 if they chose the original meaning for the original meaning portion and 1 if they chose the novel meaning in the novel meaning portion and the independent variable was the intercept with random intercepts for participant and stem identity. For example, the larger estimates for the original meaning in the type frequency condition indicate that participants preferred to select the original meaning for both stem types. As a result, these bars are lower for the novel meaning since the original and novel estimates for a given stem type sum to 1. While this visualization for the comprehension is admittedly a bit awkward, the advantage is it allows us to visualize it alongside the results for production and form-choice tasks.

```{r, echo = F, out.width = '80%', fig.align = 'center', warning = F, message = F}
#| label: fig-fullresults
#| fig-cap: "Plot of our results. Points indicate individual subject values. The x-axis indicates whether the meaning was original or novel. Green coloring corresponds to the frequent stem while blue corresponds to the infrequent stem. The y-axis indicates the response probability. For Production and Form-choice, it is the response probability of choosing the frequent form. Thus, a value closer to 1 indicates that participants chose the frequent form more than the infrequent form. For Comprehension, it is the response probability of choosing a given meaning. For example, a value closer to 1 for the original meaning with a novel stem indicates that when participants saw a novel stem with *dan*, they were more likely to select the big.pl meaning than the dim.pl meaning (as a result, for a given stem familiarity the original and novel bars sum to 1 in the comprehension condition). Facets indicate condition (type frequency, token frequency, or type-token frequency) and task (production, form-choice, comprehension). The results were obtained by running a separate regression model "
#| fig-height: 6
#| fig-width: 7

ggplot(fixed_effects_df_all, aes(x = Meaning, y = Prob, fill = Stem)) +
  geom_col(position = position_dodge(width = 0.9)) + 
  geom_point(data = subject_effects, 
             aes(x = Meaning, y = subj_values, fill = Stem, color = Stem),  # Map fill and color
             shape = 21,   # Hollow circle with fill and outline
             position = position_jitterdodge(jitter.width = 0.2, dodge.width = 0.9), 
             size = 2, stroke = 0.7, alpha = 0.1,  # Adjust size, border thickness, and transparency
             show.legend = FALSE) +  # Hides points from legend
  scale_fill_manual(values = c("Familiar" = "#66c2a5", "Novel" = "#8da0cb")) +  # Bar & point fill colors
  scale_color_manual(values = c("Familiar" = "#1b7837", "Novel" = "#2b8cbe")) +  # Darker border colors for points
  facet_grid(Task ~ Condition, labeller = labeller(Condition = condition_labels, Task = task_labels)) + 
  geom_errorbar(aes(ymax = Upper, ymin = Lower), width = 0.2, position = position_dodge(width = 0.9)) +
  theme_bw() +
  ggtitle('Results by condition for each task') +
  xlab('Meaning') +
  ylab('Response Probability') +
  ylim(0, 1)
```

The plot demonstrates that participants were more likely to produce the frequent suffix with a novel meaning when the frequent suffix had a high type frequency, but were less likely to produce the frequent suffix with a novel meaning when the frequent suffix had a high token frequency. Our results also demonstrate that this effect disappears when both forms are made accessible in the form-choice task. Further, the results also demonstrate that in comprehension, regardless of the condition or stem familiarity, the original meaning is chosen far more than the novel meaning for a given suffix.

We explore the results for each task in depth in the next section.

### Production Task

<!--# Freq bar in original is choosing dan for big_pl or nem for dim_sg in the dan language and infreq bar is choosing dan for big_pl and nem for dim_sg in the nem language -->

In order to determine whether the effect of frequency on semantic extension differed between conditions, we ran a Bayesian linear mixed-effects model on the production data. The dependent variable was whether the participant produced the frequent suffix (*dan* in the *dan* language, *nem* in the *nem* language). We treatment coded condition such that the intercept was the type-token frequency condition. Thus, a larger Intercept indicates that the frequent suffix was more likely to be produced than the infrequent suffix when it had a high type and token frequency. A larger coefficient estimate indicates that the frequent form was more likely to be produced than the infrequent form in that condition relative to the type-token frequency condition. We also included meaning as a sum-coded variable. Meaning had two values, either original or novel. An original meaning referred to big plural if the suffix was *dan* or diminutive singular if the suffix was *nem*. A meaning was novel if it was diminutive plural regardless of the suffix. We also included a random intercept for participant and a random slope for meaning by participant. The syntax for our model is included below in @eq-prodmodels.

$$
\text{frequent\_suffix} \sim \text{condition}*\text{meaning} + (1 + \text{meaning} | \text{participant})
$$ {#eq-prodmodels}

The results are shown in @tbl-prodresults. The results suggest that in general the frequent suffix is preferred generally in when there is a high type and high token frequency, but not when there is only a high type frequency or a high token frequency. Notably however, we find no meaningful interaction effect for type frequency and novel meaning. We do, however, find a negative interaction effect between token frequency and novel meaning, suggesting that the frequent suffix is used less for the novel meaning when it has higher token frequency but the same type frequency as its competitors.

These results suggest that participants are more likely to produce the frequent suffix to convey a novel meaning when the suffix has both high type and token frequency or high type frequency, but not when there is high token frequency alone.

```{r, echo = F, message = F}
#| label: tbl-prodresults
#| tbl-cap: 'Results of the statistical models for the production task.'

prod_both_meanings = bind_rows(fixefs_model_prod_both, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Type Frequency:Novel', 'Token Frequency:Novel'), times = 1))


prod_both_meanings = prod_both_meanings %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

prod_both_meanings %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')
```

It is also possible that whether the stem was seen by the participant in training or not also plays a role. As a result, we ran an additional model that included whether the stem was familiar (occurred in training) or novel (did not occur in training). Similar to the previous model, condition was treatment coded with type-token frequency as the reference level, and meaning as well as stem familiarity were sum-coded. We also included a random intercept for participant and a random slope for meaning by participant and stem familiarity by participant. The model syntax is reported in @eq-prodmodelstem. The results are reported in @tbl-prodresultsstem and visualized in @fig-prodresultsstem.

$$
\text{frequent\_suffix} \sim \text{condition}*\text{meaning}*\text{stem} + (1 + \text{meaning} * \text{stem} | \text{participant})
$$ {#eq-prodmodelstem}

We find a meaningful effect for the intercept, suggesting that the frequent suffix is chosen more than the infrequent suffix when there is a high type and high token frequency. We also find a meaningful effect for novel stems, suggesting that in general the frequent suffix is produced more than the infrequent suffix when the stem is novel. Perhaps most interestingly, we find a meaningful interaction between type frequency condition and novel stem, suggesting that in the type frequency condition, there is a preference for the frequent suffix over the infrequent suffix when the stem is novel but not when it is familiar. On the other hand, no such interaction effect is found in the token frequency condition. Further, we find a three-way interaction between type frequency condition, novel meaning, and novel stem, suggesting that learners are more likely to produce a frequent suffix in the type frequency condition when both the stem and meaning are novel.

Overall, our results suggest that in production, learners generally use the frequent suffix more regardless of meaning or stem familiarity if the suffix has both a high type and high token frequency. Additionally, when the frequent suffix has a higher type frequency than the infrequent suffix, learners are more likely to use it if the stem is novel, but not when the stem is familiar. Finally, in general there is no preference to use the frequent suffix more for novel meanings if the suffix simply has a higher token frequency than the infrequent suffix.

```{r, echo = F, message = F}
#| label: tbl-prodresultsstem
#| tbl-cap: 'Results of the statistical models for the production task.'

prod_both_meanings_stems = bind_rows(fixefs_model_prod_both_stems, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem'), times = 1))


prod_both_meanings_stems = prod_both_meanings_stems %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

prod_both_meanings_stems %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '20em')
```

```{r, echo = F, out.width = '100%', fig.align = 'center', warning = F, message = F}
#| label: fig-prodresultsstem
#| fig-cap: "Plot of the statistical model estimates for the production task. The x-axis indicates the condition (type frequency, token frequency, or type-token frequency). The y-axis corresponds to the proportion of responses with a frequent suffix. Blue points indicate that the meaning was novel while purple points corresponds to the original meaning. The facet indicates whether the stem was novel or familiar."
#| fig-height: 5
#| fig-width: 7


plot_prod_stem = plot_model(model_prod_both_stems, type = 'int',
                            axis.title = c('Condition', 'Frequency'),
                            axis.labels = "condition",
                            legend.title = 'Meaning',
                            title = "",
                            dot.size = 2,
                            line.size = 1,
                            colors = c('#298c8c', '#800074'))[[4]] 
plot_prod_stem[[11]]$linetype = 'Meaning'
plot_prod_stem[[11]]$shape = 'Meaning'

plot_prod_stem[[1]]$group_col = factor(plot_prod_stem[[1]]$group_col, levels = c('novel', 'original'), labels = c('Novel Meaning', 'Original Meaning'))

plot_prod_stem[[1]]$group = factor(plot_prod_stem[[1]]$group, levels = c('novel', 'original'), labels = c('Novel Meaning', 'Original Meaning'))

plot_prod_stem[[1]]$facet = factor(plot_prod_stem[[1]]$facet, levels = c('novel', 'familiar'), labels = c('Novel Stem', 'Familiar Stem'))

#plot_prod_stem[[1]]$x

plot_prod_stem +
  scale_x_continuous(breaks = c(1, 2, 3), 
                     labels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency')) +
  ylab('Proportion of Responses with Frequent Suffix') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, color = 'black', size = 10),
        axis.title.x = element_text(size = 11),
        axis.title.y = element_text(size = 11),
        axis.text.y = element_text(color = 'black', size = 10)) 

```

### Form Choice Task

In order to examine the effects of form-choice, we similarly ran a model analogous to the one we ran for the production task (@eq-prodmodels). In the context of the form-choice task, the dependent variable reflects whether participants chose the option with the frequent suffix or the one with the infrequent suffix. Analogous to the first production model, the independent variables were condition and meaning, where condition was treatment coded such that type-token frequency was the reference level and meaning was sum-coded.

In general we find no meaningful effects except for a small interaction effect between type frequency and novel meaning, suggesting that there may be a slight preference for the familiar suffix when the frequent suffix has a higher type frequency than the infrequent suffix. However, the lack of any other meaningful effects suggests that when participants are presented with both possible options, for all conditions (except when there is a novel meaning in the type frequency condition), participants are equally likely to choose the frequent suffix as the infrequent suffix (i.e., token and type frequency don't matter).

```{r, echo = F, message = F}
#| label: tbl-2afcresults
#| tbl-cap: 'Results of the statistical models for the 2afc task.'
#| 
tafc_both_meanings = bind_rows(fixefs_model_2afc_both, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Type Frequency:Novel', 'Token Frequency:Novel'), times = 1))


tafc_both_meanings = tafc_both_meanings %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(tafc_both_meanings$meaning)

tafc_both_meanings %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

Similar to the production task, we also hypothesized that stem familiarity may also play a role. As a result, we also ran an additional model analogous to the model we ran in the production task. The dependent variable was whether participants chose the option with the frequent suffix, and the dependent variables were stem familiarity, meaning, condition, each two-way interaction effect, and their three-way interaction. We also included a random intercept for participant and random slopes for meaning by participant and stem familiarity by participant.

The model results are presented in @tbl-2afcresultsstem. Overall we find no effect of stem familiarity.

```{r, echo = F, message = F}
#| label: tbl-2afcresultsstem
#| tbl-cap: 'Results of the statistical models for the form-choice task.'

c2afc_both_stem = bind_rows(fixefs_model_2afc_both_stem, .id = "ID") %>%
  mutate(term = rep(c('Intercept (Type-Token Frequency)', 'Type Frequency', 'Token Frequency', 'Novel Meaning', 'Novel Stem', 'Type Frequency:Novel Meaning', 'Token Frequency:Novel Meaning', 'Type Frequency:Novel Stem', 'Token Frequency:Novel Stem', 'Novel Meaning:Novel Stem', 'Type Frequency:Novel Meaning:Novel Stem', 'Token Frequency:Novel Meaning:Novel Stem'), times = 1))


c2afc_both_stem = c2afc_both_stem %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

c2afc_both_stem %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '20em')
```

### Comprehension Task

In order to examine the results for the comprehension task, similar to the previous tasks we ran a mixed-effects regression model. The dependent variable was whether the meaning that participants selected was novel or original. A positive estimate indicates that participants chose the novel meaning while a negative estimate indicates that participants were more likely to choose the original meaning. Unlike the other tasks, our independent variable was coded quite differently. Specifically, our conditions varied in what the token-to-type frequency was. For example, in the Type Frequency condition, while the frequent suffix occurs 12 times with 12 different types, the infrequent occurs 12 times in only 3 different types. Thus, instead of dividing by condition, we can include token-to-type ratio as a fixed-effect. Thus, to maximize our power, we divided the data up based on whether the token-to-type ratio for the form presented on a given trial was 12-12, 12-3, or 3-3. By comparing the 12-3 condition to the 12-12 and 3-3 conditions, we can see how an increase in type frequency and a decrease in token frequency affect participants' choice of the novel or original meaning.

We treatment coded condition (referred to as condition_numeric) such that the intercept was the 12-3 condition. As a result, for each condition, a positive coefficient indicates that participants are more likely to choose a novel meaning (relative to the 12-3 condition/intercept). The model syntax is included below in @eq-comprehensionmodel. Our results for the comprehension task are included in @tbl-comprehensionresults and visualized in @fig-comprehensionresults.

$$
\text{meaning} \sim \text{condition\_numeric} + (1 | \text{participant})
$$ {#eq-comprehensionmodel}

First, we find a meaningful effect for the intercept (12-3 condition), suggesting that participants are more likely to select the original meaning when there is a high token-to-type ratio. Additionally, we find positive coefficient estimates for both 12-12 and 3-3 suggesting that when there is an equal number of tokens as types, participants are more likely to select the novel meaning. In other words, entrenchment seems to be driven not simply by the raw value of token or type frequency, but rather the proportion of tokens to types. That is, it is the relationship between type frequency and token frequency that is relevant for semantic entrenchment in comprehension.

```{r, echo = F, message = F}
#| label: tbl-comprehensionresults
#| tbl-cap: 'Results of the statistical model for the comprehension task.'
#| 

fixefs_model_comprehension_numeric = fixefs_model_comprehension_numeric %>%
  mutate(term = rep(c('Intercept (12-3)', '12-12', '3-3'), times = 1))


fixefs_model_comprehension_numeric = fixefs_model_comprehension_numeric %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_model_comprehension_numeric %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')


```

```{r, echo = F, message = F,  out.width = '100%', fig.align = 'center',}
#| label: fig-comprehensionresults
#| fig-cap: 'Plot of the model estimates for the comprehension task.'

plot_comprehension_no_stem = conditional_effects(model_comprehension_numeric)
plot(plot_comprehension_no_stem, plot = FALSE)[[1]] +
  theme_bw() +
  ylab('Probability of Novel Meaning') +
  xlab('Condition') +
  ylim(c(0,1)) +
  geom_errorbar(width = 0.1)

```

<!--# there's probably a note about storage here -->

Similar to the form-choice task, we also ran a model with stem condition. Similar to the previous model, the dependent variable was whether participants chose the original or novel meaning. However in addition to condition, we also included stem as a fixed-effect, along with its interaction with condition. A random intercept for participant was also included.

The results of the model are presented in @tbl-comprehensionresultsstem. Our results show no effect of stem familiarity on comprehension.

```{r, echo = F, message = F}
#| label: tbl-comprehensionresultsstem
#| tbl-cap: 'Results of the statistical model for the comprehension task with stem as a fixed-effect.'
#| 

fixefs_model_comprehension_numeric_stem = fixefs_model_comprehension_numeric_stem %>%
  mutate(term = rep(c('Intercept (12-3)', '12-12', '3-3'), times = 1))


fixefs_model_comprehension_numeric_stem = fixefs_model_comprehension_numeric_stem %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_model_comprehension_numeric_stem %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')


```

Overall, the comprehension results demonstrate that participants are more likely to select the original meaning when there is a high token-to-type ratio. However, when the token-to-type ratio is equivalent (either 12-12 or 3-3) then participants are more likely to select the novel meaning than when there is a high token-to-type ratio. One caveat is that participants still prefer the original meaning over the novel meaning in general (this is evident because adding the upper CI estimate to the intercept for both conditions still results in a negative estimate). In other words, while decreasing the type-to-token ratio decreases the preference for the original meaning, it does not eliminate it.

## Rescorla-Wagner Model

In this section we examine whether the Rescorla-Wagner model [@rescorla1972theorypavlovianconditioning], an associative learning model, can accurately predict our data or not.

The Rescorla-Wagner model is an associative learning model that has gained a great deal of popularity. Despite its simplicity, it has been shown to account for many phenomena in language learning and processing [@ellisSelectiveAttentionTransfer2006; @olejarczukDistributionalLearningErrordriven2018; @ramscarChildrenValueInformativity2013; @baayen2012demythologizingwordfrequency].

Specifically, the Rescorla-Wagner model is a two-layer feedforward neural network. It takes as its input a set of cues and predicts an outcome [@rescorla1972theorypavlovianconditioning; @kapatsinskiLearningFastAvoiding2021]. The Rescorla-Wagner model is defined below in @eq-rwmodel and @eq-rwmodelabsent, which differ in whether the predicted outcome is present or not. The model learns the weight of an association between a present cue and a present outcome. In the equation, $\alpha_C$ denotes the salience of the cue, $\beta^P_O$ denotes the salience of an outcome when it is present, and $\beta^A_O$ denotes the salience of an outcome when it is absent [@kapatsinskiLearningFastAvoiding2021]. $\lambda_{max}$ is the learning rate.

$$
\Delta V_{C\rightarrow O } = \alpha_C\beta^P_O(\lambda_{max}-\alpha_O)
$$ {#eq-rwmodel}

$$
\Delta V_{C\rightarrow O } = \alpha_C\beta^A_O(\lambda_{min}-\alpha_O)
$$ {#eq-rwmodelabsent}

While the Rescorla-Wagner model is often used with a linear activation function, in the present simulations we use a logistic activation instead @eq-rwlogistic) . The motivation behind this decision is that the Rescorla-Wagner model with a logistic activation function is much more sensitive to type frequency than the Rescorla-Wagner model with a linear activation function [@caballero2022howagglutinativesearching].

$$
\alpha_O = logit^{-1}(\sum_cV_{C\rightarrow O})
$$ {#eq-rwlogistic}

Given the Rescorla-Wagner model's success on a wide variety of linguistic phenomena, it's possible that it is also able to predict the results we see in this paper. Thus in this section we simulate the Rescorla-Wagner predictions for our production data in each exposure condition and compare it to the human data.

For the simulations in this section, $\alpha$ and $\beta$ were set to 0.1, $\lambda_{min}$ was set to 0, and $\lambda_{max}$ was set to 2. Our simulation process was as follows: First, for each of the different exposure conditions, we obtained a matrix of predicted cue-outcome associations using the Rescorla-Wagner model. This was done by feeding the model each trial of the exposure phase in a random order. The cues were the stem identity along with the meaning (e.g., bal_dim_pl) and the outcome was the suffix that the stem occurred with on that trial (i.e., dan, nem, sil, or shoon). The model then learned associations between each cue and each outcome.

Next, for each of the items in the production task, we summed the associations for each cue-outcome present in that trial. For example, given the item *baldan* and the meaning big plural, we consulted the matrix of cue-outcome associations for *bal* and *dan*, big and *dan*, and pl and *dan*. We then summed these to get the predicted associations for *bal* with the big.pl meaning and *dan*. This resulted in a matrix that included the model's learned association strength for any given cue with each of the four suffixes.

Following this, in order to compare the simulations with the human data, we calculated association strengths depending on whether the meaning was original or familiar. For the original meanings, we subtracted the activation strengths between the original meaning and the appropriate suffix. Specifically, this is the activation strength between the meaning cue big plural and the outcome *dan*, and the meaning cue diminutive singular and the outcome *nem*. If the language was dan (i.e., *dan* was the frequent suffix), then the activation strength between diminutive singular and *nem* was subtracted from the activation strength between big plural and *dan*. If the language was nem (i.e., *nem* was the frequent suffix), then the subtraction was in the opposite direction. To calculate the association strengths for novel meanings, if the frequent suffix was *dan* then the activation strength between diminutive plural and *nem* was subtracted from the activation strength between diminutive plural and *dan*. If the frequent suffix was *nem* then the opposite was done. This results in a single value for each trial that is the model's predicted activation of the frequent suffix relative to the infrequent suffix.

In order to test our model, we evaluated whether the model is a good predictor of the human data. Thus, we ran three Bayesian logistic regression models. In each model, the dependent variable was whether the human learner, for a given trial, selected the frequent suffix or the infrequent suffix. The first model was a simple model that modeled the human data as a function of the Rescorla-Wagner activation strength (referred to as `freq_minus_infreq` in the model syntax), with random intercepts for participant and stem identity, and a random slope for the Rescorla-Wagner model prediction by participant (@eq-rwmodel1). The second model was analogous, except that instead of only using the suffix activations, we included the stem activations as well. For example, instead of having a single activation for `bal.dim.pl` (which was the association between those cues and the frequent suffix minus the association between those cues and the infrequent suffix) we instead calculated the activations separately for the stem, *bal*, and the meaning, dim.sg (@eq-rwmodel2). Finally, in our third model, we included the original predictors in the human model (stem, condition, and meaning) along with the Rescorla-Wagner predictions from the first model (@eq-rwmodel3).

As a brief summary, in all of our models, frequency is whether the frequent or infrequent suffix was chosen in the human data, meaning is whether the meaning was familiar or novel, stem_condition was whether the stem was familiar or novel, freq_minus_infreq was the difference in predicted associations between the frequent and infrequent suffixes, and resp_stem was the individual stem (e.g., *bal*).

$$
\text{frequency} \sim \text{freq\_minus\_infreq} + (1 | \text{participant}) + (1|\text{resp\_stem})
$$ {#eq-rwmodel1}

$$
\begin{aligned}
\text{frequency} & \sim \text{freq\_minus\_infreq\_stem} * \text{freq\_minus\_infreq\_meaning} \\ & + (\text{freq\_minus\_infreq\_stem} * \text{freq\_minus\_infreq\_meaning} | \text{participant}) \\ & + (1|\text{resp\_stem})
\end{aligned}
$$ {#eq-rwmodel2}

$$
\begin{aligned}
\text{frequency} &\sim  \text{condition}*\text{meaning}*\text{stem\_condition} + \text{freq\_minus\_infreq} \\ & + (1 + \text{freq\_minus\_infreq} | \text{participant}) \\ & + (1 | \text{resp\_stem})
\end{aligned}
$$ {#eq-rwmodel3}

The results of each model are presented in @tbl-rwsim1, @tbl-rwsim2, and @tbl-rwsim3.

```{r, echo = F, message = F}
#| label: tbl-rwsim1
#| tbl-cap: 'Results of the statistical model with only the RW predictions (@eq-rwmodel1).'


fixefs_human_rw_preds = as.dataframe(fixef(model_human_rw_preds)) %>%
  mutate(term = rep(c('Intercept', 'RW Predictions'), times = 1))


fixefs_human_rw_preds = fixefs_human_rw_preds %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_human_rw_preds %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')

```

```{r, echo = F, message = F}
#| label: tbl-rwstemmeaning 
#| tbl-cap: 'Results of the statistical analysis containing the predictions from the Rescorla-Wagner logistic model separated into stem activations and meaning activations. The results demonstrate that the human data is predicted well by suffix activations but not by stem activations.'

fixefs_model_rw_preds_stem_suffix_vary = bind_rows(fixefs_model_rw_preds_stem_suffix_vary, .id = "ID") %>%
  mutate(term = rep(c('Intercept', 'Stem Activations', 'Meaning Activations', 'Stem:Meaning Activations'), times = 1))


fixefs_model_rw_preds_stem_suffix_vary = fixefs_model_rw_preds_stem_suffix_vary %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))

#groupings=rle(prod_both_meanings$meaning)

fixefs_model_rw_preds_stem_suffix_vary %>%
  select(term, everything(), -ID) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

```{r, echo = F, message = F}
#| label: tbl-rwsim3
#| tbl-cap: 'Results of the statistical model with the RW predictions alongside the predictors from the human model (@eq-rwmodel3). If the RW predictions are not capturing any additional information they should be rendered nonsignificant.'


fixefs_human_and_rw_predictors = as.dataframe(fixef(model_prod_both_stem_rw_simple)) %>%
  mutate(term = rep(c('Intercept', ), times = 1))


fixefs_human_and_rw_predictors = fixefs_human_and_rw_predictors %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric))


fixefs_human_and_rw_predictors %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '12em')
```

Overall we find that the model activations are a good predictor of the human data.

In order to compare which model best fit the data, we performed leave-one-out cross-validation using the R package `loo` [@loopackage]. Leave-one-out cross-validation refits the model for each observation in the dataset, leaving out that observation.[^3] For each data point, the expected log predictive density is calculated. Expected log predictive density is the log-likelihood of the held-out observation given the model's parameters (trained without the observation). Each model receives a single expected log predictive density value by summing the log-likelihood of each observation using leave-one-out cross-validation. A higher value indicates the model performs better than the other models. Thus, we compared the expected log predictive density value for each of these three models, along with the model of the human data that does not contain the Rescorla-Wagner predictions.

[^3]: More accurately, Bayesian models are computationally expensive to fit many times, so this is approximated using Pareto-smoothed importance sampling instead.

The results of our leave-one-out cross-validation are included in @tbl-loocv. Our results suggest that in general, every model that includes the Rescorla-Wagner predictions outperforms the model without them. Interestingly, the best fitting model is the one that separates stem activations and meaning activations into separate predictors. The results of this model are presented in @tbl-rwstemmeaning and suggest that the human data is predicted well by the meaning activations. The model also shows little effect of stem activations (although over 90% of the posterior samples were greater than zero), however a follow-up model containing only stem activations (and not meaning activations) demonstrated a meaningful effect of stem activations. Thus, the non-significant effect of stem activation in @tbl-rwstemmeaning is more likely due to co-linearity than it is a lack of effect of stem activations.

```{r, echo = F, message = F}
#| label: tbl-loocv 
#| tbl-cap: 'Results of our leave-one-out cross-validation.'
loo_co_results = loo_co_results %>%
  select(elpd_diff, se_diff, elpd_loo, se_elpd_loo, term)
  

loo_co_results %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '22em')
```

@fig-rwvshumanpreds provides a visualization of the model predictions compared to the human results. The visualization demonstrates high agreement between the predictions and human results for the type frequency condition and the type-token frequency condition, but falls short in predicting the human results for the token frequency condition. More specifically, the model predicts an effect of stem familiarity for the token frequency condition that does not appear in the human data. One possible explanation for this difference is that humans be sensitive to the fact that stem identity is a useful predictor of the meaning in the type frequency condition but not in the token frequency condition. Specifically, in the type frequency condition, certain stems appeared only with one suffix, however in the token frequency condition all the stems occurred with all of the suffixes. This may lead to learners paying attention to the stem identity in the type frequency condition but not in the token frequency condition. On the other hand, the model learns to associate all of the cues with the present outcomes irregardless of whether that cue occurs with more than one outcome.

<!--# could test this with eye-tracking if we really wanted to, do people fixate longer on stems in the type frequency condition compared to the token frequency condition? -->

### Additional Simulations

There is evidence that humans learn associations for configural cues that their parts do not have [@kapatsinskiTestingTheoriesLinguistic2009]. For example, in English syllables, rimes are treated as a single constituent (@fig-syllstructure) and @kapatsinskiTestingTheoriesLinguistic2009 demonstrated that native English speakers can learn to associate rimes with an outcome even in cases when the onset and nucleus are associated with different outcomes.

```{r echo = F, fig.align = 'center', warning = F, message = F, out.width = '50%'}
#| label: fig-syllstructure
#| fig-cap: "A visualization of English syllable structure."
#| fig-align: center

knitr::include_graphics("English syllable structure.pdf")
```

There is also evidence that adult native English speakers show greater reliance on semantic than phonology in production [@culbertson2018childrenprivilegephonological]. For example, @culbertson2018childrenprivilegephonological demonstrated that in learning an artificial noun class adults rely more on semantic cues than phonological cues (whereas interestingly children rely more on phonological cues than semantic cues).

Thus, in order to further examine the differences between the human and model predictions we made two modifications to the follow-up simulation. First, instead of modeling the suffix meanings (diminutive plural, diminutive singular, big plural, big singular) as two separate cues, we also included a configural cue (analogous to an interaction effect in linear regression) that could be associated with the outcome. This configural cue was simply a combination of the two comprising meanings. For example, given the meaning "big plural", the cues comprised "big", "plural", and "big.plural". Similar to the previous simulations, the model was presented with these cues paired with one of the four suffixes. The model was trained on the same data that the humans were trained on.

Second, in addition to configural cues, we also increased the alpha value for semantic cues relative to the phonological cues. This results in semantic cues being more associable with outcomes than phonological cues.

Analogous to the previous simulations, we then calculated the model's predicted activation for the frequent suffix. If the meaning was novel, this was simply the difference between the activation strength for the frequent suffix and the activation strength for the infrequent suffix. If the meaning was original, then it was the difference between activation strength of big plural with *dan* and the activation strength of diminutive singular and *nem* if *dan* was the frequent suffix and vice versa if *nem* was the frequent suffix.

In order to evaluate this simulation, we ran a Bayesian logistic regression model similar to previously, with the human response as the dependent variable (1 if they chose the frequent suffix and 0 if they chose the infrequent suffix) and the model's prediction as the independent variable with random intercepts for participant and stem, and a random slope for the predicted activation by participant. We then examined whether this model was a better fit to the data than the other model predictions using leave-one-out-cross-validation.

The results of our regression model are presented in @tbl-rwconfsem and visualized next to the human data and the RW predictions without configural cues or increased semantic salience in @fig-rwvshumanpreds. Additionally, the results of the leave-one-out-cross-validation are presented in @tbl-loocv_addsims. These results taken together demonstrate that a model that includes configural cues and an increased sensitivity to semantic cues relative to phonological cues is better able to capture the human data.

<!--# to add: in-depth explanation of the configural cue and semantic  -->

```{r, echo = F, message = F}
#| label: tbl-rwconfsem 
#| tbl-cap: 'Results of the statistical analysis containing the predictions from the Rescorla-Wagner logistic model with configural cues and increased saliency for semantic cues.'

fixefs_model_model_human_conf_sem_preds = fixefs_model_model_human_conf_sem_preds %>%
  mutate(across(c(Estimate, Est.Error, Q2.5, Q97.5, `% Samples > 0`), as.numeric)) %>%
  mutate(term = c('Intercept', 'RW Model Predictions'))


fixefs_model_model_human_conf_sem_preds %>%
  select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '18em')

```

```{r, echo = F, out.width = '90%', fig.align = 'center', warning = F, message = F}
#| label: fig-rwvshumanpreds
#| fig-cap: "Plot of the original RW simulations and the modified RW simulations versus the human results. The y-axis is the probability of producing the frequent meaning. The top facet is original meanings and the bottom axis is novel meanings. 'Modified Sim' corresponds to the RW simulations with configural cues and increased semantic saliency. 'RW Logistic' corresponds to our original simulations. The results suggest that a model that includes configural cues and increased semantic saliency better predicts the human data."
#| fig-height: 6
#| fig-width: 7

config_mod_sem = read_csv('../Data/rw_plot_configural_mod_alpha.csv') %>%
  mutate(model_type = 'Modified Sim', Prob = arm::invlogit(mean_freq_diff))

fixed_effects_df = read_csv('../Data/fixed_effects_df_all.csv') %>%
  filter(Task == 'prod') %>%
  mutate(model_type = 'Human') %>%
  rename('meaning' = 'Meaning', 'condition' = 'Condition', 'mean_freq_diff' = 'Estimate', 'prod_condition' = 'Stem') %>%
  mutate(condition = case_when(
    condition == 'cond1' ~ 1,
    condition == 'cond2' ~ 2,
    condition == 'cond3' ~ 3
  )) %>%
  dplyr::select('meaning', 'prod_condition', 'condition', 'Prob', 'model_type')

no_config_cues = read_csv('../Data/data_all_conds_logistic.csv') %>%
  mutate(model_type = 'RW Logistic', Prob = arm::invlogit(mean_freq_diff))
  

all_data = config_mod_sem %>%
  full_join(fixed_effects_df) %>%
  full_join(no_config_cues)

#all_data = read_csv('../Data/model_preds_and_human_data.csv')

all_data$Meaning = all_data$meaning
all_data$Condition = all_data$condition
all_data$Stem = all_data$prod_condition


all_data = all_data %>%
  mutate(across(where(is.character), str_to_title)) %>%
  mutate(Condition = case_when(
    Condition == 1 ~ 'Type Frequency',
    Condition == 2 ~ 'Token Frequency', 
    Condition == 3 ~ 'Type-Token Frequency'
  ))

all_data$Condition = factor(all_data$Condition, levels = c('Type Frequency', 'Token Frequency', 'Type-Token Frequency'))

observed_vs_model_plot = ggplot(data = all_data, aes(x = model_type, y = Prob, fill = Stem)) +
  geom_col(position = "dodge") +
  xlab('Human Data vs Model Predictions') +
  ylab('Probability of the Frequent Meaning') +  
  scale_fill_manual(values = c("Familiar" = "#66c2a5", "Novel" = "#8da0cb")) +
  ylim(c(0,1)) +
  facet_grid(Meaning~Condition) +
  theme_bw() +
  theme(
  axis.text.x = element_text(angle = 45, hjust = 1)
)

observed_vs_model_plot

#ggarrange(observed_estimates_plot, rw_plot, nrow = 2, common.legend = T)
```

```{r, echo = F, message = F}
#| label: tbl-loocv_addsims 
#| tbl-cap: "Results of the leave-one-out cross-validation for the additional simulation. 'Modified RW' corresponds to the model with configural cues and increased saliency for semantic cues. 'RW Model' refers to the RW logistic model. 'Only Human' refers to the original statistical analysis that contains no model predictions."


loo_co_results_add = read_csv('../Data/loo_comparisons_conf_sem.csv') %>%
  dplyr::select(elpd_diff, se_diff, elpd_loo, se_elpd_loo) %>%
  mutate(term = c('Modified RW', 'RW', 'Only Human'))
  

loo_co_results_add %>%
  dplyr::select(term, everything()) %>%
  rename(` ` = term) %>%
  kable(digits = 2, row.names = FALSE, booktabs = TRUE, format = "latex", escape = TRUE) %>%
  kable_styling(latex_options = c("HOLD_position", "striped"), font_size = 11, full_width = FALSE) %>%
  #group_rows(index = setNames(groupings$lengths, groupings$values), indent = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = T, width = '22em')

```

Overall, the results of our simulations suggest that an error-driven associative learning model, specifically the Rescorla-Wagner model, fits the human data better than Interestingly, a model with only the activations outperforms (by a large margin) the model that includes stem, condition, and meaning as predictors. This suggests that while the model predicts a linear relationship between stem activations and meaning activations, humans are more sensitive to the meaning activations than the stem activations. Further, our results suggest that participants pay attention to stem identity/familiarity when it is a useful cue (such as in the type frequency condition), but not when it is not a useful cue (such as in the token frequency condition).

The results also suggest that a model with configural cues and a higher alpha value for semantic cues relative to phonological cues better fits the human data. This confirms previous findings that have demonstrated that humans learn associations for configural cues and that humans are more sensitive to semantic cues than phonological cues.

## Discussion

Our results suggest that in production, having a high type and high token frequency (relative to the competitor), along with simply having a high type but equal token frequency (relative to the competitor), leads to semantic extension, while having a high type frequency but low token frequency leads to entrenchment (i.e., using the suffix more with the original meaning than novel meanings). Further, this mirrors what we see in comprehension where participants are more likely to choose the novel meaning when the type and token frequencies are matched, but less likely when the suffix has high token frequency but low type frequency. Further, when both forms are made accessible as in the form choice task, the preference for the frequent suffix over the infrequent suffix disappears for all conditions.

Our results also demonstrate that the Rescorla-Wagner model with a logistic activation function is able to capture a good amount of the human results, however predicts an effect of stem familiarity where we do not see it in humans (in the token frequency condition).

\newpage
